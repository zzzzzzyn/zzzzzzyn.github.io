<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[诡计博物馆]]></title>
    <url>%2F2020%2F09%2F13%2F%E8%AF%A1%E8%AE%A1%E5%8D%9A%E7%89%A9%E9%A6%86%2F</url>
    <content type="text"><![CDATA[复仇日记痴心人甘愿落于人后，皆因奉心上人事事为先 人是一种无法忍受无意义的生物，如果察觉到自己的行为是无意义的，就会想方设法地赋予它意义，或者对其无意义的行为持有疑问]]></content>
      <tags>
        <tag>书</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ConcurrentHashMap笔记]]></title>
    <url>%2F2020%2F06%2F06%2FConcurrentHashMap%E7%AC%94%E8%AE%B0(JDK1.8)%2F</url>
    <content type="text"><![CDATA[1. 概述ConcurrentHashMap是并发版本的HashMap，没有线程安全问题，在JDK1.8中使用CAS+synchronized来做并发安全保证，在结构上基本和HashMap的结构相同，也是数组+链表+红黑树的结构。 2. 源码解析2.1 插入插入方法是使用最频繁的方法，就是你想的那样，插入或者替换两种情况，大致流程都写在了代码中。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879public V put(K key, V value) &#123; return putVal(key, value, false);&#125;final V putVal(K key, V value, boolean onlyIfAbsent) &#123; if (key == null || value == null) throw new NullPointerException(); // 1. 计算key的hash int hash = spread(key.hashCode()); int binCount = 0; for (Node&lt;K,V&gt;[] tab = table;;) &#123; Node&lt;K,V&gt; f; int n, i, fh; // 2. 是否需要进行初始化 if (tab == null || (n = tab.length) == 0) tab = initTable(); // 3. tab[i]位置的node是否为null else if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) &#123; // 3.1 cas方式插入新node if (casTabAt(tab, i, null, new Node&lt;K,V&gt;(hash, key, value, null))) break; // no lock when adding to empty bin &#125; // 4. 是否正在扩容，帮助扩容 else if ((fh = f.hash) == MOVED) tab = helpTransfer(tab, f); // 5. 插入或替换 else &#123; V oldVal = null; synchronized (f) &#123; if (tabAt(tab, i) == f) &#123; // 判断fh是node链头节点还是红黑树根节点？ if (fh &gt;= 0) &#123; binCount = 1; // 遍历node链，通过key决定替换还是尾部插入 for (Node&lt;K,V&gt; e = f;; ++binCount) &#123; K ek; if (e.hash == hash &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) &#123; // 替换 oldVal = e.val; if (!onlyIfAbsent) e.val = value; break; &#125; Node&lt;K,V&gt; pred = e; if ((e = e.next) == null) &#123; // 插入 pred.next = new Node&lt;K,V&gt;(hash, key, value, null); break; &#125; &#125; &#125; else if (f instanceof TreeBin) &#123; Node&lt;K,V&gt; p; binCount = 2; if ((p = ((TreeBin&lt;K,V&gt;)f).putTreeVal(hash, key, value)) != null) &#123; // 插入红黑树 oldVal = p.val; if (!onlyIfAbsent) p.val = value; &#125; &#125; &#125; &#125; if (binCount != 0) &#123; // 判断node链是否需要树化（链表循环时记录了binCount） if (binCount &gt;= TREEIFY_THRESHOLD) treeifyBin(tab, i); if (oldVal != null) return oldVal; break; &#125; &#125; &#125; addCount(1L, binCount); return null;&#125; 计算出key的hash值，并进入最外层的大循环。 判断table是否需要初始化，需要进行初始化并再次进入循环，不需要则进入下一步。 通过hash得到索引下标，判断有无Node(链表或红黑树)，没有则将kv以CAS方式插入(作为链表首节点)到此坐标位置，并退出循环增加计数返回、否则进入下一步。 table是否正在扩容，是则帮助扩容并再次进入循环，否则进入下一步。 对hash得到的下标的元素，判断插入还是替换。如果是链表，添加完成后判断是否需要树化 如果是插入则执行addCount()增加计数，否则不增加。 2.2 插入操作依赖的一些方法12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182// 重新哈希，减少哈希冲突static final int spread(int h) &#123; return (h ^ (h &gt;&gt;&gt; 16)) &amp; HASH_BITS;&#125;// table初始化private final Node&lt;K,V&gt;[] initTable() &#123; Node&lt;K,V&gt;[] tab; int sc; // table是否需要初始化 while ((tab = table) == null || tab.length == 0) &#123; // 1. sc&lt;0表示正在调整table大小 if ((sc = sizeCtl) &lt; 0) // sc&lt;0说明有其他线程正在执行扩容或初始化，本线程暂停 Thread.yield(); // lost initialization race; just spin // 2. CAS设置sizeCTL的值为-1 else if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) &#123; try &#123; // 确认此时table没有被其他线程初始化 if ((tab = table) == null || tab.length == 0) &#123; // 确定table容量 int n = (sc &gt; 0) ? sc : DEFAULT_CAPACITY; @SuppressWarnings("unchecked") Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n]; table = tab = nt; // sc为n-n/4，也就是n的3/4 sc = n - (n &gt;&gt;&gt; 2); &#125; &#125; finally &#123; // sizeCtl为下次扩容阈值 sizeCtl = sc; &#125; break; &#125; &#125; return tab;&#125;// 增加计数private final void addCount(long x, int check) &#123; CounterCell[] as; long b, s; if ((as = counterCells) != null || !U.compareAndSwapLong(this, BASECOUNT, b = baseCount, s = b + x)) &#123; CounterCell a; long v; int m; boolean uncontended = true; if (as == null || (m = as.length - 1) &lt; 0 || (a = as[ThreadLocalRandom.getProbe() &amp; m]) == null || !(uncontended = U.compareAndSwapLong(a, CELLVALUE, v = a.value, v + x))) &#123; fullAddCount(x, uncontended); return; &#125; if (check &lt;= 1) return; s = sumCount(); &#125; // check&gt;=0说明需要扩容 if (check &gt;= 0) &#123; Node&lt;K,V&gt;[] tab, nt; int n, sc; while (s &gt;= (long)(sc = sizeCtl) &amp;&amp; (tab = table) != null &amp;&amp; (n = tab.length) &lt; MAXIMUM_CAPACITY) &#123; int rs = resizeStamp(n); if (sc &lt; 0) &#123; if ((sc &gt;&gt;&gt; RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 || sc == rs + MAX_RESIZERS || (nt = nextTable) == null || transferIndex &lt;= 0) break; if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)) transfer(tab, nt); &#125; else if (U.compareAndSwapInt(this, SIZECTL, sc, (rs &lt;&lt; RESIZE_STAMP_SHIFT) + 2)) transfer(tab, null); s = sumCount(); &#125; &#125;&#125;// 转移方法 有空回来填坑private final void transfer(Node&lt;K,V&gt;[] tab, Node&lt;K,V&gt;[] nextTab) &#123;&#125;// 帮助转移final Node&lt;K,V&gt;[] helpTransfer(Node&lt;K,V&gt;[] tab, Node&lt;K,V&gt; f) &#123;&#125; 2.3 获取获取操作相对插入而言肯定会简单一些，分为三个步骤： 获取key对应的hash值，并判断对应下标出的node不为空，若node与传入key相等，返回对应value。 通过eh判断table是否正在扩容，遍历扩容处的链表上是否存在对应key，返回对应value或null。 既不是头结点也没有扩容，遍历对应链表，若存在相应key，返回value否则返回null。 1234567891011121314151617181920212223242526272829303132333435363738public V get(Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; e, p; int n, eh; K ek; // 1. 获取key的hash int h = spread(key.hashCode()); // 2. 判断链表不为空且对应下标处node不为空 if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (e = tabAt(tab, (n - 1) &amp; h)) != null) &#123; // 2.1 判断hash是否相等 if ((eh = e.hash) == h) &#123; if ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek))) return e.val; &#125; // 2.2 eh&lt;0表示正在扩容 else if (eh &lt; 0) return (p = e.find(h, key)) != null ? p.val : null; // 2.3 遍历链表查找 while ((e = e.next) != null) &#123; if (e.hash == h &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) return e.val; &#125; &#125; // 3. key不存在，返回null return null;&#125;Node&lt;K,V&gt; find(int h, Object k) &#123; Node&lt;K,V&gt; e = this; if (k != null) &#123; do &#123; K ek; if (e.hash == h &amp;&amp; ((ek = e.key) == k || (ek != null &amp;&amp; k.equals(ek)))) return e; &#125; while ((e = e.next) != null); &#125; return null;&#125; 3. HashMap和ConcurrentHashMap的区别 HashMap线程不安全，数组+链表+红黑树实现，key可为null ConcurrentHashMap线程安全，CAS+synchronized和数组+链表+红黑树实现，key不能为null 4. 总结ConcurrentHashMap是并发安全情况下的选择。]]></content>
      <tags>
        <tag>集合框架</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[重新认识String]]></title>
    <url>%2F2020%2F05%2F29%2F%E9%87%8D%E6%96%B0%E8%AE%A4%E8%AF%86String%2F</url>
    <content type="text"><![CDATA[String是大三刚学Java的时候接触的，以前看String的时候感觉很简单，感觉会用就行了，后来发现用的时候也会有很多问题，所以回来温习一下 1. 属性下面是String源码中的所有属性，我们可以看出： String是final修饰的，所以String中的所有方法也都被final修饰，类不能被继承，方法不能被重写。这也和我们面试题中看到的一致 String最重要的属性是value[]，用来存储字符串，它是一个定长的char数组，一经赋值不可修改 12345678public final class String implements java.io.Serializable, Comparable&lt;String&gt;, CharSequence &#123; private final char value[]; private int hash; // Default to 0 private static final long serialVersionUID = -6849794470754667710L; private static final ObjectStreamField[] serialPersistentFields = new ObjectStreamField[0];&#125; 2. 常用的方法下面这些方法中： equals被String重写了，先比较内存地址再比较字符数组 substring和concat都返回一个新的String，因为String是final修饰，无法被修改 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public boolean equals(Object anObject) &#123; // 首先比较内存地址 if (this == anObject) &#123; return true; &#125; if (anObject instanceof String) &#123; // 比较字符数组 String anotherString = (String)anObject; int n = value.length; if (n == anotherString.value.length) &#123; char v1[] = value; char v2[] = anotherString.value; int i = 0; while (n-- != 0) &#123; if (v1[i] != v2[i]) return false; i++; &#125; return true; &#125; &#125; return false;&#125;public String substring(int beginIndex) &#123; // 边界检查 if (beginIndex &lt; 0) &#123; throw new StringIndexOutOfBoundsException(beginIndex); &#125; // 截取长度 int subLen = value.length - beginIndex; // 边界检查 if (subLen &lt; 0) &#123; throw new StringIndexOutOfBoundsException(subLen); &#125; return (beginIndex == 0) ? this : new String(value, beginIndex, subLen);&#125;public String concat(String str) &#123; int otherLen = str.length(); if (otherLen == 0) &#123; return this; &#125; int len = value.length; // 扩充字符数组容量 char buf[] = Arrays.copyOf(value, len + otherLen); // 放入到buf中 str.getChars(buf, len); return new String(buf, true);&#125; 结论：任何修改String的操作，都只会返回新对象，不会对原来的对象有影响 3. String与常量池字符串常量池存在于堆中(jdk1.8)，Jvm为了提高性能而使用常量池，每次创建字符串对象时，都会在字符串常量池中存一份(如果里边没有的话)。 使用常量池的几种情况： 双引号赋值 String类的intern方法 new String(&quot;abc&quot;)，abc不在常量池中时，会现在常量池中创建，然后在堆中创建一份String对象 4. 字符串的拼接与比较字符串的比较123String str1 = "ab";String str2 = new String("ab");System.out.println(str1 == str2); // false str1在常量池中创建，str2先检查常量池中有无字符串ab，没有就在常量池中创建，然后去堆中创建对象并把地址复制给str2，所以他们的内存地址比较为false 123String str1 = new String("ab");String str2 = new String("ab");System.out.println(str1 == str2); // false str1和str2比较内存地址，返回false 123String str1 = "a" + "b" + "c";String str2 = "abc";System.out.println(str1 == str2); // true 上面为什么会返回true？因为编译器对str1进行了编译期优化，将String str1 = &quot;a&quot; + &quot;b&quot; + &quot;c&quot;优化成了String str1 = &quot;abc&quot;，又因为字符串常量池的存在，所以true 1234String str1 = "abc";String str2 = "ab"; String str3 = str2 + "c";System.out.println(str1 == str3); // false 上面是为什么返回false的？str3是在运行时确定的，这里其实会创建两个对象，一个StringBuilder对象和一个String对象。String str3 = str2 + &quot;c&quot;会被优化成new StringBuilder(str2).append(&quot;c&quot;).toString()，通过StringBuilder.toString()的源码方法看到返回一个新的String对象，所以false 上面对字符串的拼接做了一个总结，String内部重写了equals方法，应使用equals进行比较 5. 常见问题+的错误用法12345String str = "a";for (int i = 0; i &lt; 5; i++) &#123; str = str + "b";&#125;System.out.println(str); 每一次循环都会产生一个StringBuilder对象和一个String对象，应避免这种写法，使用StringBuilder代替]]></content>
      <tags>
        <tag>java基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring循环依赖]]></title>
    <url>%2F2020%2F05%2F17%2FSpring%E5%BE%AA%E7%8E%AF%E4%BE%9D%E8%B5%96%2F</url>
    <content type="text"><![CDATA[1. 问题SpringBoot 2.1.4报错如下，看了一下是循环依赖的问题。即 A -&gt; B，B -&gt; A（ 我的代码里 A 服务内部注入了 B 服务，B 服务内部也注入了服务 A） 2. 错误代码 3. 解决 使用 @Lazy 令两个服务中的其中一方懒加载 使用 setter 方式注入 4. 原理只知道构造注入会造成循环依赖，有空回来填坑]]></content>
      <tags>
        <tag>日常踩坑</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM的高频知识点]]></title>
    <url>%2F2020%2F04%2F23%2FJVM%E7%9A%84%E9%AB%98%E9%A2%91%E7%9F%A5%E8%AF%86%E7%82%B9%2F</url>
    <content type="text"><![CDATA[1. JVM 年轻代到年老代晋升过程？ 对象在Form和To之间来回复制，年龄达到15（默认值，可通过 MaxTenuringThreshold 修改），晋升老年代 分配对象超过eden内存的一半，直接进入老年代。小于eden一半但没有内存空间，进行minor GC，survivor也放不下，进入老年代 动态年龄判断，某个年龄对象超过survivor空间的一半，大于等于某个年龄的对象直接进入老年代 2. Minor GC，Major GC和Full GC区别？ Minor GC：年轻代GC Major GC：年老代GC Full GC：整个堆空间GC（年轻代和年老代） 3. 发生 Full GC 的几种情况？ System.gc() 方法显示调用（只是建议进行GC） 老年代空间不足：只有在新生代对象转入或大对象（数组等）分配时，老年代才会出现内存不足情况，若 Full GC后空间依旧不足，抛出内存溢出异常 CMS GC时出现 promotion failed 和 concurrent mode failure promotion failed：发生Minor GC时，survivor space放不下了，只能晋升老年代，老年代也放不下 concurrent mode failure：执行CMS GC的同时有对象要放入老年代，而此时老年代空间不足造成的（有时候“空间不足”是CMS GC时当前的浮动垃圾过多导致暂时性的空间不足触发Full GC） 统计的到的Minor GC晋升老年代对象平均大小大于老年代剩余空间 Hotspot为避免晋升失败，会统计之前每次Minor GC后晋升对象的平均大小是否可以被老年代容纳，不能的话会触发Full GC 例如第一次Minor GC后有6M晋升到老年代，那么下次Minor GC发生时就会检查老年代是否有6M大小的空间 新生代使用PS GC（并发GC收集器）时，PS GC只对当前负责，检查本次要晋升的对象大小能否被老年代容纳，不能的话出触发Full GC 堆中分配很大的对象：特指需要大量连续空间的对象 调用了 jmap -histo:live [pid]：立即出发Full GC 4. 如何拿到 JVM 的 dump 文件？ jstack [pid] &gt; xxx.txt：打印堆栈信息到文件 jstack -l [pid] &gt; xxx.txt：打印堆栈信息（包含锁）到文件 kill -3 添加 JVM 参数：-XX:+HEAPDUMPONOUTOFMEMORYERROR（在内存溢出是保存堆栈信息），一般配合 -XX:HeapDumpPath=PATH 使用（可用 jinfo 命令运行时修改） jmap -dump:format=b,file=xxx.dump [pid] 5. JVM 出现 fullGC 很频繁，怎么去线上排查问题？ jstat 查看GC信息观察GC后的堆空间大小并判断是否空间不足导致 空间不足导致：拿到 dump 文件，放入 JVisualVM 观察原因 空间充足：观察程序中有没显示调用 System.gc() 方法 6. 对象如何进行访问定位？ 句柄：在堆空间中开辟一块空间用来存放句柄池，句柄池存放对象的类型指针和对象的实例指针，reference指针指向句柄 好处：reference指向稳定的句柄，当堆空间进行gc时，对象的移动只会改变句柄中的对象实例指针，对reference没有影响 直接指针：堆中实例对象存放实例类型，reference指针直接指向实例对象 好处：速度更快，节省一次指针定位的开销 7. 对象创建过程？ 类加载检查：虚拟机遇到一条new指令，首先检查指令的参数能否在常量池（元空间）中定位到这个类的符号引用，并检查这个类是否被加载、解析和初始化过，如果没有则执行类加载过程 分配内存：对象所需内存大小在类加载完成后便可确定，为对象在堆中划出一块 分配内存的两种方式： 指针碰撞：堆空间使用时是规整的，只需要把分界点的指针移动对象大小位置即可 空闲列表：堆空间使用时不是规整的，空闲区域维护在一个列表中，分配时先查询列表，分配完之后更新列表 堆空间分配是否规整由所采用的的垃圾收集器的算法决定 并发情况下内存空间的安全分配的两种方式（跟锁的安全策略其实差不多，原理上相同） CAS失败重试，直至成功 TLAB，预先为每个线程在eden区分配空间，JVM在线程中分配内存时首先在TLAB分配，TLAB剩余空间不足或用尽时，采用CAS失败重试继续进行内存分配 初始化零值：虚拟机需要将内存空间都初始化为零值，保证对象实例字段在java中不经赋初始值就可被调用 设置对象头：设置类的元数据信息、对象的哈希码、GC分代年龄。根据虚拟机当前运行状态的不同，决定是否使用偏向锁 执行init方法：一般来说，执行new指令之后会执行init方法，把对象按照我们的意愿进行初始化，这样一个真正可用的对象才算完全产生出来 8. GC对象的判定方法？ 引用计数法：为对象添加计数器，有引用该对象的地方时，计数器+1 优点：效率高，简单 缺点：存在循环引用问题 可达性分析算法：通过一系列GcRoots的对象为起点向下搜索，走过的路径为引用链，没在引用链上为废弃对象 可做为GCRoot的对象（jdk1.7）： 虚拟机栈引用的对象 方法区中类静态属性引用的变量（static对象） 方法区中常量引用的对象（final对象） 本地方法栈中Native方法引用的变量 9. 四种引用？ 强引用：new对象就是强引用，JVM抛出OOM也不会清除 软引用：JVM内存不足时会回收软引用对象 弱引用：JVM只要进行GC就会回收弱引用对象 虚引用：幽灵引用，虚引用不会对对象生命周期产生印象，也无法通过虚引用获取对象 10. 垃圾回收算法？ 标记清除：先标记再清除，有效率问题且会产生大量不连续的内存碎片 标记整理：先标记，将标记数据移到内存一端，清除其余部分，有效率问题但不会产生内存碎片 复制算法：将内存一份为二，使用一半内存，当垃圾回收时将存活对象放入另一半，然后清理自己的内存。好处是效率高且没有内存碎片，但会牺牲一半内存。在jvm中年轻代使用复制算法，但年轻代对象都是朝生夕死，所以内存分配时eden占用80%，而survivor占用%20来使用 分代算法：新生代复制算法，老年代标记整理或标记清除 11. 垃圾收集器？ Serial收集器：年轻代串行收集器，当GC收集时，工作线程必须暂停(stop the world)直至收集结束，使用复制算法 Serial Old收集器：年老代串行收集器，特性和Serial一样，使用标记整理算法 Parallel Scavenge收集器：年轻代并行收集器，吞吐量优先收集器，使用复制算法 Parallel Old收集器：年老代并行收集器，使用标记整理算法 ParNew收集器：年轻代并行收集器，Serial收集器的多线程版本，为了配合CMS而生，复制算法 CMS收集器：年老代并发收集器，目标是最短停顿回收时间，注重用户体验，标记清除算法 运行过程： 初始标记（Stop-The-World）：仅标记GCRoot能关联到的对象 并发标记：标记GCRoot关联的所有不相关对象（从并发就可以看出，他是和用户线程一起工作的） 重新标记（Stop-The-World）：对并发标记期间因用户操作而导致标记变动的对象进行重新标记 并发清除：进行清除 优点：最短停顿回收时间，注重用户体验 缺点： CPU资源敏感 无法处理浮动垃圾，浮动垃圾过多时会启用Serial Old收集器 大量内存碎片，再次分配大对象分配不下时，会引发一次FullGC，通过-XX：+UseCMSCompactAtFullCollection，在要进行FullGC时，进行内存整理（无法并发，慢） G1收集器： 12. 理解GC日志？13. JVM常用参数？Oracle的官方文档 JVM常用参数指南 14. 分配担保机制？在发生Minor GC前，JVM检查新生代总大小是否可被老年代最大连续空间容纳，可容纳时进行Minor GC，否则检查是否允许分配担保失败，如果允许，判断老年代最大连续空间是否大于以往晋升对象的平均大小，若大于，进行Minor GC（有风险，可能这次超出平均大小，老年代接不住）。若小于或不允许分配担保失败，则转为执行Full GC 15. 类加载机制？ 加载： 通过全类名获取类的二进制字节流 将字节流所代表的的静态存储结构转换为方法区（元空间）的运行时数据结构 在内存中生成代表该类的Class文件，作为方法区（元空间）这些数据的访问入口 验证： 文件格式验证 元数据验证 字节码验证 符号引用验证 准备：正式为类变量分配内存并设置类变量初始值（就是默认值），例如public static int val = 111;，这里分配的是初值0； 解析：将虚拟机常量池内的符号引用替换为直接引用的过程，主要针对类或接口、字段、类方法、接口方法、方法类型、方法句柄和调用限定符7种符号引用进行 初始化：执行类构造器&lt;client&gt;()方法过程，比如上面的静态变量val会被赋值为111 16. 类卸载条件？类卸载即该类的class对象被GC 该类的所有的实例对象都被GC，即堆中不存在该类的实例对象 该类没有在其他地方被引用 该类的类加载器的实例已被GC 17. 类加载器？对任意一个类，都需要加载它的类加载器和这个类本身一同确立其在Java虚拟机中的唯一性，每一个类加载器都有一个独立的类名称空间 JVM内置三个重要的类加载器： 启动类加载器（Bootstrap ClassLoader）：使用C++语言实现，是虚拟机自身的一部分 扩展类加载器（Extension CLassLoader）：加载&lt;JAVA_HOME&gt;\lib&#39;ext目录中的，或被java.ext.dirs系统变量所指定的路径中的所有类库 应用程序类加载器（Application ClassLoader）：这个类加载器是ClassLoader中的getSystemClassLoader()方法的返回值，负责加载用户类路径（ClassPath）上的指定类库，我们写的类文件被这个类所加载 18. 什么是双亲委派模型，为什么使用？类加载器之间的层次关系称为双亲委派模型，双亲委派模型要求除了顶层的启动类加载器外，其余的类加载器都要有自己的父类加载器 双亲委派模型工作过程：如果一个类加载器收到类加载请求，它首先不会自己去加载这个类，而是委托给父类加载器加载，因此所有加载请求都会传送到最顶层启动类加载器中，父类加载器不能加载时会反馈自己无法完成加载请求，子类加载器才会尝试加载。大致就是（有事往上报，上头处理不了，会扔回来让你自己处理） 为什么使用：上面说过一个类的唯一性由加载它的类加载器和类本身一同决定。举个栗子：假如没有使用双亲委派模型，你自己写了一个java.lang.Object类，你自己加载，我使用的时候怎么知道到底用哪个Object。所以使用双亲委派模型是为了保证程序的稳定运行 参考 JVM 出现 fullGC 很频繁，怎么去线上排查问题 堆内存占用很小 但是 JVM 频繁full gc 问题排查 JVM面试题整理 深入理解Java虚拟机(第2版)]]></content>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LinkedHashMap源码(JDK1.8)]]></title>
    <url>%2F2020%2F04%2F19%2FLinkedHashMap%E6%BA%90%E7%A0%81(JDK8)%2F</url>
    <content type="text"><![CDATA[1. 概述LinkedHashMap继承了HashMap，并在其基础上维护了一条双向链表，用来保证顺序访问。 2. 源码分析2.1 内部类和属性LinkedHashMap的内部类继承了Node，并根据需要增加了before，after属性。这两个属性你肯定似曾相识，在LinkedList中使用过。其实他们的功能其实是一样的，定位前一个或后一个entry。 1234567891011121314151617// 头结点transient LinkedHashMap.Entry&lt;K,V&gt; head;// 尾节点transient LinkedHashMap.Entry&lt;K,V&gt; tail;// 排序方式，true：访问顺序排序(LRU) false：插入顺序排序final boolean accessOrder;// 其它的属性都在hashmap中，这里就不一一列出了// LinkedHashMap的内容存储类static class Entry&lt;K,V&gt; extends HashMap.Node&lt;K,V&gt; &#123; // 前后指针 Entry&lt;K,V&gt; before, after; Entry(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; super(hash, key, value, next); &#125;&#125; 2.2 构造方法通过下面的代码可以看出，LinkedHashMap的构造方法基本是调用父类构造来完成的，自己只是完成accessOrder属性操作（也就是排序方式，默认false）。 123456789101112131415161718192021222324252627public LinkedHashMap() &#123; super(); accessOrder = false;&#125;public LinkedHashMap(int initialCapacity) &#123; super(initialCapacity); accessOrder = false;&#125;public LinkedHashMap(int initialCapacity, float loadFactor) &#123; super(initialCapacity, loadFactor); accessOrder = false;&#125;public LinkedHashMap(Map&lt;? extends K, ? extends V&gt; m) &#123; super(); accessOrder = false; putMapEntries(m, false);&#125;// 显式指定是否启用有序访问public LinkedHashMap(int initialCapacity, float loadFactor, boolean accessOrder) &#123; super(initialCapacity, loadFactor); this.accessOrder = accessOrder;&#125; 2.3 插入方法和钩子方法LinkedHashMap的元素获取是调用HashMap的put方法，不过LinkedHashMap通过重写HashMap的钩子方法来实现一些自己的逻辑。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283// HashMapfinal V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; …… 省略无关代码 if (e != null) &#123; // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); // 钩子方法 return oldValue; &#125; &#125; if (++size &gt; threshold) resize(); afterNodeInsertion(evict); // 钩子方法 return null;&#125;// 钩子方法的定义(在HashMap中为空实现，留给子类重写逻辑)void afterNodeAccess(Node&lt;K,V&gt; p) &#123; &#125;void afterNodeInsertion(boolean evict) &#123; &#125;void afterNodeRemoval(Node&lt;K,V&gt; p) &#123; &#125;// LinkedHashMap// 节点访问后，移动元素e到链尾，频繁访问的元素就会落在尾部void afterNodeAccess(Node&lt;K,V&gt; e) &#123; // move node to last LinkedHashMap.Entry&lt;K,V&gt; last; // accessOrder为null且tail节点不是e，才会进入方法 if (accessOrder &amp;&amp; (last = tail) != e) &#123; LinkedHashMap.Entry&lt;K,V&gt; p = (LinkedHashMap.Entry&lt;K,V&gt;)e, // b为e的前驱节点，a为p的后继节点 b = p.before, a = p.after; p.after = null; if (b == null) head = a; // b=null说明e为头结点，则将后继a设为头节点 else b.after = a; // b!=null，将b的后继设置为a if (a != null) a.before = b; // a!=null，将a的前驱设置为b else last = b; // a=null则将last设置为b if (last == null) head = p; // p为头结点 else &#123; p.before = last; last.after = p; // 设置p和last的链接关系 &#125; tail = p; // 设置p为尾节点 ++modCount; &#125;&#125;// 在put方法调用到这里evict为truevoid afterNodeInsertion(boolean evict) &#123; // possibly remove eldest LinkedHashMap.Entry&lt;K,V&gt; first; if (evict &amp;&amp; (first = head) != null &amp;&amp; removeEldestEntry(first)) &#123; K key = first.key; // 作用显而易见，移除首节点 removeNode(hash(key), key, null, false, true); // 在HashMap中，这里不再解释 &#125;&#125;// 这个方法总是返回false，你可能会疑惑这个鬼东西是否有问题。// 其实这个方法是一个钩子方法，留给你自己来实现决定是否删除first(LRU算法实现)protected boolean removeEldestEntry(Map.Entry&lt;K,V&gt; eldest) &#123; return false;&#125;// 节点删除后断开链接void afterNodeRemoval(Node&lt;K,V&gt; e) &#123; // unlink LinkedHashMap.Entry&lt;K,V&gt; p = (LinkedHashMap.Entry&lt;K,V&gt;)e, b = p.before, a = p.after; p.before = p.after = null; if (b == null) head = a; else b.after = a; if (a == null) tail = b; else a.before = b;&#125; 2.4 获取方法了解了hashmap的getNode方法和上边的钩子方法，那么这里看起来就比较无脑了，没啥逻辑。 12345678910public V get(Object key) &#123; Node&lt;K,V&gt; e; // 调用hashmap的getNode获取entry if ((e = getNode(hash(key), key)) == null) return null; // 决定是否更新e到链尾 if (accessOrder) afterNodeAccess(e); return e.value;&#125; 2.5 移除方法移除方法更没营养，调用HashMap的remove方法时调用了一下afterNodeRemoval方法。 2.6 LRU缓存实现主要内容其实就是重写LinkedHashMap的removeEldestEntry方法，Mybatis也用LinkedHashMap实现LRU算法，也是这个套路，懂就行了 12345678910111213141516171819202122232425// 摘抄自石杉的LRU实现class LRUCache&lt;K, V&gt; extends LinkedHashMap&lt;K, V&gt; &#123; private final int CACHE_SIZE; /** * 传递进来最多能缓存多少数据 * * @param cacheSize 缓存大小 */ public LRUCache(int cacheSize) &#123; // true 表示让 linkedHashMap 按照访问顺序来进行排序，最近访问的放在头部，最老访问的放在尾部。 super((int) Math.ceil(cacheSize / 0.75) + 1, 0.75f, true); CACHE_SIZE = cacheSize; &#125; /** * 钩子方法，通过put新增键值对的时候，若该方法返回true * 便移除该map中最老的键和值 */ @Override protected boolean removeEldestEntry(Map.Entry&lt;K, V&gt; eldest) &#123; // 当 map中的数据量大于指定的缓存个数的时候，就自动删除最老的数据。 return size() &gt; CACHE_SIZE; &#125;&#125; 3. 总结总结好难，不总结了。]]></content>
      <tags>
        <tag>集合框架</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ThreadLocal源码]]></title>
    <url>%2F2020%2F04%2F11%2FThreadLocal%E6%BA%90%E7%A0%81%2F</url>
    <content type="text"><![CDATA[1. 属性ThreadLocal有三个属性threadLocalHashCode、nextHashCode、HASH_INCREMENT threadLocalHashCode属于对象的，每个ThreadLocal对象hashcode在初始化时确定且不可变 nextHashCode属性是静态的随着ThreadLocal类的加载而加载，分配一个AtomicInteger对象，用来以原子的方式获取最新的hashcode HASH_INCREMENT是下一个hashcode增长数，是一个静态常量 1234567891011121314public class ThreadLocal&lt;T&gt; &#123; // 每个ThreadLocal实例的hashcode(在对象被创建时赋值) private final int threadLocalHashCode = nextHashCode(); // 下一个要给出的hashcode private static AtomicInteger nextHashCode = new AtomicInteger(); // hash增长数 private static final int HASH_INCREMENT = 0x61c88647; // 返回下一个hash码 private static int nextHashCode() &#123; // 原子的方法更新值(调用unsafe操作) return nextHashCode.getAndAdd(HASH_INCREMENT); &#125;&#125; 2. 常用方法2.1 get()用来获取线程的私有变量，操作步骤如下： 获取当前线程的threadLocalMap属性，若初始化完成则进入步骤2，否则进行初始化 通过threadLocal去threadLocalMap获取对应entry，若无entiry则进行初始化 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public T get() &#123; // 获取当前线程 Thread t = Thread.currentThread(); // 获取当前线程中threadLocalMap ThreadLocalMap map = getMap(t); // 判断threadLocalMap有没有被初始化 if (map != null) &#123; // 获取entity ThreadLocalMap.Entry e = map.getEntry(this); // entity为null(可能发生内存泄漏，所以设置初始值) // 此时的引用链为Thread-&gt;ThreadLocalMap-&gt;Entry(null)-&gt;value if (e != null) &#123; @SuppressWarnings("unchecked") T result = (T)e.value; return result; &#125; &#125; // 初始化 return setInitialValue();&#125;// 获取线程t的threadLocalMapThreadLocalMap getMap(Thread t) &#123; return t.threadLocals;&#125;// 设置初始值private T setInitialValue() &#123; // 初始值(null) T value = initialValue(); // 获取当前线程 Thread t = Thread.currentThread(); // 获取ThreadLocalMap ThreadLocalMap map = getMap(t); if (map != null) // 放入map map.set(this, value); else // 创建map createMap(t, value); return value;&#125;// 初始化valueprotected T initialValue() &#123; return null;&#125; 2.2 set()set方法用来设置value到线程的threadLocalMap中 12345678910public void set(T value) &#123; // 获取当前线程 Thread t = Thread.currentThread(); // 获取ThreadLocalMap ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value);&#125; 2.3 remove()移除ThreadLocalmap中的value 12345public void remove() &#123; ThreadLocalMap m = getMap(Thread.currentThread()); if (m != null) m.remove(this);&#125; 3. 内部类ThreadLocalMapThreadLocalMap的结构如下图 3.1 为什么Entry要继承弱引用？Entry实现了对Key(也就是ThreadLocal)的弱引用。如果使用强引用，只要线程没有被销毁，ThreadLocal就一直是引用可达状态，永远无法被回收，程序不可知ThreadLocal是否可被清理。如果使用弱引用，当没有强引用链可达时，则活不过下一个GC，ThreadLocal会被回收 123456789101112131415161718192021222324252627282930313233343536373839404142static class ThreadLocalMap &#123; // 内部类Entry，实现了弱引用Key static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; &#123; /** The value associated with this ThreadLocal. */ Object value; Entry(ThreadLocal&lt;?&gt; k, Object v) &#123; super(k); value = v; &#125; &#125; // 静态常量：Table默认初始值 private static final int INITIAL_CAPACITY = 16; // Entry数组 private Entry[] table; // 初始大小 private int size = 0; // 阈值 private int threshold; // Default to 0 // 实际上Entry[]数组以一个环的形式存在 // 获取下一个下标 private static int nextIndex(int i, int len) &#123; return ((i + 1 &lt; len) ? i + 1 : 0); &#125; // 获取上一个下标 private static int prevIndex(int i, int len) &#123; return ((i - 1 &gt;= 0) ? i - 1 : len - 1); &#125; // 构造方法(懒加载，至少放入一个KV) ThreadLocalMap(ThreadLocal&lt;?&gt; firstKey, Object firstValue) &#123; table = new Entry[INITIAL_CAPACITY]; // 16 // 做与运算确定下标，和HashMap确定下标方式一样 int i = firstKey.threadLocalHashCode &amp; (INITIAL_CAPACITY - 1); // 构建entry放入table[i] table[i] = new Entry(firstKey, firstValue); // 设置ThreadLocalMap大小 size = 1; // 设置阈值 setThreshold(INITIAL_CAPACITY); &#125;&#125; 3.2 getEntity()方法获取ThreadLocalMap中的value，步骤如下： 若ThreadLocalMap对应下标处的entry存在且entry的key就是传入key，返回value，否则进入2 至此说明hash冲突或entry不存在，如果entry不存在，则返回null，否则进入3 从e开始线性探测向后查找不为null的entry，若命中则返回value，若发现失效entry则进行连续段清理 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475// 获取entry，被ThreadLocal的get方法调用private Entry getEntry(ThreadLocal&lt;?&gt; key) &#123; // 与运算获取到key对应下标 int i = key.threadLocalHashCode &amp; (table.length - 1); Entry e = table[i]; // 下标处entry存在 且 Entry的弱引用key没有失效 if (e != null &amp;&amp; e.get() == key) return e; else return getEntryAfterMiss(key, i, e);&#125; // 在getEntry()中未命中，使用本方法private Entry getEntryAfterMiss(ThreadLocal&lt;?&gt; key, int i, Entry e) &#123; Entry[] tab = table; int len = tab.length; // 基于线性探测法不断向后探测直至遇到空的Entry while (e != null) &#123; ThreadLocal&lt;?&gt; k = e.get(); // 命中 if (k == key) return e; if (k == null) // 弱引用key失效被回收，清理下标i无效的Entry expungeStaleEntry(i); else // 线性探测下一个位置 i = nextIndex(i, len); e = tab[i]; &#125; return null;&#125; // 清除staleSlot开始的陈旧条目(连续段的清理)private int expungeStaleEntry(int staleSlot) &#123; Entry[] tab = table; int len = tab.length; // 下标staleSlot的value引用断开，原entry的ThreadLocal已被回收，此时原value对象可被回收 tab[staleSlot].value = null; // 下标staleSlot出entry引用断开 tab[staleSlot] = null; size--; // Rehash until we encounter null Entry e; int i; for (i = nextIndex(staleSlot, len);(e = tab[i]) != null;i = nextIndex(i, len)) &#123; ThreadLocal&lt;?&gt; k = e.get(); if (k == null) &#123; // 对已回收的Entry进行清理操作 e.value = null; tab[i] = null; size--; &#125; else &#123; // rehash重新确定位置 int h = k.threadLocalHashCode &amp; (len - 1); /** * 重新取模后的h位置与原位置i不相等， * 则从h向后线性探测找到第一个空的位置，将tab[i]放入 */ if (h != i) &#123; tab[i] = null; // Unlike Knuth 6.4 Algorithm R, we must scan until // null because multiple entries could have been stale. while (tab[h] != null) h = nextIndex(h, len); tab[h] = e; &#125; &#125; &#125; // 返回staleSlot之后第一个空索引 return i;&#125; 3.3 set()方法设置ThreadLocalMap中的kv，步骤如下： 通过hash拿到下标，下标处为null，直接插入，否则进入2 下标处开始向后遍历，此时可能遇到三种情况： key值相等，直接替换value key失效，插入到此位置 是否需要rehash 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167private void set(ThreadLocal&lt;?&gt; key, Object value) &#123; Entry[] tab = table; int len = tab.length; // 获取key的下标 int i = key.threadLocalHashCode &amp; (len-1); /** * hash冲突，下标i位置存在Entry * 这时的Entry有两种状态： * Entry的ThreadLocal未被回收，若ThreadLocal为k直接放入value * Entry的ThreadLocal被回收，替换无效slot */ for (Entry e = tab[i];e != null;e = tab[i = nextIndex(i, len)]) &#123; ThreadLocal&lt;?&gt; k = e.get(); // 找到对应的Entry if (k == key) &#123; e.value = value; return; &#125; // Entry的ThreadLocal被回收，直接替换 if (k == null) &#123; replaceStaleEntry(key, value, i); return; &#125; &#125; // i下标处放入Entry tab[i] = new Entry(key, value); int sz = ++size; if (!cleanSomeSlots(i, sz) &amp;&amp; sz &gt;= threshold) rehash();&#125; // 替换陈旧条目private void replaceStaleEntry(ThreadLocal&lt;?&gt; key, Object value,int staleSlot) &#123; Entry[] tab = table; int len = tab.length; Entry e; // 向前遍历，找到第一个entry存在但key无效的slot int slotToExpunge = staleSlot; for (int i = prevIndex(staleSlot, len); (e = tab[i]) != null; i = prevIndex(i, len)) if (e.get() == null) slotToExpunge = i; // 向后遍历tab for (int i = nextIndex(staleSlot, len); (e = tab[i]) != null; i = nextIndex(i, len)) &#123; ThreadLocal&lt;?&gt; k = e.get(); // 找到对应key，与无效slot交换 if (k == key) &#123; e.value = value; tab[i] = tab[staleSlot]; tab[staleSlot] = e; // 确定清理点 if (slotToExpunge == staleSlot) slotToExpunge = i; // 做一次连续段清理，再做一次启发式清理 cleanSomeSlots(expungeStaleEntry(slotToExpunge), len); return; &#125; // 当前slot无效且向前扫描没有无效条目，更新slotToExpunge为当前位置 if (k == null &amp;&amp; slotToExpunge == staleSlot) slotToExpunge = i; &#125; // 若key在tab中不存在，直接插入 tab[staleSlot].value = null; tab[staleSlot] = new Entry(key, value); // 通过slotToExpunge判断是否存在无效条目，若存在，清除 if (slotToExpunge != staleSlot) cleanSomeSlots(expungeStaleEntry(slotToExpunge), len);&#125;/** * 启发式清理 * * @param i 永远为一个有效条目，从下一个索引开始判断 * @param n 扫描log2(n)个单元，除非找到无效slot * 插入方法调用时，此参数是元素数量 * replaceStaleEntry方法调用时，此参数是table长度 * @return 清理过任何无效slot，则返回true */private boolean cleanSomeSlots(int i, int n) &#123; boolean removed = false; Entry[] tab = table; int len = tab.length; do &#123; i = nextIndex(i, len); Entry e = tab[i]; // e为无效slot if (e != null &amp;&amp; e.get() == null) &#123; n = len; removed = true; // 清理连续段 i = expungeStaleEntry(i); &#125; &#125; while ( (n &gt;&gt;&gt;= 1) != 0); // 删除过任何无效slot，返回true return removed;&#125;private void rehash() &#123; // 做全量清理 expungeStaleEntries(); /** * 使用较低阈值判断是否需要扩容，上面做了清理，size可能会减小 * 这里用threshold的3/4来判断 */ if (size &gt;= threshold - threshold / 4) resize();&#125;// 清除表中所有过时条目private void expungeStaleEntries() &#123; Entry[] tab = table; int len = tab.length; for (int j = 0; j &lt; len; j++) &#123; Entry e = tab[j]; if (e != null &amp;&amp; e.get() == null) // entry为无效slot expungeStaleEntry(j); &#125;&#125;// 将table的容量加倍,对遍历过程中的无效entry直接断开valueprivate void resize() &#123; Entry[] oldTab = table; int oldLen = oldTab.length; int newLen = oldLen * 2; Entry[] newTab = new Entry[newLen]; int count = 0; // 遍历确定位置 for (int j = 0; j &lt; oldLen; ++j) &#123; Entry e = oldTab[j]; // 判断entry存在 if (e != null) &#123; ThreadLocal&lt;?&gt; k = e.get(); // 判断key是否有效 if (k == null) &#123; e.value = null; // Help the GC &#125; else &#123; int h = k.threadLocalHashCode &amp; (newLen - 1); // 冲突处理 while (newTab[h] != null) h = nextIndex(h, newLen); newTab[h] = e; count++; &#125; &#125; &#125; setThreshold(newLen); size = count; table = newTab;&#125; 3.4 remove()方法通过key移除entry 通过hash找到下标开始位置 向后遍历直至遇到null为止，判断key是否为传入的key，若是清理entry并调用连续段清理 1234567891011121314private void remove(ThreadLocal&lt;?&gt; key) &#123; Entry[] tab = table; int len = tab.length; int i = key.threadLocalHashCode &amp; (len-1); // 找到i开始向后查找，找到对应的entry，清理 for (Entry e = tab[i];e != null;e = tab[i = nextIndex(i, len)]) &#123; if (e.get() == key) &#123; e.clear(); // 清理 expungeStaleEntry(i); return; &#125; &#125;&#125; 4. ThreadLocal的常见问题？4.1 ThreadLocal为什么发生内存泄露？因为ThreadLocal被ThreadLocalMap的Entry以弱引用的方式做key，当发生GC时，ThreadLocal就会被回收，此时引用链为Thread-&gt;ThreadLocalMap-&gt;Entry(null)-&gt;Value，当线程无法结束(线程池场景，使用完后归还线程池)时，Value将不会被清理，发生内存泄露 解决：使用static修饰ThreadLocal变量，set()，get()使用完成之后手动调用remove()方法清除ThreadLocal 参考：ThreadLocal源码解读，散列表–线性探测法，ThreadLocal问题]]></content>
      <tags>
        <tag>多线程</tag>
        <tag>并发框架</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mybatis的缓存]]></title>
    <url>%2F2020%2F04%2F05%2FMybatis%E7%9A%84%E7%BC%93%E5%AD%98%2F</url>
    <content type="text"><![CDATA[缓存实现类Mybatis的缓存实现应用了装饰器模式，基础缓存为PerpetualCache，其余的缓存类都在装饰PerpetualCache来实现不同的功能，下面图是部分实现 1. PerpetualCache这个缓存比较简单，使用Map来达到缓存的目的。下边是他的源码，比较简单，只贴出了部分 123456public class PerpetualCache implements Cache &#123; // 缓存id private final String id; // 存储缓存内容 private final Map&lt;Object, Object&gt; cache = new HashMap&lt;&gt;();&#125; 2. 装饰器2.1 FifoCache先进先出式缓存，在PerpetualCache的基础上添加了一个队列集合来实现 插入缓存时： 将缓存的key放入到keyList中，检查keyList的长度是否越界(越界移除掉队列头元素，并移除delegate中的kv) 将kv插入到delegate中 12345678910111213141516171819202122232425262728293031323334public class FifoCache implements Cache &#123; // PerpetualCache private final Cache delegate; // 存放delegate中的key集合实现先进先出 private final Deque&lt;Object&gt; keyList; // keyList的大小 private int size; public FifoCache(Cache delegate) &#123; this.delegate = delegate; // 用LinkedList做队列使用 this.keyList = new LinkedList&lt;&gt;(); // 设置keyList的最大值为1024 this.size = 1024; &#125; // 添加缓存 public void putObject(Object key, Object value) &#123; cycleKeyList(key); delegate.putObject(key, value); &#125; // 对key的操作 private void cycleKeyList(Object key) &#123; // 添加到队列尾 keyList.addLast(key); if (keyList.size() &gt; size) &#123; // 若keyList的size超过最大容量时，移除队列头元素 Object oldestKey = keyList.removeFirst(); // 移除delegate中的key delegate.removeObject(oldestKey); &#125; &#125;&#125; 2.2 LruCache最近最少使用缓存，通过重写LinkedHashMap的removeEldestEntry()来实现 1234567891011121314151617181920212223242526272829303132333435363738394041424344public class LruCache implements Cache &#123; // PerpetualCache private final Cache delegate; // 用于维护最近最少使用key private Map&lt;Object, Object&gt; keyMap; // 需要移除的key(也就是最近最少使用的key) private Object eldestKey; public LruCache(Cache delegate) &#123; this.delegate = delegate; setSize(1024); &#125; public void setSize(final int size) &#123; // 维护LinkedHashMap的访问顺序，这里弄懂需要跟一下LinkedListMap的put源码 keyMap = new LinkedHashMap&lt;Object, Object&gt;(size, .75F, true) &#123; private static final long serialVersionUID = 4267176411845948333L; @Override protected boolean removeEldestEntry(Map.Entry&lt;Object, Object&gt; eldest) &#123; boolean tooBig = size() &gt; size; if (tooBig) &#123; // 当长度越界后，返回LinkedList的头结点的key eldestKey = eldest.getKey(); &#125; return tooBig; &#125; &#125;; &#125; public void putObject(Object key, Object value) &#123; delegate.putObject(key, value); cycleKeyList(key); &#125; private void cycleKeyList(Object key) &#123; // 将key存入keyMap keyMap.put(key, key); if (eldestKey != null) &#123; // delegate中移除eldestKey并将eldestKey置null delegate.removeObject(eldestKey); eldestKey = null; &#125; &#125;&#125; 2.3 BlockingCache阻塞式缓存，使用ReentrantLock来实现的，同一时刻只有一个线程可以key的缓存 线程A访问缓存时， 通过getObject()方法加锁，当缓存命中，返回值不为null(释放锁) 当缓存未命中，返回null(不释放锁)，mybatis查询数据库，将结果放入缓存(putObject()方法)，此时释放锁 线程A操作缓存时，线程B进入获取和A相同的key时，只能等待 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586public class BlockingCache implements Cache &#123; // 超时时间 private long timeout; // PerpetualCache private final Cache delegate; // 存储锁 private final ConcurrentHashMap&lt;Object, ReentrantLock&gt; locks; public BlockingCache(Cache delegate) &#123; this.delegate = delegate; this.locks = new ConcurrentHashMap&lt;&gt;(); &#125; public String getId() &#123; return delegate.getId(); &#125; public int getSize() &#123; return delegate.getSize(); &#125; public void putObject(Object key, Object value) &#123; try &#123; // 查询缓存 delegate.putObject(key, value); &#125; finally &#123; // 释放锁 releaseLock(key); &#125; &#125; public Object getObject(Object key) &#123; // 尝试加锁 acquireLock(key); Object value = delegate.getObject(key); if (value != null) &#123; // value不为null时才会释放锁 releaseLock(key); &#125; return value; &#125; public Object removeObject(Object key) &#123; // despite of its name, this method is called only to release locks releaseLock(key); return null; &#125; public void clear() &#123; delegate.clear(); &#125; private ReentrantLock getLockForKey(Object key) &#123; // 获取锁对象 return locks.computeIfAbsent(key, k -&gt; new ReentrantLock()); &#125; private void acquireLock(Object key) &#123; Lock lock = getLockForKey(key); if (timeout &gt; 0) &#123; try &#123; // 在timeout时间内尝试加锁 boolean acquired = lock.tryLock(timeout, TimeUnit.MILLISECONDS); if (!acquired) &#123; throw new CacheException("Couldn't get a lock in " + timeout + " for the key " + key + " at the cache " + delegate.getId()); &#125; &#125; catch (InterruptedException e) &#123; throw new CacheException("Got interrupted while trying to acquire lock for key " + key, e); &#125; &#125; else &#123; // 加锁 lock.lock(); &#125; &#125; private void releaseLock(Object key) &#123; ReentrantLock lock = locks.get(key); if (lock.isHeldByCurrentThread()) &#123; // 当锁被当前线程持有才会释放 lock.unlock(); &#125; &#125; public long getTimeout() &#123;return timeout;&#125; public void setTimeout(long timeout) &#123;this.timeout = timeout;&#125;&#125; CacheKeyCacheKey主要用来充当Mybatis一二级缓存(PerpetualCache存储)的key，value肯定为数据库的返回结果，这点毋容置疑。那么key的选择会麻烦一些，需要考虑到方法id、参数列表、是否分页、执行的SQL等因素。所以有了CacheKey 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108public class CacheKey implements Cloneable, Serializable &#123; private static final long serialVersionUID = 1146682552656046210L; public static final CacheKey NULL_CACHE_KEY = new CacheKey() &#123; public void update(Object object) &#123; throw new CacheException("Not allowed to update a null cache key instance."); &#125; public void updateAll(Object[] objects) &#123; throw new CacheException("Not allowed to update a null cache key instance."); &#125; &#125;; // 默认乘子 private static final int DEFAULT_MULTIPLIER = 37; // 默认hash private static final int DEFAULT_HASHCODE = 17; // 实际乘子 private final int multiplier; // 实际hash private int hashcode; // 校验和 private long checksum; // 影响因子个数 private int count; // 影响因子(像方法id，参数列表这些都是影响因子) private List&lt;Object&gt; updateList; public CacheKey() &#123; this.hashcode = 17; this.multiplier = 37; this.count = 0; this.updateList = new ArrayList(); &#125; public CacheKey(Object[] objects) &#123; this(); this.updateAll(objects); &#125; // 获取影响因子个数 public int getUpdateCount() &#123; return this.updateList.size(); &#125; // 更新操作(目的是为了hashcode更随机，因为这是需要作为map的key的) public void update(Object object) &#123; // 获取基础hashcode int baseHashCode = object == null ? 1 : ArrayUtil.hashCode(object); // count自增1 ++this.count; // 校验和更新 this.checksum += (long)baseHashCode; // 基础hash更新 baseHashCode *= this.count; // 实际hash更新 this.hashcode = this.multiplier * this.hashcode + baseHashCode; // 添加影响因子到列表 this.updateList.add(object); &#125; // 将objects逐一放入到udateList中 public void updateAll(Object[] objects) &#123; Object[] var2 = objects; int var3 = objects.length; for(int var4 = 0; var4 &lt; var3; ++var4) &#123; Object o = var2[var4]; this.update(o); &#125; &#125; // 因为要作为缓存的key，所以重写了hash和equals public boolean equals(Object object) &#123; if (this == object) &#123; // 比较内存地址 return true; &#125; else if (!(object instanceof CacheKey)) &#123; // 比较类型 return false; &#125; else &#123; CacheKey cacheKey = (CacheKey)object; if (this.hashcode != cacheKey.hashcode) &#123; // 比较hash return false; &#125; else if (this.checksum != cacheKey.checksum) &#123; // 比较校验和 return false; &#125; else if (this.count != cacheKey.count) &#123; // 比较影响因子个数 return false; &#125; else &#123; // 比较每个影响因子 for(int i = 0; i &lt; this.updateList.size(); ++i) &#123; Object thisObject = this.updateList.get(i); Object thatObject = cacheKey.updateList.get(i); if (!ArrayUtil.equals(thisObject, thatObject)) &#123; return false; &#125; &#125; return true; &#125; &#125; &#125; public int hashCode() &#123; return this.hashcode; &#125;&#125; 一级缓存Mybatis的一级缓存是使用PerpetualCache来做的，key为CacheKey，value为数据库返回的结果集。会在INSERT|UPDATE|DELETE、事务提交、回滚时清空 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128public abstract class BaseExecutor implements Executor &#123; // 一级缓存 protected PerpetualCache localCache; // 查询方法 public &lt;E&gt; List&lt;E&gt; query(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler) throws SQLException &#123; // 获取绑定SQL BoundSql boundSql = ms.getBoundSql(parameter); // 获取cacheKey CacheKey key = this.createCacheKey(ms, parameter, rowBounds, boundSql); // 调用重载，真正逻辑 return this.query(ms, parameter, rowBounds, resultHandler, key, boundSql); &#125; // 返回cacheKey对象 public CacheKey createCacheKey(MappedStatement ms, Object parameterObject, RowBounds rowBounds, BoundSql boundSql) &#123; if (this.closed) &#123; throw new ExecutorException("Executor was closed."); &#125; else &#123; CacheKey cacheKey = new CacheKey(); // 传入ms的id：com.xyn.mapper.Rolemapper.getRole cacheKey.update(ms.getId()); // 分页参数 cacheKey.update(rowBounds.getOffset()); cacheKey.update(rowBounds.getLimit()); // sql cacheKey.update(boundSql.getSql()); // 参数列表 List&lt;ParameterMapping&gt; parameterMappings = boundSql.getParameterMappings(); TypeHandlerRegistry typeHandlerRegistry = ms.getConfiguration().getTypeHandlerRegistry(); Iterator var8 = parameterMappings.iterator(); while(var8.hasNext()) &#123; ParameterMapping parameterMapping = (ParameterMapping)var8.next(); if (parameterMapping.getMode() != ParameterMode.OUT) &#123; String propertyName = parameterMapping.getProperty(); Object value; if (boundSql.hasAdditionalParameter(propertyName)) &#123; value = boundSql.getAdditionalParameter(propertyName); &#125; else if (parameterObject == null) &#123; value = null; &#125; else if (typeHandlerRegistry.hasTypeHandler(parameterObject.getClass())) &#123; value = parameterObject; &#125; else &#123; MetaObject metaObject = this.configuration.newMetaObject(parameterObject); value = metaObject.getValue(propertyName); &#125; // 传入运行时参数：#&#123;xx&#125; cacheKey.update(value); &#125; &#125; if (this.configuration.getEnvironment() != null) &#123; // 存在环境变量时传入环境变量 cacheKey.update(this.configuration.getEnvironment().getId()); &#125; return cacheKey; &#125; &#125; // 真正的查询业务逻辑 public &lt;E&gt; List&lt;E&gt; query(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, CacheKey key, BoundSql boundSql) throws SQLException &#123; ErrorContext.instance().resource(ms.getResource()).activity("executing a query").object(ms.getId()); if (this.closed) &#123; throw new ExecutorException("Executor was closed."); &#125; else &#123; // 若查询栈深度为1 且 ms是否清空缓存(根据ms类型决定,select类型为false,其余为true) if (this.queryStack == 0 &amp;&amp; ms.isFlushCacheRequired()) &#123; // 清空一级缓存 this.clearLocalCache(); &#125; List list; try &#123; // 栈深度自增 ++this.queryStack; // 从一级缓存中取，若为null，则去数据库查询 list = resultHandler == null ? (List)this.localCache.getObject(key) : null; if (list != null) &#123; // 存储过程逻辑 this.handleLocallyCachedOutputParameters(ms, key, parameter, boundSql); &#125; else &#123; // 从数据库中取 list = this.queryFromDatabase(ms, parameter, rowBounds, resultHandler, key, boundSql); &#125; &#125; finally &#123; // 栈深度自减 --this.queryStack; &#125; if (this.queryStack == 0) &#123; for (DeferredLoad deferredLoad : deferredLoads) &#123; deferredLoad.load(); &#125; // issue #601 deferredLoads.clear(); // 检查本地缓存使用范围，若为(STATEMENT)则清空localCache if (this.configuration.getLocalCacheScope() == LocalCacheScope.STATEMENT) &#123; this.clearLocalCache(); &#125; &#125; return list; &#125; &#125; // 从数据库查询 private &lt;E&gt; List&lt;E&gt; queryFromDatabase(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, CacheKey key, BoundSql boundSql) throws SQLException &#123; // TODO 插入占位符 没搞太懂这个操作 this.localCache.putObject(key, ExecutionPlaceholder.EXECUTION_PLACEHOLDER); List list; try &#123; list = this.doQuery(ms, parameter, rowBounds, resultHandler, boundSql); &#125; finally &#123; // 移除占位符 this.localCache.removeObject(key); &#125; // 查询结果放入到localCache中 this.localCache.putObject(key, list); if (ms.getStatementType() == StatementType.CALLABLE) &#123; // 若为存储过程，放入到localOutputParameterCache中 this.localOutputParameterCache.putObject(key, parameter); &#125; return list; &#125; 二级缓存TODO]]></content>
      <tags>
        <tag>Mybatis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机网络笔记]]></title>
    <url>%2F2020%2F03%2F24%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[第一章1.3 因特网的组成两种通信方式 客户端服务器方式(C/S方式)，Client/Server方式 就像我们Java开发的系统，部署一个网站，那个网站所在主机就是服务器。用户通过浏览器访问网站，浏览器就是客户端 对等方式(P2P方式)，Peer-toPeer方式 数据交换方式 电路交换：基本可以做到实时通信 电路交换的过程：建立连接–&gt;通信–&gt;关闭连接 适用场景：使用数据量很大的实时性传输 像我们打电话，就是电路交换。拨号等待就是建立连接的过程，对话就是通信，挂断就是关闭连接 分组交换：将数据分组传输 优点：高效，灵活，迅速，可靠 缺点：时延，开销 计算机就采用分组传输，不需要建立路径，只需要给分段数据加上目标头部即可 报文交换：不分组，直接加个目标首部传输，时延长，开销大 1.6 计算机性能 速率：连接在计算机网络上的主机在数字信道上传送数据位数的速率，也称比特率 单位：b/s，kb/s，Mb/s，Gb/s 我们手机下载软件看到的速度，就是在下载信道上的速率，xxkb/s，xMb/s这种， 带宽：数据通信领域，数字信道所传送的最高数据率(他和速率打配合，多条信道，最高带宽) 单位：b/s，kb/s，Mb/s，Gb/s 吞吐量：单位时间内通过某个网络的数据量 单位：b/s，Mb/s等 时延： 时延带宽积：传播时延*带宽 往返时间：从发送发发送数据开始，到发送方收到接收方确认 利用率：信道利用率和网络利用率组成 信道利用率：有数据通过时间/(有+无)数据通过时间 网络利用率：网络空闲时的时延/(1-信道利用率) 1.7 计算机网络体系结构OSI参考模型应用层–&gt;表示层–&gt;会话层–&gt;传输层–&gt;网络层–&gt;数据链路层–&gt;物理层 TCP/IP四层模型应用层–&gt;传输层–&gt;网络层–&gt;数据链路层 第五章5.3 传输层协议5.3.1 TCP协议概述 TCP是面向连接的传输层协议 每一天TCP协议连接只能有两个端点，每一条TCP连接只能是点对点的(一对一) TCP提供可靠交付的服务 TCP提供全双工通信 面向字节流 5.3.2 TCP连接 TCP把连接作为最基本的抽象 每一条TCP连接有两个端点 TCP连接的端点不是主机，不是主机的IP地址，不是应用进程，也不是运输层的协议端口。TCP 连接的端点叫做套接字(socket)或插口(是不是联想到了Java的Socket连接) 端口号拼接到IP地址即构成了套接字 套接字 套接字socket=(IP地址: 端口号) TCP连接= {socket1, socket2}={(IP1: port1), (IP2: port2)} 5.3.3 TCP协议实现可靠传输停止等待协议 情况(a)无差错情况，A发送M1，B收到并确认M1，A收到M1的确认并发送M2，直至完成 情况(b)超时重传，A发送M1，在M1到达B时数据包丢了，那么B肯定不会给A发送M1的确认。此时的A在一直等待M1的确认，在等待数据往返时间更多一点时间后，判定M1发送失败，重新发送M1，重复情况(a) 情况(a)确认丢失，A发送M1，在M1正确到达B，B发送M1的确认，但M1的确认丢失了，此时A在一直等待M1的确认，在等待数据往返时间更多一点时间后，判定M1发送失败，重新发送M1，这时B会收到重复的M1，丢弃重复的M1并给A发送M1的确认 情况(b)确认迟到，A发送M1，在M1正确到达B，B发送M1的确认，M1的确认由于某些原因迟到了。A在等待M1的确认，超过一定时间重新发送给M1，B收到重复的M1，丢弃重复的M1并发送M1的确认，开始AB正常的收发。但一段时间后A收到了迟到的M1的确认，但A什么也不做 流水线传输上面的停止等待协议会造成信道利用率低的问题，所以有了流水线传输 发送方可连续发送多个分组，不必每发完一个分组就停顿下来等待对方的确认 由于信道上一直有数据不间断地传送，这种传输方式可获得很高的信道利用率 连续ARQ协议ARQ：自动重传请求 用一个滑动窗口来发送请求，假设这个窗口可以存放5个数据，A一次发送5个，B收到1位置的数据，发送窗口滑动，而B如果全部收到的话，只需要发送5，就表示1-5的数据包全部收到了，此时会滑动5个位置 5.3.4 三次握手为什么是三次握手？ 第一次client告诉server，我要连接你，server被动打开了 第二次server回复client，哥准备好了，你来吧 第三次client，好嘞，我知道你好了 这里有个必问的问题，明明两次就可以建立连接，为什么还要第三次？ 5.3.5 四次挥手为什么是四次挥手？ 第七章7.1 对称加密7.2 非对称加密和数字签名7.3 证书颁发机构CA7.4 安全套接字SSL第七章就是讲的是https的原理 client请求server，server（server像CA机构获取公钥私钥）传输公钥给client，client通过SSL验证公钥合法性 client发送用公钥加密过的对称秘钥给server，server使用私钥解析获得对称秘钥，至此SSL功能完成 client和server开始使用对称秘钥进行通信]]></content>
      <tags>
        <tag>计算机网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis粗讲]]></title>
    <url>%2F2020%2F03%2F06%2FRedis%E7%B2%97%E8%AE%B2%2F</url>
    <content type="text"><![CDATA[1. Redis是什么？C语言开发的高性能键值对的内存数据库，可以用来做缓存、消息中间件、数据库(noSql)。 2. Redis都有哪些基本数据类型？ 类型 简介 特性 场景 string(字符串) 二进制存储 可以包含任何数据，图片或序列化对象 验证码、cookie、session存储 hash(字典) 相当于java中的map 适合存储对象，每次修改一个属性 修改对象的信息 list(列表) 双向链表 增删快 排行榜，消息队列(阻塞添加获取功能) set(集合) 元素不重复 增加、删除、查询时间复杂度为O(1)，做交集补集差集 共同好友 sorted set(有序集合) 为set中元素增加一个权重，元素按权重有序排列 数据插入集合时就根据权重进行了排序 排行榜、带权重的消息队列 bit(位图) 相当于一个数组 做用户签到，登录统计 hyperLogLog 数据统计不太准确 做网站的UV，PV geo(地理位置) 附近的人功能 3. 在项目里是如何使用Redis的？emmm，一般集成在springboot中使用，使用springboot的RedisTemplate或者StringRedisTemplate。 4. 使用缓存遇到的问题？ 缓存雪崩：同一时间大量key失效导致直接访问数据库。 解决：①固定失效时间+随机失效时间。②主备两个redis，备库的key过期时间较长 缓存穿透：一直访问数据库中不存在的key为缓存穿透。 解决：①接口层参数校验，用户鉴权等。②直接把key和value为null放入缓存，设置短一点的有效期。③布隆过滤器(分布式：redis布隆过滤器插件，单机：guava) 缓存击穿：热点key的过期为击穿。解决：设置热点key永不过期或互斥锁解决。 5. 过期策略定期删除+惰性删除 定期删除：每隔一段时间随机抽取设置过期时间的key，检测是否过期，过期就删除。 惰性删除：当访问到过期key是，删除过期key，不返回 6. 内存淘汰机制 过期策略 描述 volatile-lru 设置过期时间键值对中，最近最少未使用 allkeys-lru 所有键值对，最近最少未使用 volatile-lfu 设置过期时间键值对中，访问频率最少的淘汰 allkeys-lfu 所有键值对中，访问频率最少的淘汰 volatile-random 设置过期时间键值对中，随机淘汰 allkeys-random 所有键值对中，随机淘汰 volatile-ttl 设置过期时间键值对中，剩余时间短的淘汰 noeviction 从不淘汰，内存不足时报错 7. 持久化redis提供两种持久化方案，RDB和AOF。 RDB：在指定时间间隔对数据进行快照存储。 优点： 保存某个时间点的数据集，适合做数据备份。 保存RDB时，父进程fork一个子进程进行RDB的写入，父进程只需对数据进行关注，性能较高。 恢复大的数据集是，RDB相比AOF会更快一些。 缺点： 在redis宕机时，可能会丢失几分钟的数据。 大数据量情况下，对RDB备份会对性能有一些影响。 AOF：每次写入都会将命令追加进aof文件。 优点： AOF相比RDB使redis更加耐久，默认策略每秒fsync，当redis宕机最多丢失1秒数据。 redis可以在aof文件体积过大时重写aof文件，只写入执行内存中数据最少命令。 AOF文件可以被非常简单可读，当不小心执行flushall(删库)命令时，只要AOF文件未被重写，那么找到AOF文件，删掉flushall命令，重启redis即可挽回。 缺点： 对相同数据集，AOF文件体积大于RDB文件。 不同fsync策略会影响AOF的速度，不过在响应方面会低于RDB。 如何使用两种持久化方式？看数据丢失的承受性，可单用，可混合使用，一般情况混合使用。 8. 高可用主从复制+哨兵 哨兵(Sentinel)作用？ 监控：Sentinel 会不断地检查你的主服务器和从服务器是否运作正常。 提醒：当被监控的某个Redis服务器出现问题时，Sentinel可以通过API向管理员或者其他应用程序发送通知。 自动故障迁移：当一个主服务器不能正常工作时，Sentinel 会开始一次自动故障迁移操作，它会将失效主服务器的其中一个从服务器升级为新的主服务器，并让失效主服务器的其他从服务器改为复制新的主服务器；当客户端试图连接失效的主服务器时，集群也会向客户端返回新主服务器的地址，使得集群可以使用新主服务器代替失效服务器。 redis cluster 参考：http://www.redis.cn/]]></content>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HashMap源码(JDK1.8)]]></title>
    <url>%2F2020%2F03%2F02%2FHashMap%E6%BA%90%E7%A0%81(JDK8)%2F</url>
    <content type="text"><![CDATA[1.概述HashMap是我们常用的集合类，以K-V形式的键值对来存储数据，散列算法实现，不保证键值对的顺序存储。 2.数据结构HashMap底层使用数组+链表+红黑树来存储数据，根据Key的hashCode扰动处理后得到的hash，通过(n - 1) &amp; hash确定位置，然后插入到链表或红黑树中(搞不懂可以继续往下看，用到的时候再说)。 HashMap使用内部类Node和TreeNode来存储数据，还有一些重要的属性，都在下面代码中。 123456789101112131415161718192021222324252627282930313233/** Node数组 */transient Node&lt;K,V&gt;[] table;/** K-V键值对数量 */transient int size;/** 下次扩容时的阈值 */int threshold; /** 负载因子 */final float loadFactor;/** 默认初始容量，必须为2的幂 */static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; /** 默认负载因子 */static final float DEFAULT_LOAD_FACTOR = 0.75f;/** 链表转化红黑树阈值 */static final int TREEIFY_THRESHOLD = 8;/** 红黑树退化链表阈值 */static final int UNTREEIFY_THRESHOLD = 6;/** 链表节点，实现Map.Entry */static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; // 扰动后的hash final K key; // key V value; // value Node&lt;K,V&gt; next; // nextNode&#125;/** 红黑树节点 */static final class TreeNode&lt;K,V&gt; extends LinkedHashMap.Entry&lt;K,V&gt; &#123; TreeNode&lt;K,V&gt; parent; TreeNode&lt;K,V&gt; left; TreeNode&lt;K,V&gt; right; TreeNode&lt;K,V&gt; prev; boolean red;&#125; 上面代码中比较重要的属性有两个： loadFactor：负载因子，取值在0-1之间。越接近1存放的数据越多，数据分布越密集、越接近0存放数据越少，数据分布稀疏。官方默认0.75f，可在构造时指定。 threshold：扩容阈值，容量*负载因子。 3.源码分析3.1构造方法HashMap有四个构造方法，无参依旧是经典选择，当然知晓需存储元素数量的情况下，依旧推荐指定容量。 1234567891011121314151617181920212223242526272829303132333435363738394041public HashMap() &#123; // 定义负载因子 this.loadFactor = DEFAULT_LOAD_FACTOR;&#125;/** 指定初始容量 */public HashMap(int initialCapacity) &#123; // 调用重载的构造方法 this(initialCapacity, DEFAULT_LOAD_FACTOR);&#125;/** 指定初始容量和负载因子 */public HashMap(int initialCapacity, float loadFactor) &#123; if (initialCapacity &lt; 0) throw new IllegalArgumentException("Illegal initial capacity: " + initialCapacity); if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException("Illegal load factor: " + loadFactor); this.loadFactor = loadFactor; this.threshold = tableSizeFor(initialCapacity);&#125;/** 传入实现map的子类 */public HashMap(Map&lt;? extends K, ? extends V&gt; m) &#123; this.loadFactor = DEFAULT_LOAD_FACTOR; putMapEntries(m, false);&#125;/** 返回大于cap的最合适的2^n */static final int tableSizeFor(int cap) &#123; int n = cap - 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;&#125; 关于tableSizeFor(int cap)这个算法非常的巧妙，它可以找到最合适的2^n返回。假设传入的cap为11，n=10 n |= n &gt;&gt;&gt; 1，等价于n或n&gt;&gt;&gt;1(无符号右移一位)，1010 | 0101 = 1111 就为15 n |= n &gt;&gt;&gt; 2，同上操作 最后会得出合适的2^n，也就是16。 3.2插入将指定键值对相关联插入Map，若存在则替换Value。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162/** * 集合的添加，也就是数组的尾部插入 */public V put(K key, V value) &#123; return putVal(hash(key), key, value, false, true);&#125;final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; // 判断table是否需要进行扩容 if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; // 判断指定位置是否存在元素 if ((p = tab[i = (n - 1) &amp; hash]) == null) // 创建新节点 tab[i] = newNode(hash, key, value, null); else &#123; Node&lt;K,V&gt; e; K k; // 判断是否需要替换Value if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; else if (p instanceof TreeNode) // 属于红黑树节点，插入红黑树 e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else &#123; // 属于链表节点，找出尾节点，插入 for (int binCount = 0; ; ++binCount) &#123; // 是否尾节点 if ((e = p.next) == null) &#123; // 插入原尾节点之后 p.next = newNode(hash, key, value, null); // 判断链表长度是否达到转换红黑树阈值 if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; // 判断链表中是否有相同的Key if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; // 替换键值对的Value if (e != null) &#123; V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; // LinkedHashMap覆盖方法 afterNodeAccess(e); return oldValue; &#125; &#125; ++modCount; // 更新size并判断是否需要扩容 if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null;&#125; 对于元素的添加，有一下两种情况： 元素不存在，判断插入红黑树还是插入链表 元素存在，判断为红黑树节点，还是链表节点，替换Value 图有点问题，转换红黑树那里应该是 数组扩容或链表转化为红黑树 3.3获取键值对Value的获取相对put简单。 12345678910111213141516171819202122232425262728293031/** * 返回指定键值对的Value，若不存在返回null */ public V get(Object key) &#123; Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value;&#125;final Node&lt;K,V&gt; getNode(int hash, Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; // 判断table为null或长度为0或hash对应下标处为null if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) &#123; if (first.hash == hash &amp;&amp; // always check first node // 首节点为key，返回first ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; if ((e = first.next) != null) &#123; if (first instanceof TreeNode) // 红黑树节点 return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); // 链表节点 do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; while ((e = e.next) != null); &#125; &#125; return null;&#125; 3.4扩容HashMap的扩容需要进行rehash和元素遍历，非常耗时，应尽量避免 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596final Node&lt;K,V&gt;[] resize() &#123; Node&lt;K,V&gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; // 1.第一个判断，设置容量和阈值 if (oldCap &gt; 0) &#123; // 旧容量&gt;=MAXIMUM_CAPACITY，扩容不做处理，去碰撞吧，管不了 if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return oldTab; &#125; else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) // 新容量=旧容量*2，新扩容阈值=旧扩容阈值*2 newThr = oldThr &lt;&lt; 1; // double threshold &#125; else if (oldThr &gt; 0) // initial capacity was placed in threshold // 新容量=旧扩容阈值 newCap = oldThr; else &#123; // zero initial threshold signifies using defaults // 新容量=16 newCap = DEFAULT_INITIAL_CAPACITY; // 新扩容阈值=0.75f*16 newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; // 2.设置扩容阈值 if (newThr == 0) &#123; // 扩容阈值=容量*负载因子 float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; threshold = newThr; @SuppressWarnings(&#123;"rawtypes","unchecked"&#125;) // 创建新Node数组 Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; if (oldTab != null) &#123; // 遍历并将旧数组元素拷贝到新数组 for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) &#123; // oldTab[j]元素不为null oldTab[j] = null; if (e.next == null) // oldTab[j]上只有一个Node newTab[e.hash &amp; (newCap - 1)] = e; else if (e instanceof TreeNode) // e是红黑树节点，转为红黑树处理 ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else &#123; // preserve order /** * oldTab[j]元素是一个链表 * 链表可能会分裂为两个链表，lo存放第一个链表的首尾，hi存放第二个链表的首尾 */ Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do &#123; next = e.next; // 判断rehash后应在第一个链表上还是第二个链表上 if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); // 链表拆解完成，放入newTab对应位置 if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; if (hiTail != null) &#123; hiTail.next = null; // 新链表位置为j+oldCap newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab;&#125; 对于上面红黑树的扩容我也没搞太懂……就不拿出来显了，链表的扩容可能有点难以理解，为什么会分裂成两个链表，这里画个图，所以原位置上的key可能会拷贝到oldCap+j位置上。 4. 面试介绍的时候主要介绍 数据结构：数组+链表+红黑树 插入时的流程 扩容时的流程 5. 总结Hashmap可学习的点非常多，建议自己去jdk中找源码看一看。面试可以通过HashMap扩展到ConcurrentHashmap然后再扩展到juc的集合工具类，可讲的点非常多，非常考察个人能力。]]></content>
      <tags>
        <tag>集合框架</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LinkedList源码]]></title>
    <url>%2F2020%2F02%2F29%2FLinkedList%E6%BA%90%E7%A0%81%2F</url>
    <content type="text"><![CDATA[1. 概述LinkedList是长度可变的集合，基于链表来实现，和ArrayList都具有存储重复元素和空值的特点。因为基于链表实现，所以并不像数组那样需要连续的内存空间来存储元素，且在首尾插入元素的效率较高，时间复杂度为O(1)，但因为结构的问题，导致查询较慢，时间复杂度为O(n)。 2. 继承关系下图是LinkedList的继承体系(阉割版)，实现了Deque、List接口，继承AbstractSequentialList，Deque其实是一个双向链表接口，而AbstractSequentialList则提供的顺序访问方法。可以得知LinkedList是一个可存重、顺序访问的双向链表。 LinkedList可以顺序访问其实是重写了AbstractSequentialList的ListIterator方法，本质上就是通过迭代器来拿到指定位置元素 123456789101112131415161718AbstractSequentialList.classpublic abstract ListIterator&lt;E&gt; listIterator(int index);LinkedList.classpublic ListIterator&lt;E&gt; listIterator(int index) &#123; checkPositionIndex(index); return new ListItr(index);&#125;private class ListItr implements ListIterator&lt;E&gt; &#123; ListItr(int index) &#123; /** * next指向取出node(index) * node遍历列表来取出指定索引出的Node */ next = (index == size) ? null : node(index); nextIndex = index; &#125;&#125; 3. 源码分析3.1 构造方法LinkedList有两个构造方法，一个无参一个有参。常用的肯定是无参构造，有参构造很少使用。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778transient Node&lt;E&gt; first; // 首节点transient Node&lt;E&gt; last; // 尾节点transient int size = 0;private static class Node&lt;E&gt; &#123; E item; Node&lt;E&gt; next; Node&lt;E&gt; prev; Node(Node&lt;E&gt; prev, E element, Node&lt;E&gt; next) &#123; this.item = element; this.next = next; this.prev = prev; &#125;&#125;/** 无参构造 */public LinkedList() &#123;&#125;/** 构建一个指定集合元素的列表 */public LinkedList(Collection&lt;? extends E&gt; c) &#123; this(); addAll(c);&#125;public boolean addAll(Collection&lt;? extends E&gt; c) &#123; return addAll(size, c);&#125;public boolean addAll(int index, Collection&lt;? extends E&gt; c) &#123; checkPositionIndex(index); Object[] a = c.toArray(); int numNew = a.length; if (numNew == 0) return false; // pred前驱节点，succ后继节点 Node&lt;E&gt; pred, succ; if (index == size) &#123; succ = null; pred = last; &#125; else &#123; succ = node(index); pred = succ.prev; &#125; // 将数组a的元素转换为节点 for (Object o : a) &#123; @SuppressWarnings("unchecked") E e = (E) o; Node&lt;E&gt; newNode = new Node&lt;&gt;(pred, e, null); /** * 判断前驱节点是否为null * null：这个是空列表，将first指向自己 * 非null：这不是空列表，将pred的next节点指向自己 */ if (pred == null) first = newNode; else pred.next = newNode; // 将pred指向新节点 pred = newNode; &#125; /** * 判断succ是否为null * null：这个是空列表，将last指向pred，也就是a的最后一个元素转换成节点 * 非null：这不是空列表，更新pred的后继和succ的前驱 */ if (succ == null) &#123; last = pred; &#125; else &#123; pred.next = succ; succ.prev = pred; &#125; // 更新size size += numNew; modCount++; return true;&#125; 3.2 插入元素的插入也是有两种方式，一种是从尾部插入，另一种是插入指定位置。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546/** 集合的添加 */ public boolean add(E e) &#123; linkLast(e); return true;&#125;/** 插入到指定位置 */ public void add(int index, E element) &#123; checkPositionIndex(index); if (index == size) linkLast(element); else linkBefore(element, node(index));&#125;/** 插入到链尾 */ void linkLast(E e) &#123; final Node&lt;E&gt; l = last; final Node&lt;E&gt; newNode = new Node&lt;&gt;(l, e, null); last = newNode; if (l == null) first = newNode; else l.next = newNode; size++; modCount++;&#125;/** 插入到指定位置 */void linkBefore(E e, Node&lt;E&gt; succ) &#123; // assert succ != null; /** * 1.取出succ的前驱pred * 2.构建新节点newNode * 3.更新原来的前驱节点和后继节点与newNode的关系 */ final Node&lt;E&gt; pred = succ.prev; final Node&lt;E&gt; newNode = new Node&lt;&gt;(pred, e, succ); succ.prev = newNode; if (pred == null) first = newNode; else pred.next = newNode; size++; modCount++;&#125; 添加到集合尾部，时间复杂度O(1) 添加到指定位置，时间复杂度为O(1)，不过遍历寻址的时间复杂度为O(n) 3.3 删除对于元素的删除，和ArrayList相同，LinkedList提供了两种删除方式，指定位置元素的删除，元素的删除。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172/** 删除index位置元素 */ public E remove(int index) &#123; checkElementIndex(index); return unlink(node(index));&#125;/** 返回指定索引出的节点 */ Node&lt;E&gt; node(int index) &#123; // assert isElementIndex(index); // 通过index和size决定首节点或尾节点开始遍历 if (index &lt; (size &gt;&gt; 1)) &#123; Node&lt;E&gt; x = first; for (int i = 0; i &lt; index; i++) x = x.next; return x; &#125; else &#123; Node&lt;E&gt; x = last; for (int i = size - 1; i &gt; index; i--) x = x.prev; return x; &#125;&#125;/** 取消链表节点的x */E unlink(Node&lt;E&gt; x) &#123; // assert x != null; final E element = x.item; final Node&lt;E&gt; next = x.next; final Node&lt;E&gt; prev = x.prev; // 建立前驱节点与后继节点的关联，这里注意首尾节点问题 if (prev == null) &#123; first = next; &#125; else &#123; prev.next = next; x.prev = null; &#125; if (next == null) &#123; last = prev; &#125; else &#123; next.prev = prev; x.next = null; &#125; x.item = null; size--; modCount++; return element;&#125;/** * 删除对象o */ public boolean remove(Object o) &#123; if (o == null) &#123; for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123; if (x.item == null) &#123; unlink(x); return true; &#125; &#125; &#125; else &#123; for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123; if (o.equals(x.item)) &#123; unlink(x); return true; &#125; &#125; &#125; return false;&#125; 链表元素的删除比较简单，主要就是对删除元素相关联的前驱后继关系的操作，大致步骤如下 更新前驱节点 更新后继节点 更新size 3.4 遍历遍历方式和ArrayList一样，不过因为自身结构问题，遍历一直是LinkedList的性能短板。 1234567891011121314151617181920212223242526public static void main(String[] args) &#123; List&lt;Integer&gt; list = new LinkedList(); for (int i = 0; i &lt; list.size(); i++) &#123; System.out.println(list.get(i)); &#125;&#125;public static void main(String[] args) &#123; List&lt;Integer&gt; list = new LinkedList(); for (Integer val : list) &#123; System.out.println(val); &#125;&#125;public static void main(String[] args) &#123; List&lt;Integer&gt; list = new LinkedList(); Iterator&lt;Integer&gt; iterator = list.iterator(); while (iterator.hasNext())&#123; System.out.println(iterator.next()); &#125;&#125;public static void main(String[] args) &#123; List&lt;Integer&gt; list = new LinkedList(); list.forEach(System.out::println);&#125; 4. 面试介绍时可以从以下几个方面讲解LinkedList 线程安全方面 底层数据结构 插入删除元素与位置的影响 内存空间占用 效率，使用场景 5. 总结没啥总结，链表的结构记住就行。。。]]></content>
      <tags>
        <tag>集合框架</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ArrayList源码]]></title>
    <url>%2F2020%2F02%2F25%2FArrayList%E6%BA%90%E7%A0%81%2F</url>
    <content type="text"><![CDATA[1. 概述ArrayList是长度可变的集合，基于定长数组来实现的，且可以存储重复元素和空值。当插入元素个数大于数组长度时，就需要进行扩容(其实就是创建一个更长的新数组)。因为底层基于数组实现，所以随机查找的时间复杂度为O(1)。 2. 源码分析2.1 构造方法ArrayList有三个构造方法，一个无参两个有参，其中常用的为无参构造，推荐在知晓存储元素数量的情况下，使用有参构造ArrayList(int initialCapacity)，好处是避免数组扩容带来的额外开销。 1234567891011121314151617181920212223242526272829303132private static final int DEFAULT_CAPACITY = 10;private static final Object[] EMPTY_ELEMENTDATA = &#123;&#125;;private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = &#123;&#125;;transient Object[] elementData; // non-private to simplify nested class accessprivate int size;public ArrayList() &#123; // 将elementData初始化为空数组 this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA;&#125;public ArrayList(int initialCapacity) &#123; // 根据initialCapacity初始化elementData if (initialCapacity &gt; 0) &#123; this.elementData = new Object[initialCapacity]; &#125; else if (initialCapacity == 0) &#123; this.elementData = EMPTY_ELEMENTDATA; &#125; else &#123; throw new IllegalArgumentException("Illegal Capacity: "+ initialCapacity); &#125;&#125;public ArrayList(Collection&lt;? extends E&gt; c) &#123; elementData = c.toArray(); if ((size = elementData.length) != 0) &#123; if (elementData.getClass() != Object[].class) elementData = Arrays.copyOf(elementData, size, Object[].class); &#125; else &#123; this.elementData = EMPTY_ELEMENTDATA; &#125;&#125; 三个构造方法其实都是对elementData进行初始化的操作，ArrayList(Collection&lt;? extends E&gt; c)的作用是把Collection类型的元素全部添加到ArrayList中，平常开发中不常用到。 2.2 插入数组元素的插入有两种方式，一种是从尾部插入，另一种是从任意指定位置插入 12345678910111213141516171819202122232425262728/** * 集合的添加，也就是数组的尾部插入 */ public boolean add(E e) &#123; // 容量检查 ensureCapacityInternal(size + 1); /** * 1. size元素赋值e， * 2. size++ */ elementData[size++] = e; return true;&#125;/** * 将element插入到index位置，指定位置插入 */ public void add(int index, E element) &#123; rangeCheckForAdd(index); ensureCapacityInternal(size + 1); // Increments modCount!! // 指定位置插入，需要将从索引index开始的元素都后移一位，如果数据量大的话会比较耗时 System.arraycopy(elementData, index, elementData, index + 1, size - index); // 新元素插入index位置 elementData[index] = element; size++;&#125; 以上就是元素的两种添加方式，对添加操作而言，基本只有三个过程： 容量检查，判断是否需要扩容 元素插入 size++ 添加到集合尾部，时间复杂度O(1) 添加到指定位置，时间复杂度为O(n) 2.3 删除对于元素的删除，ArrayList提供了两种删除方式，指定位置元素的删除，元素的删除。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152/** * 删除index位置元素 */ public E remove(int index) &#123; rangeCheck(index); modCount++; // 获取index位置元素 E oldValue = elementData(index); // 元素移动长度 int numMoved = size - index - 1; if (numMoved &gt; 0) System.arraycopy(elementData, index+1, elementData, index, numMoved); // 数组尾元素置null elementData[--size] = null; // clear to let GC do its work return oldValue;&#125;/** * 删除对象o */ public boolean remove(Object o) &#123; if (o == null) &#123; for (int index = 0; index &lt; size; index++) if (elementData[index] == null) &#123; fastRemove(index); return true; &#125; &#125; else &#123; for (int index = 0; index &lt; size; index++) if (o.equals(elementData[index])) &#123; fastRemove(index); return true; &#125; &#125; return false;&#125;/** * 快速删除，跳过边界检查，不返回删除元素 */ private void fastRemove(int index) &#123; modCount++; int numMoved = size - index - 1; if (numMoved &gt; 0) System.arraycopy(elementData, index+1, elementData, index, numMoved); elementData[--size] = null; // clear to let GC do its work&#125; 集合元素的删除比较简单，基本和添加操作大同小异，大致过程如下： 取出index位置元素 index+1开始的元素，前移一位 size– 2.4 扩容机制数组是定长的，如果数据元素一致增加的话，会面临容量问题需要进行扩容(其实就是换一个更大的数组) 12345678910111213141516171819202122232425262728private void ensureCapacityInternal(int minCapacity) &#123; if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) &#123; minCapacity = Math.max(DEFAULT_CAPACITY, minCapacity); &#125; ensureExplicitCapacity(minCapacity);&#125;private void ensureExplicitCapacity(int minCapacity) &#123; modCount++; // minCapacity &gt; elementData.length则需要进行扩容 if (minCapacity - elementData.length &gt; 0) grow(minCapacity);&#125;private void grow(int minCapacity) &#123; // overflow-conscious code int oldCapacity = elementData.length; // 新容量为旧容量的1.5倍 int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); // 将原数组的元素拷贝到新数组，时间复杂度O(n) elementData = Arrays.copyOf(elementData, newCapacity);&#125; 因为数组的扩容涉及到数组的拷贝，时间复杂度O(n)，所以知晓元素数量情况下应设置容量。 2.5 遍历下面是 ArrayList 的几种迭代方式，推荐第一种方式，因为ArrayList实现了RandomAccess(随机访问的标志接口)，又因为底层是数组存储，取值的时间复杂度为O(1)，其余都是转化为迭代器进行遍历。 1234567891011121314151617181920212223242526public static void main(String[] args) &#123; List&lt;Integer&gt; list = new ArrayList(10); for (int i = 0; i &lt; list.size(); i++) &#123; System.out.println(list.get(i)); &#125;&#125;public static void main(String[] args) &#123; List&lt;Integer&gt; list = new ArrayList(10); for (Integer val : list) &#123; System.out.println(val); &#125;&#125;public static void main(String[] args) &#123; List&lt;Integer&gt; list = new ArrayList(10); Iterator&lt;Integer&gt; iterator = list.iterator(); while (iterator.hasNext())&#123; System.out.println(iterator.next()); &#125;&#125;public static void main(String[] args) &#123; List&lt;Integer&gt; list = new ArrayList(10); list.forEach(System.out::println);&#125; 3. 面试介绍时可以从以下几个方面讲解ArrayList 线程安全方面 底层数据结构 插入删除元素与位置的影响 内存空间占用 效率，使用场景 4. 总结ArrayList比较简单，源码基本可以很轻松地看懂，建议去自己翻阅一遍。 田小波-ArrayList源码分析]]></content>
      <tags>
        <tag>集合框架</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis.conf参数]]></title>
    <url>%2F2020%2F01%2F01%2Fredis-conf%E5%8F%82%E6%95%B0%2F</url>
    <content type="text"><![CDATA[12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273参数说明redis.conf 配置项说明如下：1. Redis默认不是以守护进程的方式运行，可以通过该配置项修改，使用yes启用守护进程 daemonize no2. 当Redis以守护进程方式运行时，Redis默认会把pid写入/var/run/redis.pid文件，可以通过pidfile指定 pidfile /var/run/redis.pid3. 指定Redis监听端口，默认端口为6379，作者在自己的一篇博文中解释了为什么选用6379作为默认端口，因为6379在手机按键上MERZ对应的号码，而MERZ取自意大利歌女Alessia Merz的名字 port 63794. 绑定的主机地址 bind 127.0.0.15.当 客户端闲置多长时间后关闭连接，如果指定为0，表示关闭该功能 timeout 3006. 指定日志记录级别，Redis总共支持四个级别：debug、verbose、notice、warning，默认为verbose loglevel verbose7. 日志记录方式，默认为标准输出，如果配置Redis为守护进程方式运行，而这里又配置为日志记录方式为标准输出，则日志将会发送给/dev/null logfile stdout8. 设置数据库的数量，默认数据库为0，可以使用SELECT &lt;dbid&gt;命令在连接上指定数据库id databases 169. 指定在多长时间内，有多少次更新操作，就将数据同步到数据文件，可以多个条件配合 save &lt;seconds&gt; &lt;changes&gt; Redis默认配置文件中提供了三个条件： save 900 1 save 300 10 save 60 10000 分别表示900秒（15分钟）内有1个更改，300秒（5分钟）内有10个更改以及60秒内有10000个更改。 10. 指定存储至本地数据库时是否压缩数据，默认为yes，Redis采用LZF压缩，如果为了节省CPU时间，可以关闭该选项，但会导致数据库文件变的巨大 rdbcompression yes11. 指定本地数据库文件名，默认值为dump.rdb dbfilename dump.rdb12. 指定本地数据库存放目录 dir ./13. 设置当本机为slav服务时，设置master服务的IP地址及端口，在Redis启动时，它会自动从master进行数据同步 slaveof &lt;masterip&gt; &lt;masterport&gt;14. 当master服务设置了密码保护时，slav服务连接master的密码 masterauth &lt;master-password&gt;15. 设置Redis连接密码，如果配置了连接密码，客户端在连接Redis时需要通过AUTH &lt;password&gt;命令提供密码，默认关闭 requirepass foobared16. 设置同一时间最大客户端连接数，默认无限制，Redis可以同时打开的客户端连接数为Redis进程可以打开的最大文件描述符数，如果设置 maxclients 0，表示不作限制。当客户端连接数到达限制时，Redis会关闭新的连接并向客户端返回max number of clients reached错误信息 maxclients 12817. 指定Redis最大内存限制，Redis在启动时会把数据加载到内存中，达到最大内存后，Redis会先尝试清除已到期或即将到期的Key，当此方法处理 后，仍然到达最大内存设置，将无法再进行写入操作，但仍然可以进行读取操作。Redis新的vm机制，会把Key存放内存，Value会存放在swap区 maxmemory &lt;bytes&gt;18. 指定是否在每次更新操作后进行日志记录，Redis在默认情况下是异步的把数据写入磁盘，如果不开启，可能会在断电时导致一段时间内的数据丢失。因为 redis本身同步数据文件是按上面save条件来同步的，所以有的数据会在一段时间内只存在于内存中。默认为no appendonly no19. 指定更新日志文件名，默认为appendonly.aof appendfilename appendonly.aof20. 指定更新日志条件，共有3个可选值： no：表示等操作系统进行数据缓存同步到磁盘（快） always：表示每次更新操作后手动调用fsync()将数据写到磁盘（慢，安全） everysec：表示每秒同步一次（折衷，默认值） appendfsync everysec 21. 指定是否启用虚拟内存机制，默认值为no，简单的介绍一下，VM机制将数据分页存放，由Redis将访问量较少的页即冷数据swap到磁盘上，访问多的页面由磁盘自动换出到内存中（在后面的文章我会仔细分析Redis的VM机制） vm-enabled no22. 虚拟内存文件路径，默认值为/tmp/redis.swap，不可多个Redis实例共享 vm-swap-file /tmp/redis.swap23. 将所有大于vm-max-memory的数据存入虚拟内存,无论vm-max-memory设置多小,所有索引数据都是内存存储的(Redis的索引数据 就是keys),也就是说,当vm-max-memory设置为0的时候,其实是所有value都存在于磁盘。默认值为0 vm-max-memory 024. Redis swap文件分成了很多的page，一个对象可以保存在多个page上面，但一个page上不能被多个对象共享，vm-page-size是要根据存储的 数据大小来设定的，作者建议如果存储很多小对象，page大小最好设置为32或者64bytes；如果存储很大大对象，则可以使用更大的page，如果不 确定，就使用默认值 vm-page-size 3225. 设置swap文件中的page数量，由于页表（一种表示页面空闲或使用的bitmap）是在放在内存中的，，在磁盘上每8个pages将消耗1byte的内存。 vm-pages 13421772826. 设置访问swap文件的线程数,最好不要超过机器的核数,如果设置为0,那么所有对swap文件的操作都是串行的，可能会造成比较长时间的延迟。默认值为4 vm-max-threads 427. 设置在向客户端应答时，是否把较小的包合并为一个包发送，默认为开启 glueoutputbuf yes28. 指定在超过一定的数量或者最大的元素超过某一临界值时，采用一种特殊的哈希算法 hash-max-zipmap-entries 64 hash-max-zipmap-value 51229. 指定是否激活重置哈希，默认为开启（后面在介绍Redis的哈希算法时具体介绍） activerehashing yes30. 指定包含其它的配置文件，可以在同一主机上多个Redis实例之间使用同一份配置文件，而同时各个实例又拥有自己的特定配置文件 include /path/to/local.conf]]></content>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx的安装]]></title>
    <url>%2F2019%2F11%2F29%2Fnginx%E7%9A%84%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[nginx作用 反向代理 暴露代理服务器地址，请求分发，对外给调用者感觉是一个服务器， 负载均衡 根据服务器情况分发请求 动静分离 动态资源(servlet,jsp)和静态资源(html,css,img)分离 安装 安装下列依赖 1yum -y install gcc zlib zlib-devel pcre-devel openssl openssl-devel 解压nginx的tar包 1tar -zxvf nginx-1.8.0.tar.gzcd nginx-1.8.0 配置参数 123456789101112./configure \--prefix=/usr/local/nginx \--pid-path=/var/run/nginx/nginx.pid \--lock-path=/var/lock/nginx.lock \--error-log-path=/var/log/nginx/error.log \--http-log-path=/var/log/nginx/access.log \--with-http_gzip_static_module \--http-client-body-temp-path=/var/temp/nginx/client \--http-proxy-temp-path=/var/temp/nginx/proxy \--http-fastcgi-temp-path=/var/temp/nginx/fastcgi \--http-uwsgi-temp-path=/var/temp/nginx/uwsgi \--http-scgi-temp-path=/var/temp/nginx/scgi 编译 1make &amp;&amp; make install 进入/usr/local/nginx/sbin下启动 12./nginx(可能会出现: [emerg] mkdir() "/var/temp/nginx/client" failed (2: No such file or directory)，我是直接在/var/temp/nginx/client手动创建出来解决的)ps -ef | grep nginx(查看进程是否启动) nginx常用命令 查看版本号 1./nginx -v 停止nginx 1./nginx -s stop 重启nginx 1./nginx -s reload]]></content>
      <categories>
        <category>后台</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux防火墙常用操作]]></title>
    <url>%2F2019%2F11%2F18%2Flinux%E9%98%B2%E7%81%AB%E5%A2%99%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[linux防火墙常用命令 查看firewall服务状态 systemctl status firewalld 查看firewall状态firewall-cmd –state 开启关闭重启防火墙3.1 开启防火墙service firewalld start3.2 重启防火墙service firewalld restart3.3 关闭防火墙service firewalld stop 查看防火墙规则firewall-cmd –list-all 查询开放关闭端口5.1 查询端口(8080)是否开放firewall-cmd –query-port=8080/tcp5.2 开放端口(8080)firewall-cmd –permanent –add-port=8080/tcp5.3 关闭端口(8080)firewall-cmd –permanent –remove-port=8080/tcp 重启防火墙(配置修改后使用)firewall-cmd –reload 常用参数 firwall-cmd：是Linux提供的操作firewall的一个工具； –permanent：表示设置为持久； –add-port：标识添加的端口； 转载自：https://www.cnblogs.com/xxoome/p/7115614.html]]></content>
      <categories>
        <category>后台</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Intellij idea在debug时修改类自动加载]]></title>
    <url>%2F2019%2F11%2F05%2FIntellij%20idea%E5%9C%A8debug%E6%97%B6%E4%BF%AE%E6%94%B9%E7%B1%BB%E8%87%AA%E5%8A%A8%E5%8A%A0%E8%BD%BD%2F</url>
    <content type="text"><![CDATA[debug时需要修改代码，但修改完还需要重启感觉特别麻烦，就找到了以下这个方法，当代码修改后，idea会自动加载修改的类 ctrl+alt+s打开设置框，勾选设置 ctrl+shift+a弹出的页面搜索registry，并勾选 打开项目设置]]></content>
      <categories>
        <category>编译工具</category>
      </categories>
      <tags>
        <tag>Intellij idea</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springboot2.2.0打war包运行报错]]></title>
    <url>%2F2019%2F10%2F27%2Fspringboot2.2.0%E6%89%93war%E5%8C%85%E8%BF%90%E8%A1%8C%E6%8A%A5%E9%94%99%2F</url>
    <content type="text"><![CDATA[springboot2.2.0版本打war包放入tomcat后加载不到mapper的bean今天本来想试一试maven多版本打包，用的是springboot2.2.0，什么都配好了结果war包放入tomcat后老是运行不起来，加载不到mybatis的bean，折腾了一下午，原因是springboot2.2.0有问题，将springboot版本回退就好了 下面是tomcat的主要报错信息： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546E:\apache-tomcat-9.0.27\webapps\boot.war] 时出错 java.lang.IllegalStateException: Error starting child at org.apache.catalina.core.ContainerBase.addChildInternal(ContainerBase.java:720) at org.apache.catalina.core.ContainerBase.addChild(ContainerBase.java:690) at org.apache.catalina.core.StandardHost.addChild(StandardHost.java:705) at org.apache.catalina.startup.HostConfig.deployWAR(HostConfig.java:978) at org.apache.catalina.startup.HostConfig$DeployWar.run(HostConfig.java:1849) at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) at java.util.concurrent.FutureTask.run(FutureTask.java:266) at org.apache.tomcat.util.threads.InlineExecutorService.execute(InlineExecutorService.java:75) at java.util.concurrent.AbstractExecutorService.submit(AbstractExecutorService.java:112) at org.apache.catalina.startup.HostConfig.deployWARs(HostConfig.java:773) at org.apache.catalina.startup.HostConfig.deployApps(HostConfig.java:427) at org.apache.catalina.startup.HostConfig.start(HostConfig.java:1576) at org.apache.catalina.startup.HostConfig.lifecycleEvent(HostConfig.java:309) at org.apache.catalina.util.LifecycleBase.fireLifecycleEvent(LifecycleBase.java:123) at org.apache.catalina.util.LifecycleBase.setStateInternal(LifecycleBase.java:423) at org.apache.catalina.util.LifecycleBase.setState(LifecycleBase.java:366) at org.apache.catalina.core.ContainerBase.startInternal(ContainerBase.java:936) at org.apache.catalina.core.StandardHost.startInternal(StandardHost.java:841) at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:183) at org.apache.catalina.core.ContainerBase$StartChild.call(ContainerBase.java:1384) at org.apache.catalina.core.ContainerBase$StartChild.call(ContainerBase.java:1374) at java.util.concurrent.FutureTask.run(FutureTask.java:266) at org.apache.tomcat.util.threads.InlineExecutorService.execute(InlineExecutorService.java:75) at java.util.concurrent.AbstractExecutorService.submit(AbstractExecutorService.java:134) at org.apache.catalina.core.ContainerBase.startInternal(ContainerBase.java:909) at org.apache.catalina.core.StandardEngine.startInternal(StandardEngine.java:262) at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:183) at org.apache.catalina.core.StandardService.startInternal(StandardService.java:421) at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:183) at org.apache.catalina.core.StandardServer.startInternal(StandardServer.java:930) at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:183) at org.apache.catalina.startup.Catalina.start(Catalina.java:633) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.apache.catalina.startup.Bootstrap.start(Bootstrap.java:344) at org.apache.catalina.startup.Bootstrap.main(Bootstrap.java:475) Caused by: org.apache.catalina.LifecycleException: Failed to start component [StandardEngine[Catalina].StandardHost[localhost].StandardContext[/boot]] at org.apache.catalina.util.LifecycleBase.handleSubClassException(LifecycleBase.java:440) at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:198) at org.apache.catalina.core.ContainerBase.addChildInternal(ContainerBase.java:717) ... 37 more Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'userController': Unsatisfied dependency expressed through field 'userService'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'userServiceImpl': Unsatisfied dependency expressed through field 'userMapper'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'userMapper' defined in file [E:\apache-tomcat-9.0.27\webapps\boot\WEB-INF\classes\com\boot\mapper\UserMapper.class]: Unsatisfied dependency expressed through bean property 'sqlSessionFactory'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'org.mybatis.spring.boot.autoconfigure.MybatisAutoConfiguration': Unsatisfied dependency expressed through constructor parameter 0; nested exception is org.springframework.boot.context.properties.ConfigurationPropertiesBindException: Error creating bean with name 'mybatis-org.mybatis.spring.boot.autoconfigure.MybatisProperties': Could not bind properties to 'MybatisProperties' : prefix=mybatis, ignoreInvalidFields=false, ignoreUnknownFields=true; nested exception is org.springframework.boot.context.properties.bind.BindException: Failed to bind properties under 'mybatis.configuration.mapped-statements[0].parameter-map.parameter-mappings[0]' to org.apache.ibatis.mapping.ParameterMapping pom文件设置多版本依赖123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354&lt;profiles&gt; &lt;!--开发环境--&gt; &lt;profile&gt; &lt;id&gt;dev&lt;/id&gt; &lt;activation&gt; &lt;!--默认启动此配置--&gt; &lt;activeByDefault&gt;true&lt;/activeByDefault&gt; &lt;/activation&gt; &lt;properties&gt; &lt;spring.profiles.active&gt;dev&lt;/spring.profiles.active&gt; &lt;/properties&gt; &lt;/profile&gt; &lt;!--测试环境--&gt; &lt;profile&gt; &lt;id&gt;test&lt;/id&gt; &lt;properties&gt; &lt;spring.profiles.active&gt;test&lt;/spring.profiles.active&gt; &lt;/properties&gt; &lt;/profile&gt; &lt;!--线上--&gt; &lt;profile&gt; &lt;id&gt;prod&lt;/id&gt; &lt;properties&gt; &lt;spring.profiles.active&gt;prod&lt;/spring.profiles.active&gt; &lt;/properties&gt; &lt;/profile&gt; &lt;/profiles&gt; &lt;build&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;$&#123;project.basedir&#125;/src/main/resources&lt;/directory&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;!-- 打包跳过test --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;skip&gt;true&lt;/skip&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;!-- 修改war包名称 --&gt; &lt;finalName&gt;boot&lt;/finalName&gt; &lt;/build&gt; application.yml 存放了一些通用配置，如mybatis的全局config和mapper位置 123456789101112spring: profiles: active: @spring.profiles.active@server: port: 9527 servlet: context-path: /bootmybatis: config-location: classpath:mybatis-config.xml mapper-locations: classpath:mapper/*.xml application-dev.yml 这是开发环境的yml配置，应该还有一份test和prod的yml，大致相同就不列出了 123456spring: datasource: driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://127.0.0.1:3306/luntan username: root password: root]]></content>
      <categories>
        <category>后台</category>
      </categories>
      <tags>
        <tag>那些年踩过的坑= =</tag>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux权限命令乞丐版]]></title>
    <url>%2F2019%2F10%2F21%2Flinux%E6%9D%83%E9%99%90%E5%91%BD%E4%BB%A4%E4%B9%9E%E4%B8%90%E7%89%88%2F</url>
    <content type="text"><![CDATA[权限管理文件目录基本操作文件/目录所有者默认文件的创建者是文件所有者 查看文件的所有者ls -ahl：查看文件所有者 下图所示：红线是文件所有者，蓝线是文件所有组 修改文件所有者chown 用户名 文件名：改变文件所有者 chown tom a.tar.gz：将a.tar.gz文件的所有者变更为tom 文件/目录所在组文件创建者所在的组是文件的所有组 修改文件所在组chgrp 组名 文件名：修改文件所在组 chgrp superman a.tar.gz：将a.tar.gz的所在组变更为superman 其他组除了文件的所有者在的组的用户外，其他用户都是其他组 改变用户所在组usermod -g 组名 用户名：将用户所在组改变 usermod -g 金刚狼 天启：将金刚狼放到天启组下 usermod -d 目录名 用户名：改变用户登录的初始目录 usermod -d /var 金刚狼：将金刚狼登录目录变更为/var 权限基本介绍下图显示的内容，划横线的是操作权限，出了最后的点，一共十个位置(没解释的一律不知道) 第0位是文件类型（d:目录，-:文件，l:软连接，c，b） 第1-3位是文件所有者的权限（r:读权限，w:写权限，x:执行权限）–&gt;user 第4-6位是文件所属组的权限–&gt;group 第7-9位是其他组的权限–&gt;other rwx的权限解读rwx作用到文件 r（read）：读写查看权限 w（write）：修改权限，不一定可删除，需持有文件所在目录的w权限，才能删除 x（execute）：执行权限 rwx作用到目录 r（read）：读写查看权限 w（write）：修改权限，目录内容创建，修改，冲命令 x（execute）：执行全新，进入该目录 修改权限可通过chmod来修改文件或目录的权限 通俗方式u：所有者，g：所有组，o：其他组，a：全部人（u和g和o的总和） chmod u=rwx,g=rx,o=x 文件或目录：修改文件或目录使u拥有rwx，g拥有rx，o拥有x权限 chmod o+w 文件目录名：为o添加上w权限 chmod a-x 文件目录名：为a减去x权限 简易方式通过数字变更权限 r=4，w=2，x=1 rwx=7 chmod u=rwx,g=rx,o=x等价于 chmod 751 文件目录名 修改文件持有者使用命令chown来实现 chown 新的持有者 文件或目录：改变文件持有者 chown 金刚狼 a.tar.gz：将a.tar.gz持有者变更为金刚狼 chown 持有者:持有组 文件或目录：改变文件的持有者和持有组 chown 金刚狼:天启 文件或目录：改变文件的持有者为金刚狼持有组为天启 chown -R 持有者:持有组 目录：改变目录及目录下所有文件的持有者和持有组]]></content>
      <categories>
        <category>后台</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux常用命令]]></title>
    <url>%2F2019%2F10%2F20%2Flinux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[vimvi和vim的三种常见模式 命令模式（可以使用快捷键） 输入模式（输入i进入输入模式） 底线模式（读取，存盘，替换，离开vim） q：直接退出 q！：强制退出 w：写入磁盘 w！：强制写入磁盘 wq：写入磁盘并退出 wq！：强制写入磁盘并退出 更多命令 关机和重启shutdown： shutdown -h now：立即关机 shutdown -h 1：1分钟之后关机 shutdown -r now：重启 halt：关机 reboot：重启 sync：把内存数据同步到磁盘（关机或重启是应先执行此命令） 用户管理linux通过组的概念来管理用户和权限，每个用户都至少属于一个组 添加用户useradd 用户名：家目录位于/home下 useradd -d /home/person ：创建用户并指定该用户的家目录 useradd -g 组名 用户名：创建用户并指定用户组（组必须存在） usermod -g 组名 用户名：修改用户的组 passwd 用户名：设置用户的密码 删除用户userdel 用户名：删除用户，但保留用户家目录 userdel -r 用户名：删除用户，且删除用户家目录 查看用户信息id 用户名：显示用户id，组id，组名 切换用户su 用户名：切换到用户 高权限用户切换低权限用户不需要输密码，低权限切换到高权限需要密码，当需要返回原来用户是使用exit命令 组管理相当于角色，可对有共性的用户集中管理 创建组groupadd 组名 删除组groupdel 组名 用户和组相关文件/etc/passwd 文件：用户的配置文件，记录用户各种信息 每行含义：用户名：口令：用户标识号：组标识号：注释性描述：主目录：登录shell 个人感觉可以用此文件查看谁对本机进行了何种操作 /etc/shadow 文件：口令文件 /etc/group 文件：组配置文件 每行含义：组名：口令：组标识号：组内用户列表 实用指令帮助指令 man [命令或配置文件]：帮助指令，会列出帮助信息（centos7支持简体中文） help [命令]：帮助指令 文件目录类(常用) pwd：显示当前目录的绝对路径 ls：显示文件和目录 ls -a：显示当前目录所有的文件和目录 ls -l：列表方式显示信息 cd：进入到指定目录 cd ~ :回到自己的家目录 cd .. ：回到当前目录的上级目录（相对定位） cd /usr/local：进入到/usr目录下的local目录（绝对定位） mkdir：创建目录文件夹 mkdir /home/dog：在home下创建dog目录 mkdir -p /home/animal/dog：在home先创建animal然后在animal下创建dog rmdir：删除空目录 rmdir /home/dog rm -rf 目录名或文件名：强制删除文件夹及文件夹下所有文件（删库跑路必备神器） touch 文件名：创建一个空文件 cp：拷贝文件到指定目录 cp aaa.txt bbb/：将当前目录aaa.txt拷贝到bbb目录下 cp -r /home/tomcat/ /opt/：将home下的tomcat目录拷贝到opt目录下，当tomat有文件或文件夹时，应带参数-r \cp -r /home/tomcat/ /opt/：opt下存在tomcat目录时会提示是否覆盖，此命令强制覆盖 mv：移动文件与目录或重命名 mv pig.txt dog.txt：将pig.txt重命名为dog.txt mv tomcat/ /home/：将tomcat目录移动到home目录下 cat：只读方式打开文件 cat 文件名：显示文件内容 cat -n 文件名：带行号，显示文件内容 cat -n 文件名 | more ：带行号，分页(空格进入下一页)，显示文件内容 less：分屏查看内容(懒加载，效率高，适合大型文件的查看) less /etc/profile 快捷键 功能 空格键、pagedown 向下翻动一页 pageup 向上翻动一页 /字符 向下搜索字符 ?字符 向上搜索字符 q 离开less程序 &gt;和&gt;&gt; cat /etc/profile &gt; a.txt：将etc下的peofile内容覆盖写入到a.txt中 cat /etc/profile &gt;&gt; a.txt：将etc下的peofile内容追加写入到a.txt中 echo hello &gt;&gt; a.txt：将hello追加写入到a.txt中 echo hello：将hello输出到控制台 head 文件名(默认前10行) head /etc/profile：显示etc下profile前10行内容 head -n 5 /etc/profile：显示etc下profile前5行内容 tail 文件名(默认输出后10行) tail /etc/profile：显示etc下profile后10行内容 tail -n 5 /etc/profile：显示etc下profile后5行内容 tail -f 文件名：实时追踪文件的所有更新(常用，日志文件的追踪) ln -s 链接到的地址 链接名(类似于windows的快捷方式) ln -s /root lindToRoot：链接为lindToRoot history：查看执行过的历史指令 时间日历类 date：当前时间信息，设置时间 date +%Y：当前年份 date +%Y-%m：当前年月 date +%Y-%m-%d：当前年月日 date “+%Y-%m-%d %H:%M:%S””：当前年月日时分秒 date -s “2019-10-19”：设置日期 cal：日历 cal ：显示当前日历信息 cal 2019：显示2019年所有日历 压缩和解压缩 gzip和gunzip：压缩和解压缩(完成后不会保留原文件) gzip a.txt：将a.txt压缩，并删除掉a.txt gunzip a.txt.gz：将a.txt.gz解压缩，并删除掉a.txt.gz zip和unzip：压缩和解压缩 zip [选项] 压缩包.zip 被压缩的文件或目录 zip -r(递归压缩) package.zip /home/：将home下的所有文件递归压缩为package.zip unzip [选项] [解压位置] 被解压文件或目录 unzip -d(指定解压位置) /opt/tmp/ package.zip：将package解压到opt目录的tmp目录下 tar：压缩和解压缩指令，打包完的文件是.tag.gz文件 tar [选项] xxx.tar.gz 被打包的文件或目录 tar -zcvf a.tar.gz a.txt b.txt：将a.txt和b.txt压缩为a.tar.gz tar -zcvf a.tar.gz /home/：将home目录下所有文件压缩为a.tar.gz tar -zxvf a.tar.gz -C /opt：将a.tar.gz解压缩到opt目录下 选项 功能 -c 产生.tar打包文件 -v 显示详细信息 -f 指定压缩后的文件名 -z 打包同时压缩 -x 解包.tar文件 进程命令显示系统进程ps，进程查看指令，通常使用参数为ps -aux -a 显示终端所有进程信息 -u 用户格式显示进程信息 -x 显示后台进程运行参数 ps -aux | more：分页查看进程 ps -ef | more：分页全格式显示当前进程 ps -f | grep mysql：查看mysql相关进程 -e 显示所有进程 -f 全格式 进程终止kill -9(强制杀死) 进程号：通过进程号强制杀死进程 kill -9 9527：强制杀死进程号为9527的进程 killall 父进程名：杀掉父进程及下属所有子进程 服务管理本质是进程，运行在后台，监听端口，又称守护进程（例如：mysql，sshd，防火墙） systemctl [start | stop | restart | reload | status] 服务名 systemctl status firewalld：查看防火墙状态 rpm和yumrpm包删除rpm -e rpm包名称 rpm -e firefox：卸载火狐 rpm包安装rmp -ivh(i:安装，v:提示信息，h:进度条) rmp包全路径名称 yum相关文件查询yum list | grep 文件：查询yum服务器是否有需要安装的软件 yum list | grep chrome：查询谷歌浏览器 安装yum指定包yum install 文件名：下载安装文件]]></content>
      <categories>
        <category>后台</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[教育知识与能力考试大纲]]></title>
    <url>%2F2019%2F10%2F07%2F%E6%95%99%E8%82%B2%E7%9F%A5%E8%AF%86%E4%B8%8E%E8%83%BD%E5%8A%9B%E8%80%83%E8%AF%95%E5%A4%A7%E7%BA%B2%2F</url>
    <content type="text"><![CDATA[考试题型 题型 题量 每题分值 总分值 所占比重 单选题 21道 2 42 28% 辨析题 4道 8 32 21% 简答题 4道 10 40 27% 材料分析题 2道 18 36 24% 总计 31道 150 考试内容 第一章：教育基础知识和基本原理 30’’ 第二章：中学课程 5-6’’ 第三章：中学教学 22’’ 第四章：中学生学习心理 33’’ 第五章：中学生发展心理 10-15’’ 第六章：中学生心理辅导 6’’ 第七章：中学德育 22-25’’ 第八章：中学班级管理与教师心理 6’’]]></content>
      <categories>
        <category>教资</category>
      </categories>
      <tags>
        <tag>教资</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RabbitMQ实战指南笔记(一)]]></title>
    <url>%2F2019%2F10%2F05%2FRabbitMQ%E5%AE%9E%E6%88%98%E6%8C%87%E5%8D%97%E7%AC%94%E8%AE%B0(%E4%B8%80)%2F</url>
    <content type="text"><![CDATA[消息何去何从mandatory参数mandatory是channel.basicPublish的参数，当交换器无法根据自身类型和路由键匹配到队列时，根据mandatory的值有两种情况： true：RabbitMQ调用Basic.Return命令将消息返还给生产者 false：消息丢弃 123456789101112131415// 注意channel和connection不要关闭，否则返回监听也会失效// 消息发布（第三个参数为mandatory，默认false）channel.basicPublish(EXCHANGE_NAME, ROUTING_KEY, false, MessageProperties.PERSISTENT_TEXT_PLAIN, message.getBytes());// 返回监听channel.addReturnListener(new ReturnListener() &#123; // 处理返回 public void handleReturn(int i, String s, String s1, String s2, AMQP.BasicProperties basicProperties, byte[] bytes) throws IOException &#123; String msg = new String(bytes); System.out.println(String.format("Basic Return返回的结果: %s", msg)); &#125;&#125;); 备份交换器又称“备胎交换器”，当主交换器的消息没有路由到正确的队列时，消息应该被返回或丢弃，若不想返回或丢弃，可以为主交换器声明一个备胎交换器 123456789101112Map&lt;String, Object&gt; arg = new HashMap&lt;String, Object&gt;(3);arg.put("alternate-exchange", "myAe");// 创建正常交换器channel.exchangeDeclare("normalExchange", "direct", true, false, false, arg);// 备用交换器channel.exchangeDeclare("myAe", "fanout", true, false, false, null);channel.queueDeclare("normalQueue", true, false, false, null);channel.queueBind("normalQueue", "normalExchange", "normalKey");channel.queueDeclare("unroutingQueue", true, false, false, null);channel.queueBind("unroutingQueue", "myAe", ""); 设置备份交换器会发生以下情况： 设置的备份交换器不存在，无异常，消息丢失 备份交换器没有绑定队列，无异常，消息丢失 备份交换器没有匹配队列，无异常，消息丢失 备份交换器和mandatory一起使用，mandatory失效 过期时间TTLTime to live，rabbitmq可对消息和队列设置过期时间 消息过期rabbitmq设置消息过期有两种方式： 在消息发布时设置过期时间（单位：毫秒）： 12345678910String message = "Hello World !";AMQP.BasicProperties.Builder builder = new AMQP.BasicProperties.Builder();// 消息持久化builder.deliveryMode(2);// 过期时间3秒，毫秒为单位builder.expiration("3000");AMQP.BasicProperties properties = builder.build();// 消息发布channel.basicPublish(EXCHANGE_NAME, ROUTING_KEY, false, properties, message.getBytes()); 消息过期时不会被立即抹去，会在出队列时进行检验，过期丢弃，未过期则投递消费 在队列声明时设置消息过期时间（单位：毫秒）： 1234Map&lt;String, Object&gt; arg = new HashMap&lt;String, Object&gt;(3);// 设置队列中消息过期时间，10秒过期（毫秒为单位）arg.put("x-message-ttl", 10000);channel.queueDeclare(QUEUE_NAME, true, false, false, arg); 因为过期消息肯定在队列头（队列性质决定），所以过期的消息会被立即丢弃 队列过期rabbitmq通过channel.queueDeclare方法的“x-expires”参数设置过期，参数指的是队列处于未使用状态的时间达到时会被自动删除，上面未使用有下面三个概念： 队列上没有消费者 队列没有被重新声明 在过期时间内未调用Basic.Get方法 1234Map&lt;String, Object&gt; arg = new HashMap&lt;String, Object&gt;(3);// 设置队列过期时间，单位：毫秒arg.put("x-expires", 10000);channel.queueDeclare(QUEUE_NAME, true, false, false, arg); 死信队列deal-letter-exchange，死信交换器。消息在队列中变成变成死信可以被发送到死信交换机（DLX），死信交换机绑定的队列为死信队列。消息变成死信的情况： 消息被拒绝（Basic.Reject/Basic.Nack），且设置requeue参数为false 消息过期 队列达到最大长度 可以通过在channel.queueDeclare方法中设置x-dead-letter-exchange参数为队列添加DLX 12345678910111213141516171819202122// 死信交换器channel.exchangeDeclare("exchange.dlx", "direct", true, false, null);// 正常交换器channel.exchangeDeclare("exchange.normal", "fanout", true, false, null);Map&lt;String, Object&gt; arg = new HashMap&lt;String, Object&gt;(3);// 消息过期时间3秒arg.put("x-message-ttl", 3000);// 死信交换器arg.put("x-dead-letter-exchange", "exchange.dlx");channel.queueDeclare("queue.normal", false, false, false, arg);channel.queueBind("queue.normal", "exchange.normal", "");channel.queueDeclare("queue.dlx", false, false, false, null);channel.queueBind("queue.dlx", "exchange.dlx", "rk");String message = "Hello World !";channel.basicPublish("exchange.normal", "rk", false, MessageProperties.PERSISTENT_TEXT_PLAIN, message.getBytes()); 延迟队列延迟队列就是在一定时间后才让消费者拿到消息，应用场景有我们的手机手机定时关机等。rabbitmq中没有延迟队列的实现，但使用消息过期和死信队列可以达到消息延时的效果 将消费者挂在死信队列上，此时死信队列就是一个延迟队列，具体的延迟时间则是由队列或者消息来决定 优先级队列优先级队列中的消息都有优先级，高优先级的消息优先消费，通过设置队列参数“x-max-priority”指定队列中消息的最大优先级 123456789101112131415channel.exchangeDeclare("exchange.priority", "direct", true, false, null);Map&lt;String, Object&gt; arg = new HashMap&lt;String, Object&gt;(3);arg.put("x-max-priority", 10);channel.queueDeclare("queue.priority", true, false, false, arg);channel.queueBind("queue.priority", "exchange.priority", "routingKey");String message = "Hello World!";AMQP.BasicProperties.Builder builder = new AMQP.BasicProperties.Builder();// 消息优先级为5builder.priority(5);AMQP.BasicProperties properties = builder.build();// 消息发布channel.basicPublish("exchange.priority", "routingKey", false, properties, message.getBytes()); 消息的最大优先级为队列的优先级（上文中消息最大优先级为10，默认为0） 设置消息优先消费会有一个问题：消息的生产速度必须大于消费速度，造成队列中消息的堆积，消息优先级的设置才会变得有意义。否则就会变成队列中只有一个消息，优先级设置就不会起到作用 RPC实现 RPC实现 持久化rabbit持久化分为三个部分：交换器持久化、队列持久化、消息持久化 交换器的持久化的通过在声明队列是将durable参数设置为true实现的，如果不设置持久化，在rabbitmq重启后交换器的数据会丢失。对于长期使用的交换器建议设置为持久化 12// 创建一个 type="direct" 、持久化的、非自动删除的交换器channel.exchangeDeclare(EXCHANGE_NAME, "direct", true, false, null); 队列的持久化在声明队列时将durable参数设置为true实现的，队列是消息的存储地，若队列没有设置为持久化，在rabbitmq重启后队列的元数据会丢失，相应的，队列中的消息也会丢失 12// 创建一个持久化、非排他的、非自动删除的队列channel.queueDeclare(QUEUE_NAME, true, false, false, null); 消息的持久化通过投递时将投递模式（BasicProperties的deliveryMode属性）设为2来实现的 1234 // 消息发布channel.basicPublish(EXCHANGE_NAME, ROUTING_KEY, MessageProperties.PERSISTENT_TEXT_PLAIN, message.getBytes()); 只有将队列和消息同时设置为持久化，rabbitmq重启后消息才会存在 即便配置了持久化，但消息还是有几率丢失： 消费者设置自动确认（autoAck），消费者异常或宕机造成消息丢失 消息进入rabbit后还需要一段时间才能同步存盘，此时发生异常会导致消息的丢失，解决办法是镜像队列机制（相对可靠更多），或发送端事务与发送端消息确认机制来提高可靠性 生产者确认生产者如何知道自己发送的消息顺利抵达队列？ 事务机制事务相关的方法有三个： channel.txSelect：将信道设置为事务模式 channel.txCommit：事务的提交 channel.txRollback：事务的回滚 开启事务模式，发送消息给rabbitmq，若成功，事务提交，若异常，事务回滚 12345678910// 开启事务try &#123; channel.txSelect(); channel.basicPublish(EXCHANGE_NAME, ROUTING_KEY, false, MessageProperties.PERSISTENT_TEXT_PLAIN, "事务".getBytes()); channel.txCommit();&#125; catch (IOException e) &#123; e.printStackTrace(); channel.txRollback();&#125; 事务非常影响性能，基本不用 发送方确认机制生产者将信道设置为confirm模式，信道进入confirm模式后，信道上发布的消息都会被分配唯一ID号（从1开始），当消息到达匹配队列时信道会发送（Basic.Ack）发送方确认（包含消息的ID号）给生产者，使生产者知道消息安全到达队列。如果消息是持久化消息，发送方确认会在消息写入磁盘后回执给生产者。回传的确认消息的序号在确认消息的deliveryTag中。rabbitmq也可设置channel.basicAck方法的multiple参数，表示到这个序号之前的所有消息已经被处理 和事务相比，事务是同步的，必须等待rabbitmq响应才能发送下一条消息。而confirm是异步的，发送消息后生产者可继续发送下一条消息，通过回调方法处理rabbitmq的响应。若rabbitmq自身原因导致消息丢失会发送nack命令，生产者可在回调中处理 生产者调用channel.confirmSelect方法将信道设置为confirm模式，此后发送的消息都会被ack或nack一次。 发送方确认的使用方式有两种 批量confirm方法：发送一批消息，调用channel.waitForConfirms方法，等待服务器确认返回 12345678910111213141516171819channel.confirmSelect();String msg = "我是confirm模式 消息 批量发送";//多条一起发送for (int i = 0; i &lt; 5; i++) &#123; channel.basicPublish("exchange.confirm", "queue.confirm", MessageProperties.PERSISTENT_TEXT_PLAIN, msg.getBytes());&#125;try &#123; //等待回复，如果回复true if (channel.waitForConfirms()) &#123; System.out.println("发送成功"); &#125; else &#123; System.out.println("发送失败"); &#125;&#125;catch (InterruptedException e) &#123; e.printStackTrace(); System.out.println("发送失败");&#125; 异步confirm方法：提供一个回调方法，服务端确认一条或多条消息服务端会回调这个方法处理 1234567891011121314151617181920212223242526272829303132333435final SortedSet&lt;Long&gt; confirmSet = Collections.synchronizedNavigableSet(new TreeSet&lt;Long&gt;());channel.confirmSelect();// 开启监听channel.addConfirmListener(new ConfirmListener() &#123; // 处理成功 public void handleAck(long deliveryTag, boolean multiple) throws IOException &#123; System.out.println("消息发送成功: " + deliveryTag + ", multiple : " + multiple); if (multiple) &#123; confirmSet.headSet(deliveryTag - 1).clear(); &#125; else &#123; confirmSet.remove(deliveryTag); &#125; &#125; // 处理失败 public void handleNack(long deliveryTag, boolean multiple) throws IOException &#123; if (multiple) &#123; confirmSet.headSet(deliveryTag - 1).clear(); &#125; else &#123; confirmSet.remove(deliveryTag); &#125; &#125;&#125;);// 循环发送消息for (int i = 0; true; i++) &#123; String msg = "我是confirm模式 消息 异步【" + i + "】"; long tag = channel.getNextPublishSeqNo(); //发送消息 channel.basicPublish("exchange.confirm", "queue.confirm2", MessageProperties.PERSISTENT_TEXT_PLAIN, msg.getBytes()); System.out.println("tag:" + tag); confirmSet.add(tag);&#125; 参考：RabbitMq实战指南]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>rabbitmq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅谈RabbitMQ]]></title>
    <url>%2F2019%2F10%2F03%2F%E6%B5%85%E8%B0%88RabbitMQ%2F</url>
    <content type="text"><![CDATA[基本概念生产者和消费者rabbitmq扮演代理服务器（提供投递服务，==》邮局），在我的理解中消息队列使用的就是生产者消费者模式 生产者生产者创建消息，消息包含两部分：有效载荷和标签（邮件） 有效载荷：传输的数据（内容） 标签：决定谁来消费（收件人） 消费者消费者接收每一条消息都必须手动进行确认（邮件手动签收），或者设置在订阅队列时就自动确认（邮件自动签收==》消费者接收消息，rabbitmq自动视其确认了消息），消费者对消息的确认和告诉生产者消息已被接收这两件事毫不相关 rabbitmq收到消费者的确认后，才会认为消息投递成功并删除队列中的消息 信道信道建立在真实Tcp连接中的虚拟连接，AMQP命令都是通过信道传输的。因为对于操作系统而言建立和销毁Tcp连接代价十分高昂，所以引入信道概念（可以把Tcp连接想象成电缆，信道就是光纤） AMQP元素交换器 direct交换器：路由键匹配，消息就被投递到对应的队列。此处路由键为warning的消息会被路由到Queue1，而路由键为info，warning，debug的消息会被路由到Queue2 fanout交换器：将消息广播到绑定的队列上 topic交换器：通配符匹配，以“.”为分隔，BindingKey中可以同时存在两种特殊字符串“*”和“#”，用于模糊匹配，其中”※”用于匹配一个单词，而“#”匹配一个或多个单词（可以是0个），以下图为例 路由键为”com.rabbitmq.client”的消息会同时路由到 Queue1 Queue2 路由键为”com.hidden.client”的消息只会路由到 Queue2中 路由键为”com.hidden.demo”的消息只会路由到 Queue2中 路由键为”java.rabbitmq.demo”的消息只会路由到 Queue1中 路由键为”java.uti l. concurrent” 的消息将会被丢弃或者返回给生产者(需要设置mandatory 参数) ，因为它没有匹配任何路由键。 header交换器（基本不用，不做解释） 队列存放生产者发送的消息，消息的容器和终点 绑定生产者发送消息给交换器，交换器根据特定规则投递到相应队列，这里的规则就是路由键（routing key），队列通过路由键绑定到交换器。 那么问题来了，如果消息的路由键为空（“”）或路由键没有匹配到任何绑定会发生什么？ 路由键为空时交换机也会去尝试匹配绑定队列，若匹配（队列绑定的路由键为空），则投递到队列 消息没有匹配到任何绑定时，消息会进入“黑洞”（彻底丢失） 多租户模式（多虚拟主机）rabbitmq服务器可以创建多个虚拟消息服务器，称为”虚拟主机”（vhost），每个vhost都是mini版的rabbitmq服务器，拥有自己的队列、交换器、绑定等，还拥有自己的权限控制，从而达到各个实例间逻辑上的分离 如果都使用默认的vhost（/），非常容易产生命名冲突。所以对于通用模块（web日志）消息队列的使用，应创建属于自己的vhost，保证了安全性和可移植性 持久化说了那么多，万一你的rabbitmq宕机，消息岂不是全丢了？ rabbitmq有自己的持久化策略：维护持久化日志文件。宕机重启后自动重建持久化交换器和队列并重播持久化日志文件的消息到合适的队列或交换器上 在消息发布前将它的”投递模式”选项设置为2（AMQP客户端会使用人性化常量来代替数值），此时发布的消息被标记为持久化消息，当消息被发布到持久化交换器中且到达持久化队列时，才算真正的持久化完成。因此消息可恢复的三个前提为： 投递模式设为持久 发送到持久化交换器 到达持久化队列 rabbitmq会把持久化消息写入磁盘上的持久化日志文件，当消息到达持久化交换器时会被写入磁盘日志文件，写入成功后返回响应。此时又有一个问题，持久化日志文件何时移除消息： 持久化消息被路由到非持久化队列 持久化消息被消费 你肯定还会有疑问，生产者如何知道自己发送的消息被rabbit接收了？ 事务，非常影响性能且会产生同步效果，背离使用mq的初衷 发送方确认模式（confirm模式） 将信道设置为confirm模式，信道上发布的消息都会被分配唯一ID号（从1开始），当消息到达匹配队列时信道会发送发送方确认（包含消息的ID号）给生产者，使生产者知道消息安全到达队列。如果消息是持久化消息，发送方确认会在消息写入磁盘后回执给生产者。 好处是更轻量，异步 代码一个简单的生产消费案例的实现 Maven依赖： 12345&lt;dependency&gt; &lt;groupId&gt;com.rabbitmq&lt;/groupId&gt; &lt;artifactId&gt;amqp-client&lt;/artifactId&gt; &lt;version&gt;4.2.1&lt;/version&gt;&lt;/dependency&gt; 生产者： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849import com.rabbitmq.client.Channel;import com.rabbitmq.client.Connection;import com.rabbitmq.client.ConnectionFactory;import com.rabbitmq.client.MessageProperties;import java.io.IOException;import java.util.concurrent.TimeoutException;/** * 生产者 */public class RabbitProducer &#123; private static final String EXCHANGE_NAME = "exchange_demo"; private static final String ROUTING_KEY = "routingkey_demo"; private static final String QUEUE_NAME = "queue_demo"; private static final String IP_ADDRESS = "127.0.0.1"; private static final int PORT = 5672;//RabbitMQ（AMQP） 服务端默认端口号为 5672 public static void main(String[] args) throws IOException, TimeoutException, InterruptedException &#123; ConnectionFactory factory = new ConnectionFactory(); factory.setHost(IP_ADDRESS); factory.setPort(PORT); // 指定虚拟主机 factory.setVirtualHost("/vhost_xyn"); factory.setUsername("user_xyn"); factory.setPassword("123456"); // 创建连接 Connection connection = factory.newConnection(); // 创建信道 Channel channel = connection.createChannel(); // 创建一个 type="direct" 、持久化的、非自动删除的交换器 channel.exchangeDeclare(EXCHANGE_NAME, "direct", true, false, null); // 创建一个持久化、非排他的、非自动删除的队列 channel.queueDeclare(QUEUE_NAME, true, false, false, null); // 将交换器与队列通过路由键绑定 channel.queueBind(QUEUE_NAME, EXCHANGE_NAME, ROUTING_KEY); // 发送一条持久化的消息: hello world ! String message = "Hello World !"; // 消息发布 channel.basicPublish(EXCHANGE_NAME, ROUTING_KEY, MessageProperties.PERSISTENT_TEXT_PLAIN, message.getBytes()); //关闭资源 channel.close(); connection.close(); &#125;&#125; 消费者： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950import com.rabbitmq.client.*;import java.io.IOException;import java.util.concurrent.TimeUnit;import java.util.concurrent.TimeoutException;/** * 消费者 */public class RabbitConsumer &#123; private static final String QUEUE_NAME = "queue_demo"; private static final String IP_ADDRESS = "127.0.0.1"; private static final int PORT = 5672; public static void main(String[] args) throws IOException, TimeoutException, InterruptedException &#123; Address[] addresses = new Address[]&#123; new Address(IP_ADDRESS, PORT) &#125;; ConnectionFactory factory = new ConnectionFactory(); factory.setUsername("user_xyn"); factory.setPassword("123456"); factory.setVirtualHost("/vhost_xyn"); Connection connection = factory.newConnection(addresses); final Channel channel = connection.createChannel(); // 设置客户端最多未被ack的个数 channel.basicQos(64); Consumer consumer = new DefaultConsumer(channel) &#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; System.out.println(" recv message: " + new String(body)); try &#123; TimeUnit.SECONDS.sleep(1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; channel.basicAck(envelope.getDeliveryTag(), false); &#125; &#125;; channel.basicConsume(QUEUE_NAME, consumer); // 等待回调函数执行完毕之后 关闭资源 TimeUnit.SECONDS.sleep (5); channel.close(); connection.close(); &#125;&#125; 参考：RabbitMQ实战指南]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>rabbitmq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[String与常量池]]></title>
    <url>%2F2019%2F09%2F27%2FString%E4%B8%8E%E5%B8%B8%E9%87%8F%E6%B1%A0%2F</url>
    <content type="text"><![CDATA[String类和常量池String对象的创建方式123String str1 = "abc";String str2 = "abc"; // 此时str1 == str2，因为他们都是常量池中的abcString str3 = new String("abc") // 这会在堆中创建一个abc新对象，此时str1≠str3 第一种：直接赋值，若字符串存在于常量池中，会直接引用常量池中字符串；若不存在，会在常量池中创建并返回引用 第二种：new创建(先检测常量池中是否存在该字符串)，若字符串存在于常量池中，则直接在堆中创建字符串对象；若常量池中不存在，会现在常量池中创建字，再从堆中创建字符串 下面思考一下String str = new String(&quot;abc&quot;)到底创建了几个对象？答案一个或两个，当常量池中存在abc时，只在堆中创建对象abc，当常量池中不存在abc时，先在常量池中创建abc，然后从堆中创建对象abc String常量池的使用 双引号赋值，使用常量池 String类的intern方法，如果常量池中有等于此String的字符串，返回常量池中该字符串引用。如果没有，在常量池中创建与此String内容相等字符串并返回常量池中字符串的引用（此处说法笼统：具体可以看这篇博客） 8种基本类型的包装类和常量池除了Float和Double外，其他几种基本类型的包装类(Byte，Short，Integer，Long，Character，Boolean)都实现了常量池技术，包装类默认创建数值 [-128，127] 的相应类型的缓存数据，超出此范围仍然会去堆中创建对象， 以Integer缓存为例123456789101112131415161718192021222324252627282930313233343536// 缓存[-128，high]之间的数值否则堆中创建对象private static class IntegerCache &#123; static final int low = -128; static final int high; static final Integer cache[]; // 类加载初始化(静态代码块) static &#123; // high value may be configured by property int h = 127; String integerCacheHighPropValue = sun.misc.VM.getSavedProperty("java.lang.Integer.IntegerCache.high"); if (integerCacheHighPropValue != null) &#123; try &#123; int i = parseInt(integerCacheHighPropValue); i = Math.max(i, 127); // Maximum array size is Integer.MAX_VALUE h = Math.min(i, Integer.MAX_VALUE - (-low) -1); &#125; catch( NumberFormatException nfe) &#123; // If the property cannot be parsed into an int, ignore it. &#125; &#125; high = h; // 构建常量池 cache = new Integer[(high - low) + 1]; int j = low; for(int k = 0; k &lt; cache.length; k++) cache[k] = new Integer(j++); // range [-128, 127] must be interned (JLS7 5.1.7) assert IntegerCache.high &gt;= 127; &#125; private IntegerCache() &#123;&#125;&#125; 应用场景 Integer i1 = 40; 编译时将代码封装成Integer i1 = Integer.valueOf(40); Integer i2 = new Integer(40); 创建新对象 转载自Java 学习/面试指南(JavaGuide)]]></content>
      <categories>
        <category>后台</category>
      </categories>
      <tags>
        <tag>java基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Intellij idea中查看当前方法都被哪些类引用]]></title>
    <url>%2F2019%2F09%2F26%2FIntellij%20idea%E4%B8%AD%E6%9F%A5%E7%9C%8B%E5%BD%93%E5%89%8D%E6%96%B9%E6%B3%95%E9%83%BD%E8%A2%AB%E5%93%AA%E4%BA%9B%E7%B1%BB%E5%BC%95%E7%94%A8%2F</url>
    <content type="text"><![CDATA[当我们想要查看类中的方法都被谁引用时，可以点击这个方法，然后快捷键 Alt + F7 ，弹出如下窗口，点击yes，就可查看到所有的引用树了]]></content>
      <categories>
        <category>编译工具</category>
      </categories>
      <tags>
        <tag>Intellij idea</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Intellij idea中查看当前类中所有方法]]></title>
    <url>%2F2019%2F09%2F26%2FIntellij%20idea%E4%B8%AD%E6%9F%A5%E7%9C%8B%E5%BD%93%E5%89%8D%E7%B1%BB%E4%B8%AD%E6%89%80%E6%9C%89%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[当我们想要查找类中的方法，而类方法又特别多的时候，可以使用快捷键 Alt + 7 （没有修改过快捷键的话），就可以方便地查找了]]></content>
      <categories>
        <category>编译工具</category>
      </categories>
      <tags>
        <tag>Intellij idea</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git常用命令以及误删文件恢复]]></title>
    <url>%2F2019%2F09%2F21%2FGit%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E4%BB%A5%E5%8F%8A%E8%AF%AF%E5%88%A0%E6%96%87%E4%BB%B6%E6%81%A2%E5%A4%8D%2F</url>
    <content type="text"><![CDATA[配置类命令设置git的用户信息（以后的git提交都会带上这些信息） 12git config --global user.name &quot;???&quot;git config --global user.email ???????@???.com 查看所有配置信息 1git config --list 生成秘钥 123cd ~/.sshssh-keygen // 生成秘钥cat ~/.ssh/id_rsa.pub // 查看公钥 版本库操作克隆版本库 123git clone url // 使用http协议git clone ssh // 使用ssh协议（需要配置ssh密钥）git clone -b 分支名 url(ssh) // 拉取指定分支项目 初始化命令(在此处建立版本库) 1git init 检查文件的状态(文件只有被追踪和未追踪两种状态) 1git status 添加文件追踪 12git add . // 添加所有文件git add git命令.txt // 添加git命令.txt文件追踪 提交更新 1git commit -m &quot;提交信息&quot; 推送到远程仓库 12git push 默认名 分支名git push origin master 分支操作创建分支 1git branch 分支名 切换分支 1git checkout 分支名 查看当前分支 1git branch 删除分支 1git branch -d 分支名 创建并切换分支 1git checkout -b 分支名 合并分支 1git merge 分支名 关于冲突解决下面这段冲突示例中，head是你当前分支的内容，==下边则是提交目的地分支的内容，你需要做的就是合并两块代码，解决完冲突后需要把此文件git add，表示冲突解决 1234567&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD:index.html&lt;div id=&quot;footer&quot;&gt;contact : email.support@github.com&lt;/div&gt;=======&lt;div id=&quot;footer&quot;&gt; please contact us at support@github.com&lt;/div&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; iss53:index.html 关于撤回操作撤回本次commit执行完commit后，想撤回本次的commit时，执行下面命令，返回到提交之前（你所写的代码依旧会保留） 12git reset --soft HEAD~1 // 撤回上次提交git reset --sort HEAD~2 // 撤销上2次提交 如果只是注释写错，想修改注释，可以执行以下命令，会进入vim窗口，然后就可以修改注释了 1git commit --amend 文件的误操作(退回到某个版本)查看git的日志，可以查看近期的详细操作日志 1git log git的简易日志，前面的commitid 1git reflog git版本回退，注意此时的回退是回退到commitid那个版本 1git reset --hard 【commitid】 比较推荐的一个git命令学习网站 git一些常见的错误]]></content>
      <categories>
        <category>后台</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一些常用的工具类]]></title>
    <url>%2F2019%2F09%2F19%2F%E4%B8%80%E4%BA%9B%E5%B8%B8%E7%94%A8%E7%9A%84%E5%B7%A5%E5%85%B7%E7%B1%BB%2F</url>
    <content type="text"><![CDATA[下面为大家介绍一些常用的apache工具类（轮子工厂）2333~apache轮子工厂]]></content>
      <categories>
        <category>后台</category>
      </categories>
      <tags>
        <tag>java基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java文件流操作]]></title>
    <url>%2F2019%2F09%2F18%2FJava%E6%96%87%E4%BB%B6%E6%B5%81%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[文件流的分类1. 字节流所有字节流实现类都继承自抽象类InputStream和OutputStream，下面是一些常用的字节流（输入流和输出流都是一一对应的） FileInputStream：实现对文件字节的读取操作 ByteArrayInputStream：把内存中的一个缓冲区作为输入源，从内存数组中读取数据字节（一般用来操作用户的输入）。 ObjectInputStream：将用ObjectOutputStream写入的的文件读取出来，序列化的类应实现Serializable接口 PipeInputStream：实现了管道的概念，从线程通道中读取线程字节。主要在线程中使用，用于两个线程间通信。 SequenceInputStream：表示其他输入流的逻辑串联。它从输入流的有序集合开始，并从第一个输入流开始读取，直到到达文件末尾，接着从第二个输入流读取，依次类推，直到到达包含的最后一个输入流的文件末尾为止。 System.in：从用户控制台读取数据字节，在System类中，in是 InputStream 类的静态导入。 12345678910111213141516// 获取输入流InputStream fis = new FileInputStream(&quot;D:/a.png&quot;); // 获取输出流OutputStream fos = new FileOutputStream(&quot;D:/b.png&quot;); // 临时存放字节的数组byte[] bytes = new byte[1024];// 检查是否到达文件尾（字节流到达文件为返回-1）int i;while ((i = fis.read(bytes)) != -1)&#123; // 实际上底层都是调用write(bytes, 0, bytes.length()) fos.write(bytes); &#125;// 关闭输入流fis.close();// 关闭输出流fos.close(); 2. 字符流字符流和字节流使用基本相同，只不过字符流都是继承自抽象类Reader和Writer（一般用来处理文本文件） 1234567891011Reader reader = new FileReader(&quot;D:/a.txt&quot;);Writer writer = new FileWriter(&quot;D:/b.txt&quot;);char[] chars = new char[1024];int i;while ((i = reader.read(chars)) != -1)&#123; writer.write(chars);&#125;writer.flush();reader.close(); writer.close(); 3. 缓冲流字节流和字符流都是直接对文件源进行操作（文件—》程序—》文件），这样会受制于硬盘的读写速度，缓冲流则是把流读出的数据先缓存到内存中，等达到缓冲区指定大小或执行flush操作时，将数据一次性写入文件 字节缓冲流 123456789101112BufferedInputStream bis = new BufferedInputStream(new FileInputStream(&quot;D:/a.txt&quot;));BufferedOutputStream bos = new BufferedOutputStream(new FileOutputStream(&quot;D:/b.txt&quot;));byte[] bytes = new byte[2048];int i;while ((i = bis.read(bytes)) != -1)&#123; // 底层都是调用write（byte[] b, int off, int len）方法，循环写入bytes bos.write(bytes); // 刷新缓冲区的输出流，使所有缓冲的输出字节写出到底层输入流 bos.flush(); &#125;bis.close();bos.close(); 字符缓冲流 1234567891011BufferedReader br = new BufferedReader(new FileReader(&quot;D:/a.txt&quot;));BufferedWriter bw = new BufferedWriter(new FileWriter(&quot;D:/b.txt&quot;));String line;while ((line = br.readLine()) != null)&#123; // 写入一行 bw.write(line); // 换行 bw.newLine(); &#125;br.close();bw.close(); 参考：https://www.cnblogs.com/jmcui/p/9096536.html]]></content>
      <categories>
        <category>后台</category>
      </categories>
      <tags>
        <tag>java基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker笔记之环境的安装(一)]]></title>
    <url>%2F2019%2F09%2F16%2Fdocker%E7%AC%94%E8%AE%B0%E4%B9%8B%E7%8E%AF%E5%A2%83%E7%9A%84%E5%AE%89%E8%A3%85-%E4%B8%80%2F</url>
    <content type="text"><![CDATA[Centos 7下安装Docker要求CentOS 系统的内核版本高于3.10（Centos 7环境下），可以使用下方命令查看内核版本 1uname -r // 查看内核版本 确保yum包更新到最新 1yum update // 更新yum 卸载旧版本(如果安装过旧版本的话) 1yum remove docker docker-common docker-selinux docker-engine 安装需要的软件包， yum-util 提供yum-config-manager功能，另外两个是devicemapper驱动依赖的 1yum install -y yum-utils device-mapper-persistent-data lvm2 设置阿里yum源 1yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo 可以查看所有仓库中所有docker版本，并选择特定版本安装 1yum list docker-ce --showduplicates | sort -r 安装docker(自选版本安装有坑) 123yum install docker-ce // 由于repo中默认只开启stable仓库，故这里安装的是最新稳定版yum -y install docker-ce-[VERSION] // 自行选择版本yum -y install docker-ce-18.03.1.ce-1.el7.centos // 有坑，找对应自己操作系统的版本安装 启动并加入开机启动 12systemctl start dockersystemctl enable docker 验证安装是否成功(有client和service两部分表示docker安装启动都成功了) 1docker version 设置镜像加速器，提高镜像拉取速度，在阿里云有docker专属加速器地址，不过需要有一个支付宝账号登录 1vim /etc/docker/daemon.json 设置好加速器地址后，重启docker服务 12systemctl daemon-reloadsystemctl restart docker]]></content>
      <categories>
        <category>后台</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Jfinal启动项目后访问404问题]]></title>
    <url>%2F2019%2F08%2F30%2FJfinal%E5%90%AF%E5%8A%A8%E9%A1%B9%E7%9B%AE%E5%90%8E%E8%AE%BF%E9%97%AE404%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[Jfinal启动项目后访问路径报错一般情况下是jetty启动成功，但jfinal没有启动，所以显示未找到，可以再Jfinal的config中添加一句输出来查看是否启动成功 12345678910// 方法没有全部列举public class DemoConfig extends JFinalConfig &#123; // 加载配置信息 private Prop dbProp = PropKit.use(&quot;jfinal_config.txt&quot;); // 定义常量 public void configConstant(Constants me) &#123; System.out.println(&quot;进来了&quot;); me.setDevMode(true); &#125;&#125; 解决方法添加web.xml 1234567891011121314151617&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;web-app xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns=&quot;http://java.sun.com/xml/ns/javaee&quot; xsi:schemaLocation=&quot;http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_3_0.xsd&quot; id=&quot;WebApp_ID&quot; version=&quot;3.0&quot;&gt; &lt;filter&gt; &lt;filter-name&gt;jfinal&lt;/filter-name&gt; &lt;filter-class&gt;com.jfinal.core.JFinalFilter&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;configClass&lt;/param-name&gt; &lt;!--你的jfinal-Config位置--&gt; &lt;param-value&gt;com.xyn.config.DemoConfig&lt;/param-value&gt; &lt;/init-param&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;jfinal&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt;&lt;/web-app&gt; 添加后查看是否成功]]></content>
      <categories>
        <category>后台</category>
      </categories>
      <tags>
        <tag>那些年踩过的坑= =</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java多线程编程笔记（附PDF）]]></title>
    <url>%2F2019%2F08%2F20%2FJava%E5%A4%9A%E7%BA%BF%E7%A8%8B%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0%EF%BC%88%E9%99%84PDF%EF%BC%89%2F</url>
    <content type="text"><![CDATA[Java多线程编程核心技术链接：https://pan.baidu.com/s/1waW7B9PTmkNMS-qkh6LNKg 提取码：cm4i synchronizedsynchronized同步方法 方法内的变量为线程安全的（因为局部变量在栈中，又因为栈是线程私有的，线程安全） 实例变量非线程安全（实例对象存在堆中，堆是线程共享区域，非线程安全） 多个对象会有多个锁 synchronized锁可重入性（持有锁A后，可调用其它需要持有锁A的方法，若不可重入则会死锁） 出现异常时，锁会自动释放 同步不能被子类继承 synchronized同步代码块 synchronized方法的弊端（当锁住的方法执行时间特别长时，等待该锁的其他线程就需要等待较长时间，推荐使用同步代码块锁关键代码，也就是需要同步的某一块代码） 使用String对象做监视器时，应着重注意（String对象存在于常量池或堆中） 锁对象的改变（对于锁对象而言，只要这个对象没变，即使修改了它的属性，结果还是同步的。例如对于一个student对象而言，当其作为锁对象存在时，修改它的学号姓名都没有问题，结果依旧会是同步的） synchronized（非 this 对象 x）可得出三个结论： 多个线程执行synchronized（x）{}代码块时是同步效果 其它线程执行对象 x 中的synchronized方法时是同步效果 其它线程执行对象 x 中的synchronized（this）{}代码块时是同步效果 小结 synchronized（class）{} 的锁是类 synchronized（this）{} 的锁是本类的实例对象 synchronized（非 this 对象 x）{} 的锁是实例对象 x synchronized public void set() {} 的锁是本类的实例对象 synchronized public static void set() {} 的锁是类 注意：多线程情况下，只有持有相同的锁，才能达到同步效果 生产者 / 消费者模式实现原理都是基于wait和notify来实现的 一生产一消费：操作值123public class ValueObject &#123; public static String value = &quot;&quot;;&#125; 生产者 1234567891011121314151617181920212223public class P &#123; private String lock; public P(String lock)&#123; this.lock = lock; &#125; public void setValue()&#123; try &#123; synchronized (lock)&#123; if (!ValueObject.value.equals(&quot;&quot;))&#123; lock.wait(); &#125; String value = System.currentTimeMillis() + &quot;_&quot; + System.nanoTime(); ValueObject.value = value; System.out.println(&quot;set的值是：&quot; + value); lock.notify(); &#125; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 消费者 12345678910111213141516171819202122public class C &#123; private String lock; public C(String lock)&#123; this.lock = lock; &#125; public void getValue()&#123; try &#123; synchronized (lock)&#123; if (ValueObject.value.equals(&quot;&quot;))&#123; lock.wait(); &#125; String value = ValueObject.value; System.out.println(&quot;get的值是：&quot; + value); ValueObject.value = &quot;&quot;; lock.notify(); &#125; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public class Run &#123; // 单个生产者消费者 public static void main(String[] args) &#123; String lock = &quot;&quot;; P p = new P(lock); C c = new C(lock); ThreadP threadP = new ThreadP(p); ThreadC threadC = new ThreadC(c); threadP.start(); threadC.start(); &#125;&#125;class ThreadC extends Thread&#123; private C c; public ThreadC(C c)&#123; this.c = c; &#125; @Override public void run() &#123; while (true)&#123; c.getValue(); &#125; &#125;&#125;class ThreadP extends Thread&#123; private P p; public ThreadP(P p)&#123; this.p = p; &#125; @Override public void run() &#123; while (true)&#123; p.setValue(); &#125; &#125;&#125; 多生产多消费：操作值生产者 1234567891011121314151617181920212223public class P &#123; private String lock; public P(String lock)&#123; this.lock = lock; &#125; public void setValue()&#123; try &#123; synchronized (lock)&#123; while (!ValueObject.value.equals(&quot;&quot;))&#123; lock.wait(); &#125; String value = System.currentTimeMillis() + &quot;_&quot; + System.nanoTime(); ValueObject.value = value; System.out.println(&quot;生产者：&quot;+ Thread.currentThread().getName() + value); lock.notifyAll(); &#125; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 消费者 12345678910111213141516171819202122public class C &#123; private String lock; public C(String lock)&#123; this.lock = lock; &#125; public void getValue()&#123; try &#123; synchronized (lock)&#123; while (ValueObject.value.equals(&quot;&quot;))&#123; lock.wait(); &#125; String value = ValueObject.value; System.out.println(&quot;消费者：&quot;+ Thread.currentThread().getName() + value); ValueObject.value = &quot;&quot;; lock.notifyAll(); &#125; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public class Run &#123; public static void main(String[] args) throws InterruptedException &#123; String lock = &quot;&quot;; P p = new P(lock); C c = new C(lock); ThreadP[] threadP = new ThreadP[2]; ThreadC[] threadC = new ThreadC[2]; for (int i = 0; i &lt; 2; i++) &#123; threadP[i] = new ThreadP(p); threadP[i].setName(&quot;生产者&quot; + (i+1)); threadC[i] = new ThreadC(c); threadC[i].setName(&quot;消费者&quot; + (i+1)); threadP[i].start(); threadC[i].start(); &#125; &#125;&#125;class ThreadC extends Thread&#123; private C c; public ThreadC(C c)&#123; this.c = c; &#125; @Override public void run() &#123; while (true)&#123; c.getValue(); &#125; &#125;&#125;class ThreadP extends Thread&#123; private P p; public ThreadP(P p)&#123; this.p = p; &#125; @Override public void run() &#123; while (true)&#123; p.setValue(); &#125; &#125;&#125; 上述代码若使用notify唤醒单个线程，可能会造成“ 假死 ”（notify唤醒同类线程造成假死），所以使用notifyAll唤醒所有线程 多生产多消费：操作栈123456789101112131415161718192021222324252627282930public class MyStack &#123; private List list = new ArrayList(); synchronized public void push() &#123; try &#123; while (list.size() == 1) &#123; this.wait(); &#125; list.add(&quot;anything: &quot; + Math.random()); this.notifyAll(); System.out.println(&quot;push=&quot; + list.size()); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; synchronized public void pop() &#123; try &#123; while (list.size() == 0) &#123; this.wait(); &#125; System.out.println(list.get(0)); list.remove(0); this.notifyAll(); System.out.println(&quot;pop=&quot; + list.size()); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 生产者 1234567891011public class Provider &#123; private MyStack stack; public Provider(MyStack stack)&#123; this.stack = stack; &#125; public void pushService()&#123; stack.push(); &#125;&#125; 消费者 123456789101112public class Consumer &#123; private MyStack stack; public Consumer(MyStack stack)&#123; this.stack = stack; &#125; public void popService()&#123; stack.pop(); &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445public class Run &#123; public static void main(String[] args) &#123; MyStack stack = new MyStack(); Provider provider = new Provider(stack); Consumer consumer = new Consumer(stack); Provider provider1 = new Provider(stack); CThread cThread = new CThread(consumer); PThread pThread = new PThread(provider); PThread pThread1 = new PThread(provider1); cThread.start(); pThread.start(); pThread1.start(); &#125;&#125;class CThread extends Thread&#123; private Consumer consumer; public CThread(Consumer consumer) &#123; this.consumer = consumer; &#125; @Override public void run()&#123; while (true) &#123; consumer.popService(); &#125; &#125;&#125;class PThread extends Thread&#123; private Provider provider; public PThread(Provider provider)&#123; this.provider = provider; &#125; @Override public void run() &#123; while (true) &#123; provider.pushService(); &#125; &#125;&#125; Lock的使用ReentrantLock类的使用 使用ReentrantLock可以用来实现同步 12lock.lock();lock.unlock(); // 一般写在finally当中，因为出现异常锁不会自动释放 使用Condition实现等待通知（还是应当注意signal()和signalAll()的使用，避免多对多等待通知时“ 假死 ”情况的出现） 1234567891011121314151617181920212223242526public class Service &#123; private Lock lock = new ReentrantLock(); private Condition condition = lock.newCondition(); public void await()&#123; try &#123; lock.lock(); System.out.println(&quot;await时间为：&quot; + System.currentTimeMillis()); condition.await(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; lock.unlock(); &#125; &#125; public void signal()&#123; try &#123; lock.lock(); System.out.println(&quot;signal时间为：&quot; + System.currentTimeMillis()); condition.signal(); &#125; finally &#123; lock.unlock(); &#125; &#125;&#125; 实现生产者 / 消费者模式：多对多打印服务类（这里需要注意的还是condition的signalAll()方法的使用） 12345678910111213141516171819202122232425262728293031323334353637public class Service &#123; private ReentrantLock lock = new ReentrantLock(); private Condition condition = lock.newCondition(); private boolean hasValue = false; public void set()&#123; try &#123; lock.lock(); while (hasValue == true)&#123; condition.await(); &#125; System.out.println(&quot;######&quot;); hasValue = true; condition.signalAll(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; lock.unlock(); &#125; &#125; public void get()&#123; try &#123; lock.lock(); while (hasValue == false)&#123; condition.await(); &#125; System.out.println(&quot;*****&quot;); hasValue = false; condition.signalAll(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; lock.unlock(); &#125; &#125;&#125; 线程类 123456789101112131415161718192021222324252627282930313233343536373839404142434445public class Run &#123; public static void main(String[] args) &#123; Service service = new Service(); ThreadA[] a = new ThreadA[2]; ThreadB[] b = new ThreadB[2]; for (int i = 0; i &lt; 2; i++) &#123; a[i] = new ThreadA(service); b[i] = new ThreadB(service); a[i].start(); b[i].start(); &#125; &#125;&#125;class ThreadA extends Thread &#123; private Service service; public ThreadA(Service service) &#123; this.service = service; &#125; @Override public void run() &#123; super.run(); while (true) &#123; service.set(); &#125; &#125;&#125;class ThreadB extends Thread &#123; private Service service; public ThreadB(Service service) &#123; this.service = service; &#125; @Override public void run() &#123; super.run(); while (true) &#123; service.get(); &#125; &#125;&#125; Lock的公平锁与非公平锁公平锁：获取锁的顺序大致上按线程加锁顺序来执行，FIFO（先进先出）非公平锁：抢占式获取锁，先来不一定获取得到锁，有可能会导致有些线程一直获取不到锁 123// 设置公平锁与非公平锁boolean isFair = true;ReentrantLock lock = new ReentrantLock(isFair); 使用多个Condition实现顺序执行（这里可以使用signal()因为唤醒的是不同的condition） 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687public class Run &#123; volatile private static int nextPrintWho = 1; private static ReentrantLock lock = new ReentrantLock(); private static Condition conditionA = lock.newCondition(); private static Condition conditionB = lock.newCondition(); private static Condition conditionC = lock.newCondition(); public static void main(String[] args) &#123; Thread threadA = new Thread()&#123; @Override public void run() &#123; try &#123; lock.lock(); while (nextPrintWho != 1)&#123; conditionA.await(); &#125; nextPrintWho = 2; for (int i = 0; i &lt; 3; i++) &#123; System.out.println(&quot;ThreadA：&quot; + (i + 1)); &#125; conditionB.signal(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; lock.unlock(); &#125; &#125; &#125;; Thread threadB = new Thread()&#123; @Override public void run() &#123; try &#123; lock.lock(); while (nextPrintWho != 2)&#123; conditionB.await(); &#125; nextPrintWho = 3; for (int i = 0; i &lt; 3; i++) &#123; System.out.println(&quot;ThreadB：&quot; + (i + 1)); &#125; conditionC.signal(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; lock.unlock(); &#125; &#125; &#125;; Thread threadC = new Thread()&#123; @Override public void run() &#123; try &#123; lock.lock(); while (nextPrintWho != 3)&#123; conditionC.await(); &#125; nextPrintWho = 1; for (int i = 0; i &lt; 3; i++) &#123; System.out.println(&quot;ThreadC：&quot; + (i + 1)); &#125; conditionA.signal(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; lock.unlock(); &#125; &#125; &#125;; Thread[] ta = new Thread[5]; Thread[] tb = new Thread[5]; Thread[] tc = new Thread[5]; for (int i = 0; i &lt; 5; i++) &#123; ta[i] = new Thread(threadA); tb[i] = new Thread(threadB); tc[i] = new Thread(threadC); ta[i].start(); tb[i].start(); tc[i].start(); &#125; &#125;&#125; ReentrantReadWriteLock类的使用ReentrantLock具有完全互斥排他效果，好处是通过同步保证了线程安全，缺点则是效率低下。因此，JDK推出了ReentrantReadWriteLock类，在某些不需要操作实例变量方法中，可以使用ReentrantReadWriteLock来提高效率。 读写锁ReentrantReadWriteLock具有以下特点： 读读共享 读写互斥 写读互斥 写写互斥 可以通过下面的代码去自行测试： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566public class Service &#123; private static ReentrantReadWriteLock readWriteLock = new ReentrantReadWriteLock(); public static void main(String[] args) &#123; Service service = new Service(); ThreadA ta = new ThreadA(service); ta.setName(&quot;A&quot;); ta.start(); ThreadB tb = new ThreadB(service); tb.setName(&quot;B&quot;); tb.start(); &#125; synchronized public static void set() &#123; try &#123; readWriteLock.writeLock().lock(); System.out.println(&quot;这是写锁&quot; + Thread.currentThread().getName() + System.currentTimeMillis()); Thread.sleep(3000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; readWriteLock.writeLock().unlock(); &#125; &#125; public void get() &#123; try &#123; readWriteLock.readLock().lock(); System.out.println(&quot;这是读锁&quot; + Thread.currentThread().getName() + System.currentTimeMillis()); Thread.sleep(3000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; readWriteLock.readLock().unlock(); &#125; &#125;&#125;class ThreadA extends Thread &#123; private Service service; public ThreadA(Service service) &#123; this.service = service; &#125; @Override public void run() &#123; service.set(); &#125;&#125;class ThreadB extends Thread &#123; private Service service; public ThreadB(Service service) &#123; this.service = service; &#125; @Override public void run() &#123; service.set(); &#125;&#125; 总结我认为本书主要讲了Synchronize和Lock的使用，等待通知机制的各种实现，还有一些零碎的线程方法，本文并没有进行罗列。本书还讲解了上述线程操作的基本姿势，但并没有特别的深入原理，不过这本书的配套书Java并发编程则是对这本书原理的详细讲解，也算是进阶。]]></content>
      <categories>
        <category>后台</category>
      </categories>
      <tags>
        <tag>java基础</tag>
        <tag>笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之单例模式]]></title>
    <url>%2F2019%2F08%2F19%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[1. 什么是单例模式顾名思义，就是只有一个实例 2. 代码实现（懒汉式，饿汉式）懒汉式：顾名思义，就是很懒，你不找我要，我绝对不会先创建好对象，时间换空间 1234567891011121314151617public class Singleton &#123; private static Singleton singleton; // 私有构造，防止创建实例 private Singleton()&#123; &#125; // 有需要时才会去创建 public static Singleton getInstance()&#123; if(singleton == null)&#123; singleton = new Singleton(); &#125; return singleton; &#125;&#125; 饿汉式：初始化时创建，空间换时间 1234567891011121314// 饿汉式public class Singleton2 &#123; private static Singleton2 singleton = new Singleton2(); // 私有构造，防止创建实例 private Singleton2()&#123; &#125; public static Singleton2 newInstance()&#123; return singleton; &#125;&#125; 上面懒汉式在单线程环境下没有问题，但在多线程环境下就会出现多个实例的问题（也就是线程安全问题）。下面是多线程环境下的单例实现，使用了DCL双检查锁来保证正确实现（DCL是大多数多线程结合单例的解决方案）当然，这只是比较大众的实现方式，还有一些小众的方式比如：静态内部类实现、静态代码块实现、enum枚举实现等等。 1234567891011121314151617public class Singleton &#123; // 保证线程间的可见 private volatile static Singleton singleton; private Singleton()&#123;&#125; // 解决线程安全问题，但也因为加锁的原因，效率不高 public static Singleton getInstance()&#123; if(singleton == null)&#123; synchronized (Singleton.class)&#123; if (singleton == null)&#123; singleton = new Singleton(); &#125; &#125; &#125; return singleton; &#125;&#125; 单例的静态内部类实现，此方法的优点是解决了多线程加锁的效率问题 123456789101112public class Singleton &#123; private Singleton()&#123;&#125; private static class SingletonHandler&#123; private static Singleton singleton = new Singleton(); &#125; public static Singleton getInstance()&#123; return SingletonHandler.singleton; &#125;&#125; 欢迎指正~ 引用：设计模式之禅 、Java多线程编程核心技术]]></content>
      <categories>
        <category>后台</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法图解笔记（附PDF下载地址）]]></title>
    <url>%2F2019%2F08%2F08%2F%E7%AE%97%E6%B3%95%E5%9B%BE%E8%A7%A3%E7%AC%94%E8%AE%B0%EF%BC%88%E9%99%84PDF%E4%B8%8B%E8%BD%BD%E5%9C%B0%E5%9D%80%EF%BC%89%2F</url>
    <content type="text"><![CDATA[算法图解（pdf版） 链接：https://pan.baidu.com/s/1FJvija2NNmhOSpd7D3yE_g 提取码：bwcm 分治策略分治策略（分而治之）是一种解决问题的思路，使用递归实现 工作原理： 找出简单基线条件（递归中的概念，基线条件指函数不再调用自己；递归条件指函数调用自己） 缩小问题规模使接近基线条件（编写涉及数组的递归函数时，基线条件通常是数组为空或只包含一个元素。陷入困境时，请检查基线条件是不是这样的。） 代表算法：二分查找，快排 散列函数散列表适用场景 模拟映射关系 防止重复 数据缓存 注意的点 冲突很糟糕，应使用可以最大限度减少冲突的散列函数（冲突过多会影响数据查找、删除速度；严重时会退化为链表） 一旦填装因子超过0.7，就该调整散列表的长度 广度优先搜索广度优先是一种用于图的查找算法，一般用来帮助解决两类问题： 有无路径问题（从节点A出发，有到节点B的路径吗？） 最短路径问题（从节点A触发，前往节点B哪条路径最短？） 注意点 对于寻找最短路径的问题，可尝试使用图来建立模型，再使用广度优先搜索来解决问题 有向图中的边为箭头，箭头的方向指定了关系的方向 无向图中的边不带箭头，其中的关系是双向的 你需要按加入顺序检查搜索列表中的人，否则找到的就不是最短路径，因此搜索列表必须是队列 对于检查过的人，务必不要再去检查，否则可能导致无限循环（节点间的相互引用） 狄克斯特拉算法在介绍迪克斯特拉算法前，先介绍一些基础概念每条边都有关联数字的图，这些数字称为权重带权重的图称为加权图，不带权重的图称为非加权图图中可能有环狄克斯特拉算法包含4个步骤。 找出“最便宜”的节点，即可在最短时间内到达的节点 对于该节点的邻居，检查是否有前往它们的更短路径，如果有，就更新其开销 重复这个过程，直到对图中的每个节点都这样做了 计算最终路径 注意点 狄克斯特拉算法只适用于有向无环图 不能将狄克斯特拉算法用于包含负权边的图 小结 广度优先搜索用于在非加权图中查找最短路径。 狄克斯特拉算法用于在加权图中查找最短路径。 仅当权重为正时狄克斯特拉算法才管用。 如果图中包含负权边，请使用贝尔曼福德算法。 算法的Java实现 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495public class MyDijkstra &#123; private static int NOWAY_SIGN = Integer.MAX_VALUE; private static String START = &quot;start&quot;; private static String END = &quot;end&quot;; public static void main(String[] args) &#123; MyDijkstra dijkstra = new MyDijkstra(); dijkstra.getMinStep(); &#125; private void getMinStep()&#123; // 初始化 Map&lt;String, Map&lt;String, Integer&gt;&gt; grapth = grapthInit(); Map&lt;String, Integer&gt; costs = costInit(); Map&lt;String, String&gt; parents = parentInit(); // 判断是否检查过 List&lt;String&gt; processed = new ArrayList&lt;&gt;(10); // 1. 找到start的最小开销节点 String node = this.findLowestCostNode(costs,processed); // 2. 遍历该节点所有邻居并更新其开销 while (node != null &amp;&amp; grapth.get(node) != null)&#123; // 获取相邻节点 Map&lt;String, Integer&gt; xianglinjiedian = grapth.get(node); int cost = costs.get(node); for (Map.Entry&lt;String, Integer&gt; entry : xianglinjiedian.entrySet()) &#123; // 新旧开销的比较，若成功则更新 int newCost = cost + entry.getValue(); if(newCost &lt; costs.get(entry.getKey()) || !costs.containsKey(entry.getKey()))&#123; costs.put(entry.getKey(),newCost); parents.put(entry.getKey(),node); &#125; &#125; // 加入已处理节点 processed.add(node); // 找出最小开销节点 node = this.findLowestCostNode(costs,processed); &#125; System.out.println(parents); System.out.println(costs.get(END)); &#125; private String findLowestCostNode(Map&lt;String, Integer&gt; costs,List&lt;String&gt; processed)&#123; int lowestCost = NOWAY_SIGN; String lowNode = null; for (Map.Entry&lt;String, Integer&gt; entry : costs.entrySet()) &#123; // 未被处理且小于mini if(!processed.contains(entry.getKey()) &amp;&amp; entry.getValue() &lt; lowestCost)&#123; lowestCost = entry.getValue(); lowNode = entry.getKey(); &#125; &#125; return lowNode; &#125; private Map&lt;String,String&gt; parentInit() &#123; Map&lt;String,String&gt; parentInit = new HashMap&lt;&gt;(16); parentInit.put(&quot;A&quot;,START); parentInit.put(&quot;B&quot;,END); parentInit.put(END,null); return parentInit; &#125; private Map&lt;String,Integer&gt; costInit() &#123; Map&lt;String,Integer&gt; costsMap = new HashMap&lt;&gt;(16); costsMap.put(&quot;A&quot;,6); costsMap.put(&quot;B&quot;,2); costsMap.put(END,Integer.MAX_VALUE); return costsMap; &#125; // 构造有向图 private Map&lt;String, Map&lt;String,Integer&gt;&gt; grapthInit() &#123; Map&lt;String, Map&lt;String,Integer&gt;&gt; grapth = new HashMap&lt;&gt;(16); Map&lt;String,Integer&gt; startValue1 = new HashMap&lt;&gt;(2); startValue1.put(&quot;A&quot;,6); startValue1.put(&quot;B&quot;,2); grapth.put(START,startValue1); Map&lt;String,Integer&gt; startValue2 = new HashMap&lt;&gt;(2); startValue2.put(END,1); grapth.put(&quot;A&quot;,startValue2); Map&lt;String,Integer&gt; startValue3 = new HashMap&lt;&gt;(2); startValue3.put(&quot;A&quot;,3); startValue3.put(END,5); grapth.put(&quot;B&quot;,startValue3); grapth.put(END,null); return grapth; &#125;&#125; 贪婪算法 动态规划学习点 学习动态规划，这是一种解决棘手问题的方法，它将问题分成小问题，并先着手解决这些小问题 学习如何设计问题的动态规划解决方案 工作原理 先解决子问题，再逐渐解决大问题 课后答案9.1 假设你还可偷另外一件商品——MP3播放器，它重1磅，价值1000美元。你要偷吗？ 不要，因为重1磅的吉他价值1500磅，所有偷Mp3播放器在本题中目前没有意义 9.2 假设你要去野营。你有一个容量为6磅的背包，需要决定该携带下面的哪些东西。其中每样东西都有相应的价值，价值越大意味着越重要： 水（重3磅，价值10） 书（重1磅，价值3） 食物（重2磅，价值9） 夹克（重2磅，价值5） 相机（重1磅，价值6）请问携带哪些东西时价值最高？ 1 2 3 4 5 6 水 10（水） 10（水） 10（水） 10（水） 书 3（书） 3（书） 10（水） 13（水、书） 13（水、书） 13（水、书 食物 3（书） 9（食物） 11（书、食物） 13（水、书） 19（水、食物） 22（水、书、食物） 夹克 3（书） 9（食物） 11（书、食物） 14（食物、夹克） 19（水、食物） 22（水、书、食物） 相机 6（相机） 9（书、相机） 15（食物、相机） 17（书、食物、相机） 20（食物、夹克、相机） 25（水、食物、相机） 9.3 请绘制并填充用来计算blue和clues最长公共子串的网格 最长公共子串： b l u e c 0 0 0 0 l 0 1 0 0 u 0 0 2 0 e 0 0 0 3 s 0 0 0 0 最长公共子序列： b l u e c 0 0 0 0 l 0 1 1 1 u 0 1 2 3 e 0 1 2 3 s 0 1 2 3 背包问题启示 每种动态规划解决方案都涉及网格。 单元格中的值通常就是你要优化的值。在前面的背包问题中，单元格的值为商品的价值。 每个单元格都是一个子问题，因此你应考虑如何将问题分成子问题，这有助于你找出网格的坐标轴。 小结 需要在给定约束条件下优化某种指标时，动态规划很有用。 问题可分解为离散子问题时，可使用动态规划来解决。 每种动态规划解决方案都涉及网格。 单元格中的值通常就是你要优化的值。 每个单元格都是一个子问题，因此你需要考虑如何将问题分解为子问题。 没有放之四海皆准的计算动态规划解决方案的公式]]></content>
      <categories>
        <category>后台</category>
      </categories>
      <tags>
        <tag>java基础</tag>
        <tag>笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql开启慢查询日志]]></title>
    <url>%2F2019%2F08%2F06%2Fmysql%E5%BC%80%E5%90%AF%E6%85%A2%E6%9F%A5%E8%AF%A2%E6%97%A5%E5%BF%97%2F</url>
    <content type="text"><![CDATA[mysql开启慢查询日志https://www.cnblogs.com/jiqing9006/p/9098181.html 解读慢查询日志：https://www.cnblogs.com/sunss/p/6548588.html]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tcp三次握手和四次挥手（乞丐版）]]></title>
    <url>%2F2019%2F08%2F06%2FTcp%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B%E5%92%8C%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B%EF%BC%88%E4%B9%9E%E4%B8%90%E7%89%88%EF%BC%89%2F</url>
    <content type="text"><![CDATA[三次握手 为了准确无误地将数据送达目标处，TCP 协议采用了三次握手（three-way handshaking）策略。用 TCP 协议把数据包送出去后，TCP不会对传送后的情况置之不理，它一定会向对方确认是否成功送达。 握手过程中使用了 TCP 的标志（flag） —— SYN（synchronize） 和ACK（acknowledgement）。发送端首先发送一个带 SYN 标志的数据包给对方。接收端收到后，回传一个带有 SYN/ACK 标志的数据包以示传达确认信息。最后，发送端再回传一个带 ACK 标志的数据包，代表“握手”结束。 若在握手过程中某个阶段莫名中断，TCP 协议会再次以相同的顺序发送相同的数据包。 简易过程：客户端—》发送标有SYN数据包—》一次握手—》服务端服务端—》发送标有SYN/ACK数据包—》二次握手—》客户端客户端—》发送标有ACK数据包—》三次握手—》服务端 目的：三次握手是为了保证双方数据的可靠传输（即客户端和服务器接收与发送都正常） 第一次握手：Client什么也不能确认；Server确认对方发送正常，自己接收正常 第二次握手：Client确认自己发送、接收正常，对方发送、接收正常；Server确认对方发送正常，自己接收正常 第三次握手：Client确认自己发送、接收正常，对方发送、接收正常；Server确认对方发送、接收正常，自己发送、接收正常 四次挥手图解： 简易过程 客户端—发送一个 FIN，用来关闭客户端到服务器的数据传送 服务器—收到这个 FIN，它发回一个 ACK，确认序号为收到的序号加1。和 SYN 一样，一个 FIN 将占用一个序号 服务器—关闭与客户端的连接，发送一个 FIN 给客户端 客户端—发回 ACK 报文确认，并将确认序号设置为收到序号加1 目的任何一方都可以在数据传送结束后发出连接释放的通知，待对方确认后进入半关闭状态。当另一方也没有数据再发送的时候，则发出连接释放通知，对方确认后就完全关闭了TCP连接。 客户端发送连接释放报文，停止发送数据，进入FIN-WAIT-1（终止等待状态）； 服务器收到连接释放报文，发送确认报文并进入CLOSE-WAIT（关闭等待）状态（此时若服务器发送数据，客户端依旧需要接收） 客户端收到确认报文后，进入FIN-WAIT-2（终止等待2）状态，等待服务器发送连接释放报文 服务器将最后的数据发送完毕后，就向客户端发送连接释放报文，当服务器不再发送数据后，就进入了LAST-ACK（最后确认）状态，等待客户端的确认。 客户端收到服务器的连接释放报文后，必须发出确认报文。此时，客户端就进入了TIME-WAIT（时间等待）状态。 服务器只要收到了客户端发出的确认，立即进入CLOSED状态。结束了这次的TCP连接。 引用：https://snailclimb.gitee.io/javaguide/#/network/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C?id=_24k引用：https://blog.csdn.net/qzcsu/article/details/72861891]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>tcp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[http返回结果的状态码]]></title>
    <url>%2F2019%2F08%2F06%2Fhttp%E8%BF%94%E5%9B%9E%E7%BB%93%E6%9E%9C%E7%9A%84%E7%8A%B6%E6%80%81%E7%A0%81%2F</url>
    <content type="text"><![CDATA[类别 原因短语 1XX Infomational（信息性状态码） 接收的请求正在处理 2XX success（成功状态码） 请求正常处理完毕 3XX redirection（重定向状态码） 需进行附加操作完成请求 4XX client error（客户端错误状态码） 服务器无法处理请求 5XX server error（服务器错误状态码） 服务器处理请求出错]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>http</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[http无状态协议如何保存用户状态]]></title>
    <url>%2F2019%2F08%2F05%2Fhttp%E6%97%A0%E7%8A%B6%E6%80%81%E5%8D%8F%E8%AE%AE%E5%A6%82%E4%BD%95%E4%BF%9D%E5%AD%98%E7%94%A8%E6%88%B7%E7%8A%B6%E6%80%81%2F</url>
    <content type="text"><![CDATA[http无状态协议如何保存用户状态？HTTP 是一种不保存状态，即无状态（stateless）协议。HTTP 协议自身不对请求和响应之间的通信状态进行保存。也就是说在 HTTP 这个级别，协议对于发送过的请求或响应都不做持久化处理 常见的有以下两种解决方案： 基于Session实现的会话保持 在会话开始时（客户端第一次像服务器发送http请求），服务器将会话状态保存起来（本机内存或数据库中），然后分配一个会话标识（SessionId）给客户端，这个会话标识一般保存在客户端Cookie中，以后每次浏览器发送http请求都会带上Cookie中的SessionId到服务器，服务器拿到会话标识就可以把之前存储在服务器端的状态信息与会话联系起来，实现会话保持（如果遇到浏览器禁用Cookie的情况，则可以通过url重写的方式将会话标识放在url的参数里，也可实现会话保持） 基于Cookie实现的会话保持基于Cookie实现会话保持与上述基于Session实现会话保持的最主要区别是前者完全将会话状态信息存储在浏览器Cookie中，这样一来每次浏览器发送HTTP请求的时候都会带上状态信息，因此也就可以实现状态保持。 两者优缺点 基于Session的会话保持优点是安全性较高，因为状态信息保存在服务器端。缺点是不便于服务器的水平扩展。大型网站的后台一般都不止一台服务器，可能几台甚至上百台，浏览器发送的HTTP请求一般要先通过负载均衡器才能到达具体的后台服务器，这就会导致每次HTTP请求可能落到不同的服务器上，比如说第一次HTTP请求落到server1上，第二次HTTP请求落到server2上。而Session默认是存储在服务器本机内存的，当多次请求落到不同的服务器上时，上述方案就不能实现会话保持了（常用解决方案是中间件，例如Redis，将Session的信信息存储在Redis中，这样每个server就都可以访问到）。 基于Cookie的会话保持的优点是服务器不用保存状态信息，减轻服务端存储压力，也便于服务端做水平扩展。缺点是不够安全，因为状态信息是存储在客户端的，这意味着不能在会话中保存机密数据，另一个缺点是每次HTTP请求都需要发送额外的Cookie到服务端，会消耗更多带宽。 参考：https://blog.csdn.net/hzjjames/article/details/81143934参考：图解http 链接：https://pan.baidu.com/s/1VtKk1E9TpRzvi6XLWLQM9A提取码：pn3z]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>http</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java8新特性之Optional类（三）]]></title>
    <url>%2F2019%2F08%2F04%2FJava8%E6%96%B0%E7%89%B9%E6%80%A7%E4%B9%8BOptional%E7%B1%BB%EF%BC%88%E4%B8%89%EF%BC%89%2F</url>
    <content type="text"><![CDATA[简介 Optional 类是一个可以为null的容器对象。如果值存在则isPresent()方法会返回true，调用get()方法会返回该对象。 Optional 是个容器：它可以保存类型T的值，或者仅仅保存null。Optional提供很多有用的方法，这样我们就不用显式进行空值检测。 Optional 类的引入很好的解决空指针异常。 常用API static Optional of(T value) 创建一个 Optional 实例 123456@Test public void test1()&#123; // 创建一个 Optional 实例 Optional&lt;User&gt; optionalUser = Optional.of(new User()); System.out.println(optionalUser.get()); &#125; static Optional empty() 返回空的 Optional 实例。 1234567@Test public void test2()&#123; // 创建一个空的 Optional 实例 // (可以更精准的定位空指针位置) Optional&lt;User&gt; optionalUser = Optional.empty(); System.out.println(optionalUser.get()); &#125; static Optional ofNullable(T value) 如果不为空，返回 Optional 描述的指定值，否则返回空的 Optional。 12345678910@Test public void test3()&#123; // 如果不为空，返回 Optional 描述的指定值，否则返回空的 Optional。 // (可以更精准的定位空指针位置) Optional&lt;User&gt; optionalUser = Optional.ofNullable(new User()); System.out.println(optionalUser.get()); Optional&lt;User&gt; optionalUser2 = Optional.ofNullable(null); System.out.println(optionalUser2.get()); &#125; boolean isPresent() 如果值存在则方法会返回true，否则返回 false。 1234567891011@Test public void test4()&#123; // isPresent（）如果值存在则方法会返回true，否则返回 false。 Optional&lt;User&gt; optionalUser = Optional.ofNullable(new User()); if(optionalUser.isPresent())&#123; System.out.println(optionalUser.get()); &#125;else&#123; System.out.println(&quot;OptionalUser中无值&quot;); &#125; &#125; T orElse(T other) 如果存在该值，返回值， 否则返回 other。 1234567891011@Test public void test5()&#123; // T orElse(T other) 如果存在该值，返回值， 否则返回 other。 Optional&lt;User&gt; optionalUser1 = Optional.ofNullable(new User(&quot;zyn&quot;,20)); User user1 = optionalUser1.orElse(new User(&quot;xyn&quot;, 20)); System.out.println(user1); Optional&lt;User&gt; optionalUser2 = Optional.ofNullable(null); User user2 = optionalUser2.orElse(new User(&quot;zyn&quot;, 20)); System.out.println(user2); &#125; T orElseGet(Supplier&lt;? extends T&gt; other) 如果存在该值，返回值， 否则触发 other，并返回 other 调用的结果。 123456789101112@Test public void test6()&#123; // T orElseGet(Supplier&lt;? extends T&gt; other) // 如果存在该值，返回值， 否则触发 other，并返回 other 调用的结果。 Optional&lt;User&gt; optionalUser1 = Optional.ofNullable(new User(&quot;zyn&quot;,20)); User user1 = optionalUser1.orElseGet(() -&gt; new User(&quot;xyn&quot;,20)); System.out.println(user1); Optional&lt;User&gt; optionalUser2 = Optional.ofNullable(null); User user2 = optionalUser2.orElse(new User(&quot;xyn&quot;, 20)); System.out.println(user2); &#125; Optional map(Function&lt;? super T,? extends U&gt; mapper) 如果有值，则对其进行处理，并返回处理后的Optional，否则返回空Optional。 12345678910111213@Test public void test7()&#123; // &lt;U&gt;Optional&lt;U&gt; map(Function&lt;? super T,? extends U&gt; mapper) // 如果有值，则对其进行处理，并返回处理后的Optional // 否则返回空Optional。 Optional&lt;User&gt; optionalUser1 = Optional.ofNullable(new User(&quot;zyn&quot;,20)); Optional&lt;String&gt; name1 = optionalUser1.map(User::getName); System.out.println(name1.get()); Optional&lt;User&gt; optionalUser2 = Optional.ofNullable(null); Optional&lt;String&gt; name2 = optionalUser2.map(User::getName); System.out.println(name2.get()); &#125; Optional flatMap(Function&lt;? super T,Optional&gt; mapper) 与map类似，要求返回值必须是Optional 123456789101112@Testpublic void test8()&#123; // &lt;U&gt; Optional&lt;U&gt; flatMap(Function&lt;? super T,Optional&lt;U&gt;&gt; mapper) // 与map类似，要求返回值必须是Optional Optional&lt;User&gt; optionalUser1 = Optional.ofNullable(new User(&quot;zyn&quot;,20)); Optional&lt;String&gt; name1 = optionalUser1.flatMap(u -&gt; Optional.of(u.getName())); System.out.println(name1.get()); Optional&lt;User&gt; optionalUser2 = Optional.ofNullable(null); Optional&lt;String&gt; name2 = optionalUser2.flatMap(u -&gt; Optional.of(u.getName())); System.out.println(name2.get());&#125; 更多api：https://www.runoob.com/java/java8-optional-class.html 视频：https://www.bilibili.com/video/av35195879]]></content>
      <categories>
        <category>后台</category>
      </categories>
      <tags>
        <tag>java基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java8新特性之Stream流（二）]]></title>
    <url>%2F2019%2F08%2F03%2FJava8%E6%96%B0%E7%89%B9%E6%80%A7%E4%B9%8BStream%E6%B5%81%EF%BC%88%E4%BA%8C%EF%BC%89%2F</url>
    <content type="text"><![CDATA[简介 Java 8 API添加了一个新的抽象称为流Stream，可以让你以一种声明的方式处理数据。 Stream 使用一种类似用 SQL 语句从数据库查询数据的直观方式来提供一种对 Java 集合运算和表达的高阶抽象。 Stream API可以极大提高Java程序员的生产力，让程序员写出高效率、干净、简洁的代码。 这种风格将要处理的元素集合看作一种流， 流在管道中传输， 并且可以在管道的节点上进行处理， 比如筛选， 排序，聚合等。 元素流在管道中经过中间操作（intermediate operation）的处理，最后由最终操作(terminal operation)得到前面处理的结果。 语法Stream流的三个操作步骤 创建Stream一个数据源（如：集合，数组），获取一个流 中间操作一个中间链，对数据源数据进行处理 终止操作一个终止操作，执行中间链，并产生结果创建stream 12345678910111213141516171819202122@Test public void test()&#123; // 1. 通过collection的stream() List&lt;String&gt; list = new ArrayList&lt;&gt;(); Stream&lt;String&gt; stream = list.stream(); // 2. 通过Arrays的stream() User[] users = new User[10]; Stream&lt;User&gt; stream2 = Arrays.stream(users); // 3. 通过Stream的静态方法of() Stream&lt;String&gt; stream3 = Stream.of(&quot;aa&quot;, &quot;bb&quot;, &quot;cc&quot;); // 4. 创建无限流 // 迭代 Stream&lt;Integer&gt; stream4 = Stream.iterate(0, x -&gt; x + 2); stream4.limit(10).forEach(System.out::println); // 生成 Stream.generate(() -&gt; Math.random()) .limit(10).forEach(System.out::println); &#125; 中间操作多个中间操作可以连接起来形成一个流水线，除非流水线上触发终止操作，否则中间操作不会执行任何处理！而在终止操作时一次性全部处理，称为：“惰性求值”。 筛选与切片 filter—接收Lambda，从流中排除某些元素 12345678910111213@Test public void test()&#123; List&lt;User&gt; users = Arrays.asList(new User(&quot;xyn&quot;,20), new User(&quot;zyn&quot;,20)); // 中间操作，不会执行任何操作 Stream&lt;User&gt; userStream = users.stream() .filter(user -&gt; &#123; System.out.println(&quot;Stream 操作&quot;); return user.getAge() &gt; 19; &#125;); // 终止操作：一次性执行全部内容，即惰性求值 userStream.forEach(System.out::println); &#125; limit—截断流，使其元素不超过给定数量 12345678910111213@Test public void test()&#123; List&lt;User&gt; users = Arrays.asList(new User(&quot;xyn&quot;,20), new User(&quot;zyn&quot;,20)); // 中间操作，不会执行任何操作 users.stream() .filter(user -&gt; &#123; System.out.println(&quot;短路&quot;); return user.getAge() &gt; 19; &#125;) .limit(2) .forEach(System.out::println); &#125; skip（n）—跳过元素，返回一个扔掉了n个元素的流，若流中元素不足n个，则返回一个空流，与limit（n）互补 12345678910@Test public void test()&#123; List&lt;User&gt; users = Arrays.asList(new User(&quot;xyn&quot;,20), new User(&quot;zyn&quot;,20)); // 中间操作，不会执行任何操作 users.stream() .filter(user -&gt; user.getAge() &gt; 18) .skip(1) .forEach(System.out::println); &#125; distinct—筛选，通过流所生成元素的hashcode（）和equals（）去除重复元素 1234567891011@Test public void test()&#123; List&lt;User&gt; users = Arrays.asList(new User(&quot;xyn&quot;,20), new User(&quot;zyn&quot;,20)); // 中间操作，不会执行任何操作 users.stream() .filter(user -&gt; user.getAge() &gt; 18) .skip(1) .distinct() .forEach(System.out::println); &#125; 映射 map—接收Lambda，将元素转换为其他形式或提取信息，接收一个函数做参数该函数会被应用到每个参数上，并将其映射成一个新的元素 123456789101112131415161718192021222324252627282930@Test public void test1()&#123; List&lt;User&gt; users = Arrays.asList(new User(&quot;xyn&quot;,20), new User(&quot;zyn&quot;,20)); users.stream() .map(User::getName) .forEach(System.out::println); &#125;@Test public void test2()&#123; List&lt;String&gt; list = Arrays.asList(&quot;aaa&quot;, &quot;bbb&quot;, &quot;ccc&quot;); Stream&lt;Stream&lt;Character&gt;&gt; streamStream = list.stream() .map(TestStreamAPI3::filterCharacter); streamStream.forEach(action -&gt; &#123; action.forEach(System.out::println); &#125;); &#125;// 将字符串转化为字符流 private static Stream&lt;Character&gt; filterCharacter(String str)&#123; List&lt;Character&gt; list = new ArrayList&lt;&gt;(10); for (char c : str.toCharArray()) &#123; list.add(c); &#125; return list.stream(); &#125; flatMap—接收一个函数作为参数，将流中的每个值都换成另一个流，然后把这些流连接成一个流 1234567891011121314151617181920// 与上方map形成对比@Test public void test3()&#123; List&lt;String&gt; list = Arrays.asList(&quot;aaa&quot;, &quot;bbb&quot;, &quot;ccc&quot;); Stream&lt;Character&gt; stream = list.stream() .flatMap(TestStreamAPI3::filterCharacter); stream.forEach(System.out::println); &#125; // 将字符串转化为字符流 private static Stream&lt;Character&gt; filterCharacter(String str)&#123; List&lt;Character&gt; list = new ArrayList&lt;&gt;(10); for (char c : str.toCharArray()) &#123; list.add(c); &#125; return list.stream(); &#125; 排序 sorted—自然排序 123456@Test public void test()&#123; // 自然排序 List&lt;String&gt; list = Arrays.asList(&quot;bbb&quot;, &quot;aaa&quot;, &quot;ccc&quot;); list.stream().sorted().forEach(System.out::println); &#125; sorted（Comparator com）—定制排序 1234567891011121314151617@Test public void test()&#123; // 定制排序 List&lt;User&gt; users = Arrays.asList(new User(&quot;xyn&quot;,20), new User(&quot;zyn&quot;,20)); // 进行排序的对象必须实现Comparable接口(否则会报错) // users.stream().sorted().forEach(System.out::println); users.stream().sorted((u1,u2) -&gt; &#123; if(u1.getAge() == u2.getAge())&#123; return u1.getName().compareTo(u2.getName()); &#125;else&#123; return u1.getAge().compareTo(u2.getAge()); &#125; &#125;).forEach(System.out::println); &#125; 终止操作 查找与匹配 allMatch—检查是否匹配所有元素 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667public class User &#123; private String name; private Integer age; private Status status; public User(String name, Integer age) &#123; this.name = name; this.age = age; &#125; public User(String name, Integer age, Status status) &#123; this.name = name; this.age = age; this.status = status; &#125; public User() &#123; &#125; public Status getStatus() &#123; return status; &#125; public void setStatus(Status status) &#123; this.status = status; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public Integer getAge() &#123; return age; &#125; public void setAge(Integer age) &#123; this.age = age; &#125; @Override public String toString() &#123; return &quot;User&#123;&quot; + &quot;name=&apos;&quot; + name + &apos;\&apos;&apos; + &quot;, age=&quot; + age + &quot;, status=&quot; + status + &apos;&#125;&apos;; &#125; public enum Status&#123; FREE, BUSY, VOCATION; &#125;&#125; @Test public void test()&#123; List&lt;User&gt; users = Arrays.asList(new User(&quot;xyn&quot;,20, User.Status.BUSY), new User(&quot;zyn&quot;,20, User.Status.FREE)); boolean b = users.stream() .allMatch(e -&gt; e.getStatus().equals(User.Status.BUSY)); System.out.println(b); &#125; anyMatch—检查是否至少匹配一个元素 12345678@Test public void test()&#123; List&lt;User&gt; users = Arrays.asList(new User(&quot;xyn&quot;,20, User.Status.BUSY), new User(&quot;zyn&quot;,20, User.Status.FREE)); boolean b = users.stream() .anyMatch(e -&gt; e.getStatus().equals(User.Status.BUSY)); System.out.println(b); &#125; noneMatch—检查是否没有匹配所有元素 12345678@Test public void test()&#123; List&lt;User&gt; users = Arrays.asList(new User(&quot;xyn&quot;,20, User.Status.BUSY), new User(&quot;zyn&quot;,20, User.Status.FREE)); boolean b = users.stream() .noneMatch(e -&gt; e.getStatus().equals(User.Status.BUSY)); System.out.println(b); &#125; findFirst—返回第一个元素 12345678@Test public void test()&#123; List&lt;User&gt; users = Arrays.asList(new User(&quot;xyn&quot;,20, User.Status.BUSY), new User(&quot;zyn&quot;,20, User.Status.FREE)); Optional&lt;User&gt; optionalUser = users.stream() .findFirst(); System.out.println(optionalUser.get()); &#125; findAny—返回当前流中的任意元素 123456789@Test public void test()&#123; List&lt;User&gt; users = Arrays.asList(new User(&quot;xyn&quot;,20, User.Status.BUSY), new User(&quot;zyn&quot;,20, User.Status.FREE)); Optional&lt;User&gt; optionalUser = users.stream() .filter(e -&gt; e.getStatus().equals(User.Status.FREE)) .findAny(); System.out.println(optionalUser.get()); &#125; count—返回流中元素的总个数 12345678@Test public void test()&#123; List&lt;User&gt; users = Arrays.asList(new User(&quot;xyn&quot;,20, User.Status.BUSY), new User(&quot;zyn&quot;,20, User.Status.FREE)); long count = users.stream() .count(); System.out.println(count); &#125; max—返回流中的最大值 12345678@Test public void test()&#123; List&lt;User&gt; users = Arrays.asList(new User(&quot;xyn&quot;,20, User.Status.BUSY), new User(&quot;zyn&quot;,20, User.Status.FREE)); Optional&lt;User&gt; max = users.stream() .max((u1, u2) -&gt; Integer.compare(u1.getAge(), u2.getAge())); System.out.println(max.get()); &#125; min—返回流中的最小值 123456789@Test public void test()&#123; List&lt;User&gt; users = Arrays.asList(new User(&quot;xyn&quot;,20, User.Status.BUSY), new User(&quot;zyn&quot;,20, User.Status.FREE)); Optional&lt;Integer&gt; min = users.stream() .map(User::getAge) .min(Integer::compareTo); System.out.println(min.get()); &#125; 归约与收集（重要） reduce(T identity, BinaryOperator) / reduce(BinaryOperator)—可以将六中的元素反复结合起来，得到一个值 123456789101112131415@Test public void test()&#123; List&lt;Integer&gt; list = Arrays.asList(1, 2, 3, 4, 5, 6, 7, 8, 9); List&lt;User&gt; users = Arrays.asList(new User(&quot;xyn&quot;,20, User.Status.BUSY), new User(&quot;zyn&quot;,20, User.Status.FREE)); Integer sum = list.stream() .reduce(0, (x, y) -&gt; x + y); System.out.println(sum); // 求年龄的和 Optional&lt;Integer&gt; optional = users.stream() .map(User::getAge) .reduce(Integer::sum); System.out.println(optional.get()); &#125; collect—将流转化为其他形式。接收一个Collector接口的实现，用于给Stream中的元素做汇总的方法 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071@Test public void test()&#123; List&lt;User&gt; users = Arrays.asList(new User(&quot;xyn&quot;,20, User.Status.BUSY), new User(&quot;zyn&quot;,20, User.Status.FREE), new User(&quot;ayn&quot;,40, User.Status.FREE)); // 放入集合 List&lt;String&gt; list = users.stream() .map(User::getName) .collect(Collectors.toList()); list.forEach(System.out::println); // 总和(年龄) Integer count = users.stream() .collect(Collectors.summingInt(User::getAge)); System.out.println(count); // 平均值（年龄） Double avg = users.stream() .collect(Collectors.averagingInt(User::getAge)); System.out.println(avg); // 最大值（年龄） Optional&lt;Integer&gt; max = users.stream() .map(User::getAge) .collect(Collectors.maxBy((u1, u2) -&gt; Integer.compare(u1, u2))); System.out.println(max.get()); // 最小值（年龄） Optional&lt;Integer&gt; min = users.stream() .map(User::getAge) .collect(Collectors.minBy((u1, u2) -&gt; Integer.compare(u1, u2))); System.out.println(min.get()); // 分组（按状态） Map&lt;User.Status, List&lt;User&gt;&gt; collect = users.stream() .collect(Collectors.groupingBy(User::getStatus)); System.out.println(collect); // 多级分组（先状态，后年龄） Map&lt;User.Status, Map&lt;String, List&lt;User&gt;&gt;&gt; collect1 = users.stream() .collect(Collectors.groupingBy(User::getStatus, Collectors.groupingBy(e -&gt; &#123; if (((User) e).getAge() &lt;= 35) &#123; return &quot;青年&quot;; &#125; else &#123; return &quot;中年&quot;; &#125; &#125;))); System.out.println(collect1); // 分区(按年龄分，大于20在一个区，其余在一个区) Map&lt;Boolean, List&lt;User&gt;&gt; collect2 = users.stream() .collect(Collectors.partitioningBy(e -&gt; e.getAge() &gt; 20)); System.out.println(collect2); // 功能统计 DoubleSummaryStatistics collect3 = users.stream() .collect(Collectors.summarizingDouble(User::getAge)); System.out.println(collect3.getMax()); System.out.println(collect3.getAverage()); System.out.println(collect3.getCount()); System.out.println(collect3.getSum()); // 连接（姓名） String collect4 = users.stream() .map(User::getName) .collect(Collectors.joining(&quot;,&quot;)); System.out.println(collect4); &#125; 视频：https://www.bilibili.com/video/av35195879]]></content>
      <categories>
        <category>JavaSE</category>
      </categories>
      <tags>
        <tag>java基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java8新特性之Lambda表达式（一）]]></title>
    <url>%2F2019%2F08%2F02%2FJava8%E6%96%B0%E7%89%B9%E6%80%A7%E4%B9%8BLambda%E8%A1%A8%E8%BE%BE%E5%BC%8F%EF%BC%88%E4%B8%80%EF%BC%89%2F</url>
    <content type="text"><![CDATA[简介 Lambda表达式可称为闭包， Lambda允许把函数作为一个方法的参数（函数作为参数传递进方法中）。 使用Lambda表达式可以使代码变的更加简洁紧凑。 语法 (parameters) -&gt; expression 或 (parameters) -&gt;{ statements; } Java8中引入了一个新的操作符，”-&gt;”，该操作符称为箭头操作符或者Lambda操作符，箭头操作符将Lambda表达式拆分成两部分； 左侧： Lambda表达式的参数列表，对应的是接口中抽象方法的参数列表； 右侧： Lambda表达式中所需要执行的功能(Lambda体)，对应的是对抽象方法的实现；(函数式接口(只能有一个抽象方法)) Lambda表达式的实质是对接口的实现； 使用及示例示例使用匿名内部类: 123456Comparator&lt;Integer&gt;com = new Comparator&lt;Integer&gt;() &#123; @Override public int compare(Integer o1, Integer o2) &#123; //降序排列 return Integer.compare(o2,o1); &#125;&#125;; 使用Lambda表达式 1Comparator&lt;Integer&gt; com = (x, y) -&gt; Integer.compare(y, x); 用法 (一) 接口中的抽象方法 : 无参数，无返回值；例如：Runnable接口下的run方法 123456789Runnable run = new Runnable() &#123; @Override public void run() &#123; System.out.println(&quot;hello&quot;); &#125; &#125;// lambda形式Runnable runnable = () -&gt; System.out.println(&quot;hello&quot;); (二) 接口中的抽象方法 : 一个参数且无返回值； (若只有一个参数，那么小括号可以省略不写) 123// lambda形式Consumer&lt;String&gt; con = (x) -&gt; System.out.println(x);con.accept(&quot;hello&quot;); (三) 两个参数，有返回值，并且有多条语句： 要用大括号括起来，而且要写上return 12345678Comparator&lt;Integer&gt; comparator = (x,y) -&gt; &#123; System.out.println(&quot;函数式接口&quot;); return Integer.compare(x,y); &#125;; Integer[] nums = &#123;4,2,8,1,5&#125;; Arrays.sort(nums,com); System.out.println(Arrays.toString(nums)); (四) 两个参数，有返回值，但是只有一条语句: 大括号省略，return省略 1234Comparator&lt;Integer&gt; comparator = (x,y) -&gt; Integer.compare(x,y);Integer[] nums = &#123;4,2,8,1,5&#125;;Arrays.sort(nums,com);System.out.println(Arrays.toString(nums)); (五) Lambda表达式的参数列表的数据类型 可以省略不写，因为JVM编译器通过上下文推断出数据类型，即”类型推断”， (Integer x,Integer y) -&gt; Integer.compare(x,y)可以简写成(x,y) -&gt; Integer.compare(x,y)； 函数式接口 只有一个抽象方法的接口称为函数式接口； 可以使用注解@FunctionlInterface来标识，可以检查是否为函数式接口；例如：1234@FunctionalInterfacepublic interface MyFunction &#123; String getValue(String str);&#125; 四大内置函数式接口如果使用Lambda还要自己写一个接口的话太麻烦，所以Java自己提供了一些接口: Consumer&lt; T &gt; con消费性接口 : void accept(T t)； Supplier&lt; T &gt; sup供给型接口 : T get； Function&lt; T , R &gt; fun函数式接口 : R apply (T t)； Predicate&lt; T &gt; 断言形接口 : boolean test(T t)； Consumer&lt; T &gt;con消费性接口有参数，没有返回值 12345678@Test public void test()&#123; this.happy(1000,(m) -&gt; System.out.println(&quot;消费&quot; + m + &quot;元&quot;)); &#125; private void happy(double money, Consumer&lt;Double&gt; consumer)&#123; consumer.accept(money); &#125; Supplier&lt; T &gt;sup 供给型接口无参数，有返回值需求：产生指定个数随机数放入集合中 12345678910111213141516171819@Test public void test()&#123; List&lt;Integer&gt; list = this.getNumList(10,() -&gt; (int)(Math.random() * 100)); // 遍历，lambda消费性写法 list.forEach((num) -&gt; System.out.println(num)); /*for (Integer num : list) &#123; System.out.println(integer); &#125;*/ &#125; private List&lt;Integer&gt; getNumList(int num, Supplier&lt;Integer&gt; supplier)&#123; List&lt;Integer&gt; list = new ArrayList&lt;&gt;(num); for (int i = 0; i &lt; num; i++) &#123; Integer n = supplier.get(); list.add(n); &#125; return list; &#125; Function&lt; T , R &gt;fun函数式接口有参数，有返回值需求：字符串去空格 123456789@Test public void test3()&#123; String str = this.strHandler(&quot; xyn &quot;, s -&gt; s.trim()); System.out.println(str); &#125; private String strHandler(String str, Function&lt;String, String&gt; function)&#123; return function.apply(str); &#125; Predicate&lt; T &gt;断言形接口有参数，有返回值（布尔型）需求：取出长度大于3的字符串放入新集合 123456789101112131415161718@Test public void test4()&#123; List&lt;String&gt; list = Arrays.asList(&quot;xyn&quot;, &quot;zyn&quot;, &quot;abcde&quot;, &quot;a&quot;, &quot;bb&quot;); list = this.filterStr(list, s -&gt; s.length() &gt; 3); list.forEach(action -&gt; System.out.println(action)); &#125; private List&lt;String&gt; filterStr(List&lt;String&gt; strList, Predicate&lt;String&gt; predicate)&#123; List&lt;String&gt; list = new ArrayList&lt;&gt;(strList.size()); strList.forEach(action -&gt; &#123; if(predicate.test(action))&#123; list.add(action); &#125; &#125;); return list; &#125; 方法引用，构造器引用，数组引用方法引用使用前提: Lambda体中调用方法的参数列表和返回值类型，要和函数式接口中抽象方法的参数列表和返回值类型保持一致； 语法格式(一) 对象::实例方法名 123456789PrintStream ps = System.out; Consumer&lt;String&gt; con = x -&gt; ps.println(x); con.accept(&quot;xyn&quot;); // 简写 Consumer&lt;String&gt; con1 = ps::println; con1.accept(&quot;xyn&quot;); // 更加简写 Consumer&lt;String&gt; con2 = System.out::println; con2.accept(&quot;zyn&quot;); 实例2 1234567891011@Testpublic void test()&#123; User user = new User(&quot;zyn&quot;,20); Supplier&lt;String&gt; sup = () -&gt; user.getName(); String name = sup.get(); System.out.println(name); // 简写 Supplier&lt;Integer&gt; sup2 = user::getAge; Integer age = sup2.get(); System.out.println(age);&#125; 语法格式(二) 类名::静态方法 12345@Test public void test()&#123; Comparator&lt;Integer&gt; com = (x, y) -&gt; Integer.compare(x, y); Comparator&lt;Integer&gt; com2 = Integer::compare; &#125; 语法格式(三) 类名::实例方法名注意: 若Lambda参数列表中的第一个参数是实例方法的第一个调用者，而第二个参数是实例方法的参数时，可以使用ClassName :: method。 12345678@Test public void test()&#123; BiPredicate&lt;String, String&gt; biPredicate = (x, y) -&gt; x.equals(y); System.out.println(biPredicate.test(&quot;xyn&quot;,&quot;xyn&quot;)); BiPredicate&lt;String, String&gt; biPredicate2 = String::equals; System.out.println(biPredicate2.test(&quot;zyn&quot;,&quot;zyn&quot;)); &#125; 构造器引用语法：ClassName::new注意：需要调用构造器的参数列表，要与函数式接口中的抽象方法的参数列表保持一致； 123456789101112@Test public void test5()&#123; Supplier&lt;User&gt; supplier = () -&gt; new User(&quot;xyn&quot;,20); // 构造器引用方式(调用无参构造) Supplier&lt;User&gt; supplier2 = User::new; BiFunction&lt;String,Integer,User&gt; biFunction = (x, y) -&gt; new User(x,y); biFunction.apply(&quot;zyn&quot;,20); // 构造器引用方式(调用有参构造) BiFunction&lt;String,Integer,User&gt; biFunction2 = User::new; biFunction2.apply(&quot;zyn&quot;,20); &#125; 数组引用语法：Type[]::new 12345678@Test public void test()&#123; Function&lt;Integer,String[]&gt; function = x -&gt; new String[x]; System.out.println(function.apply(10).length); // 数组引用方式 Function&lt;Integer,String[]&gt; function2 = String[]::new; System.out.println(function.apply(10).length); &#125; 参考：https://blog.csdn.net/zxzxzx0119/article/details/82392396视频：https://www.bilibili.com/video/av35195879]]></content>
      <categories>
        <category>后台</category>
      </categories>
      <tags>
        <tag>java基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LinkedList源码个人笔记]]></title>
    <url>%2F2019%2F07%2F31%2FLinkedList%E6%BA%90%E7%A0%81%E4%B8%AA%E4%BA%BA%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[简介 LinkedList底层是链表实现的，所以增删快（插入高效），查询慢。 LinkedList继承自AbstractSequentialList，实现了List，Deque，Cloneable，Serializable。 LinkedList继承AbstractSequentialList，实现LIst，实现了增加，删除，修改，遍历功能。 LinkedList实现Deque，实现首位添加删除，末尾添加删除等功能。所以它也是一个双端链表，也可以当做队列来使用。 Cloneable，Serializable都是标志接口，接口内没有任何内容。Cloneable标志着ArrayList重写了Object类的clone方法实现拷贝，而Serializable则标志ArrayList支持序列化。 核心源码内部类LinkedList中数据的载体，用来存放数据。节点Node有三个属性：前驱节点、后继节点、节点值。 123456789101112131415private static class Node&lt;E&gt; &#123; // 节点值 E item; // 后继节点 Node&lt;E&gt; next; // 前驱结点 Node&lt;E&gt; prev; // 构造赋值 Node(Node&lt;E&gt; prev, E element, Node&lt;E&gt; next) &#123; this.item = element; this.next = next; this.prev = prev; &#125; &#125; 基本参数12345678910public class LinkedList&lt;E&gt; extends AbstractSequentialList&lt;E&gt; implements List&lt;E&gt;, Deque&lt;E&gt;, Cloneable, java.io.Serializable&#123; // 链表实际大小 transient int size = 0; // 头结点 transient Node&lt;E&gt; first; // 尾节点 transient Node&lt;E&gt; last; 构造方法123456789// 无参构造public LinkedList() &#123; &#125;// 有参构造，传入Collection类public LinkedList(Collection&lt;? extends E&gt; c) &#123; this(); addAll(c); //在下方有解释 &#125; add方法（重要）1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253 public boolean add(E e) &#123; linkLast(e); return true; &#125;// 添加到链尾void linkLast(E e) &#123; final Node&lt;E&gt; l = last; // 存储新元素 final Node&lt;E&gt; newNode = new Node&lt;&gt;(l, e, null); // 尾节点替换 last = newNode; if (l == null) // 空链表，头结点赋值 first = newNode; else // 非空链表，为原尾节点赋值后继节点 l.next = newNode; size++; modCount++; &#125;// add重载方法，插入指定位置public void add(int index, E element) &#123; // 越界检查 checkPositionIndex(index); if (index == size) // 插入位置是否为链表尾 linkLast(element); else linkBefore(element, node(index)); &#125; // 插入非空节点succ之前（succ为原index位置节点） void linkBefore(E e, Node&lt;E&gt; succ) &#123; // assert succ != null; // 取出succ的前驱节点 final Node&lt;E&gt; pred = succ.prev; // 添加新节点，前驱为succ前驱节点，后继为succ节点 final Node&lt;E&gt; newNode = new Node&lt;&gt;(pred, e, succ); // 修改succ前驱节点为新节点 succ.prev = newNode; // 判断succ节点是否为头结点 if (pred == null) first = newNode; else pred.next = newNode; size++; modCount++; &#125; addAll方法（重要）123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public boolean addAll(Collection&lt;? extends E&gt; c) &#123; return addAll(size, c); &#125;public boolean addAll(int index, Collection&lt;? extends E&gt; c) &#123; // 越界检查 checkPositionIndex(index); Object[] a = c.toArray(); int numNew = a.length; // 传入空集合 if (numNew == 0) return false; Node&lt;E&gt; pred, succ; // 判断插入位置是否为尾节点 if (index == size) &#123; succ = null; pred = last; &#125; else &#123; succ = node(index); pred = succ.prev; &#125; for (Object o : a) &#123; @SuppressWarnings(&quot;unchecked&quot;) E e = (E) o; Node&lt;E&gt; newNode = new Node&lt;&gt;(pred, e, null); // 插入位置是否为头结点 if (pred == null) first = newNode; else pred.next = newNode; pred = newNode; &#125; // 插入位置是否为链表尾部 if (succ == null) &#123; last = pred; &#125; else &#123; // 将链表连接起来 pred.next = succ; succ.prev = pred; &#125; size += numNew; modCount++; return true; &#125; get方法get方法获取元素 越界检查 index与链表长度大小比较确定遍历位置 遍历链表，取出内容123456789101112131415161718192021public E get(int index) &#123; // 索引越界检查 checkElementIndex(index); return node(index).item; &#125;Node&lt;E&gt; node(int index) &#123; // assert isElementIndex(index); // 判断索引与中位数的大小关系，确定从头遍历还是从尾遍历 if (index &lt; (size &gt;&gt; 1)) &#123; Node&lt;E&gt; x = first; for (int i = 0; i &lt; index; i++) x = x.next; return x; &#125; else &#123; Node&lt;E&gt; x = last; for (int i = size - 1; i &gt; index; i--) x = x.prev; return x; &#125; &#125; 总结LinkedList增删快，查询慢（以node节点属性决定），线程不安全 2019-11-3自己手写了一个简单的LinkedList，实现了一些基础的功能，简单的迭代器遍历等 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117public class MyLinkedList&lt;T&gt; implements Iterable&lt;T&gt; &#123; private Node startNode; private Node endNode; private int size; static class Node&lt;T&gt; &#123; private Node prev; private Node next; private T data; public Node(T data, Node prev, Node next) &#123; this.prev = prev; this.next = next; this.data = data; &#125; &#125; public boolean add(T data) &#123; if (endNode == null) &#123; Node&lt;T&gt; node = new Node&lt;&gt;(data, null, null); startNode = node; endNode = node; &#125; else &#123; Node&lt;T&gt; node = new Node&lt;&gt;(data, endNode, null); endNode.next = node; endNode = node; &#125; size++; return true; &#125; public T get(int index) &#123; this.checkIndex(index); return this.getNode(index).data; &#125; public void checkIndex(int index) &#123; if (index &lt; 0 || index &gt;= size) throw new RuntimeException("越界"); &#125; public boolean remove(int index) &#123; this.checkIndex(index); Node&lt;T&gt; node = this.getNode(index); Node prev = node.prev; Node next = node.next; if (prev == null) &#123; startNode = next; &#125; else &#123; prev.next = next; node.prev = null; &#125; if (next == null) &#123; endNode = prev; &#125; else &#123; next.prev = prev; node.prev = null; &#125; node.data = null; size--; return true; &#125; private Node&lt;T&gt; getNode(int index) &#123; Node&lt;T&gt; node; if (index &lt; size / 2) &#123; node = startNode; for (int i = 0; i &lt; index; i++) &#123; node = node.next; &#125; &#125; else &#123; node = endNode; for (int i = size - 1; i &gt; index; i--) &#123; node = node.prev; &#125; &#125; return node; &#125; // 实现迭代器 @Override public Iterator&lt;T&gt; iterator() &#123; return new Iterator&lt;T&gt;() &#123; private int index = 0; @Override public boolean hasNext() &#123; return index &lt; size; &#125; @Override public T next() &#123; T t = get(index); index++; return t; &#125; @Override public void remove() &#123; MyLinkedList.this.remove(index); &#125; &#125;; &#125; @Override public void forEach(Consumer&lt;? super T&gt; action) &#123; &#125; @Override public Spliterator&lt;T&gt; spliterator() &#123; return null; &#125;&#125; 参考：https://snailclimb.gitee.io/javaguide/#/java/collection/LinkedList]]></content>
      <categories>
        <category>后台</category>
      </categories>
      <tags>
        <tag>java基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[为什么Object数组无法被强制转换]]></title>
    <url>%2F2019%2F07%2F29%2F%E4%B8%BA%E4%BB%80%E4%B9%88Object%E6%95%B0%E7%BB%84%E6%97%A0%E6%B3%95%E8%A2%AB%E5%BC%BA%E5%88%B6%E8%BD%AC%E6%8D%A2%2F</url>
    <content type="text"><![CDATA[今天在进行数组的强制类型转换的时候爆了个异常Exception in thread “main” java.lang.ClassCastException: [Ljava.lang.Object; cannot be cast to [Ljava.lang.String;直接上代码。 ArrayList中的错误案例List的toArray返回的数组无法被强制转换 12345678List&lt;String&gt; nameList = new ArrayList&lt;String&gt;(2); nameList.add(&quot;xyn&quot;); nameList.add(&quot;zyn&quot;); // 会有问题，Object类型数组无法被强制转换 String[] nameArray = (String[])nameList.toArray(); for (String name : nameArray) &#123; System.out.println(name); &#125; 正确写法：使用ArrayList的toArray(T[] a)方法; 12345678910List&lt;String&gt; nameList = new ArrayList&lt;String&gt;(2); nameList.add(&quot;xyn&quot;); nameList.add(&quot;zyn&quot;); // 传入接收参数的数组，长度为nameList的size // 这是一个泛型方法，会返回对应类型的数组 String[] nameArray = new String[nameList.size()]; nameList.toArray(nameArray); for (String name : nameArray) &#123; System.out.println(name); &#125; 原因强制类型转换成功的条件是 ：被强制类型转换的实例需要是强制类型转换类型的类或者其子类。 一维类数组存放的是一组连续的地址引用，因此如果是取返回的Object数组其中每一个进行强制类型转换也没问题，因为每一个含义是Object name = new String(“xyn”)；底层没有问题，但nameList.toArray()返回值类型就定下来了是Object类型，也就只能确定返回的数组是Object[]类型但不知道是具体那个类型，因为要在内存开辟空间，因此强制类型转换成String[]也就出错。 参考： https://blog.csdn.net/hhhebbb/article/details/88813769]]></content>
      <categories>
        <category>后台</category>
      </categories>
      <tags>
        <tag>java基础</tag>
        <tag>那些年踩过的坑= =</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[oracle中不能插入&amp;的问题]]></title>
    <url>%2F2019%2F07%2F26%2Foracle%E4%B8%AD%E4%B8%8D%E8%83%BD%E6%8F%92%E5%85%A5%26%E7%9A%84%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[oracle插入字段不能插入&amp;的问题，比如下边这个语句&amp;就不能被插入 123update app_item_img set icon = &apos;method=queryImg&amp;imgName=grid_operation&apos;where id = &apos;test&apos; 可以改用chr(38)来改写替换，如下 123update app_item_img set icon = &apos;method=queryImg&apos;||chr(38)||&apos;imgName=grid_operation&apos;where id = &apos;test&apos;]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>那些年踩过的坑= =</tag>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HashMap源码个人笔记]]></title>
    <url>%2F2019%2F07%2F24%2FHashMap%E6%BA%90%E7%A0%81%E4%B8%AA%E4%BA%BA%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[简介 HashMap用来存放键值对，是基于哈希表的Map接口的实现 HashMap继承自AbstractMap，实现了Map，Cloneable，Serializable接口 Cloneable，Serializable都是标志接口，接口内没有任何内容。Cloneable标志着HashMap重写了Object类的clone方法实现拷贝，而Serializable则标志HashMap支持序列化 核心源码基本参数12345678910111213141516171819202122232425262728public class HashMap&lt;K,V&gt; extends AbstractMap&lt;K,V&gt; implements Map&lt;K,V&gt;, Cloneable, Serializable &#123; private static final long serialVersionUID = 362498820763181265L; // 默认初始容量 static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // aka 16 // 最大容量 static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30; // 默认负载因子 static final float DEFAULT_LOAD_FACTOR = 0.75f; // 转化为树的阈值 static final int TREEIFY_THRESHOLD = 8; // 从树转化为链表的阈值 static final int UNTREEIFY_THRESHOLD = 6; // 树的最小容量 static final int MIN_TREEIFY_CAPACITY = 64; // 存储元素的数组，总是2的幂次方倍 transient Node&lt;K,V&gt;[] table; // 存放具体元素的集 transient Set&lt;Map.Entry&lt;K,V&gt;&gt; entrySet; // 存放元素的数量，不等于数组的长度 transient int size; // 每次扩容和更改map结构的计数器 transient int modCount; // 临界值，实际大小（容量*负载因子）超过此值触发扩容 int threshold; // 实际负载因子 final float loadFactor; 构造方法1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253// 默认构造，定义负载因子public HashMap() &#123; this.loadFactor = DEFAULT_LOAD_FACTOR; // all other fields defaulted &#125;// 有参构造，指定初始容量和默认负载因子public HashMap(int initialCapacity) &#123; this(initialCapacity, DEFAULT_LOAD_FACTOR); &#125;// 有参构造，指定初始容量和负载因子public HashMap(int initialCapacity, float loadFactor) &#123; // 边界限定 if (initialCapacity &lt; 0) throw new IllegalArgumentException(&quot;Illegal initial capacity: &quot; + initialCapacity); if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException(&quot;Illegal load factor: &quot; + loadFactor); this.loadFactor = loadFactor; this.threshold = tableSizeFor(initialCapacity); &#125;// 有参构造，传入一个Map进行构造public HashMap(Map&lt;? extends K, ? extends V&gt; m) &#123; this.loadFactor = DEFAULT_LOAD_FACTOR; putMapEntries(m, false); &#125;final void putMapEntries(Map&lt;? extends K, ? extends V&gt; m, boolean evict) &#123; // 获取插入的map的size int s = m.size(); // 判断该map的size大小 if (s &gt; 0) &#123; // 判断表是否为空表 if (table == null) &#123; // pre-size float ft = ((float)s / loadFactor) + 1.0F; int t = ((ft &lt; (float)MAXIMUM_CAPACITY) ? (int)ft : MAXIMUM_CAPACITY); if (t &gt; threshold) threshold = tableSizeFor(t); &#125; else if (s &gt; threshold) resize(); for (Map.Entry&lt;? extends K, ? extends V&gt; e : m.entrySet()) &#123; K key = e.getKey(); V value = e.getValue(); putVal(hash(key), key, value, false, evict); &#125; &#125; &#125; put方法（重要）12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758public V put(K key, V value) &#123; return putVal(hash(key), key, value, false, true); &#125;final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; // 判断表是否为空表 if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; // (n - 1) &amp; hash确定位置并判断此位置有无节点 if ((p = tab[i = (n - 1) &amp; hash]) == null) // 无节点，直接插入 tab[i] = newNode(hash, key, value, null); else &#123; // 有节点 Node&lt;K,V&gt; e; K k; // 判断hash和key是否相等 if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) // 相等，直接替换 e = p; // 判断是否为红黑树节点 else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); // 为链表节点，遍历链表 else &#123; for (int binCount = 0; ; ++binCount) &#123; if ((e = p.next) == null) &#123; // 节点为空，直接插入 p.next = newNode(hash, key, value, null); // 判断是否到达红黑树转化阈值（8） if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; if (e != null) &#123; // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; ++modCount; // 判断实际容量是否大于阈值（是否需要扩容） if (++size &gt; threshold) resize(); // 访问回调 afterNodeInsertion(evict); return null; &#125; resize扩容方法（重要）12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273final Node&lt;K,V&gt;[] resize() &#123; Node&lt;K,V&gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; if (oldCap &gt; 0) &#123; if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return oldTab; &#125; else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // double threshold &#125; else if (oldThr &gt; 0) // initial capacity was placed in threshold newCap = oldThr; else &#123; // zero initial threshold signifies using defaults newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; if (newThr == 0) &#123; float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; threshold = newThr; @SuppressWarnings(&#123;&quot;rawtypes&quot;,&quot;unchecked&quot;&#125;) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; if (oldTab != null) &#123; for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) &#123; oldTab[j] = null; if (e.next == null) newTab[e.hash &amp; (newCap - 1)] = e; else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else &#123; // preserve order Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do &#123; next = e.next; if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab; &#125; 总结 HashMap维护的是键值对，jdk1.8是用数组+链表+红黑树存储的，相较于1.7数组+链表，避免了极端情况下退化为链表查询的问题 重写了Object的hash方法，通过传入key的hash来确定存放（替换）位置 最影响性能的是扩容方法，知晓需要存入的数据的长度，应在构造时设置好HashMap的容量(若不知道具体长度也应在构造时给予构造初值16)，减少扩容提高效率 参考：https://snailclimb.gitee.io/javaguide/#/java/collection/HashMap]]></content>
      <categories>
        <category>后台</category>
      </categories>
      <tags>
        <tag>java基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何使用油猴插件白*视频网站哇啊皮]]></title>
    <url>%2F2019%2F07%2F18%2F%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8%E6%B2%B9%E7%8C%B4%E6%8F%92%E4%BB%B6%E7%99%BD-%E8%A7%86%E9%A2%91%E7%BD%91%E7%AB%99%E5%93%87%E5%95%8A%E7%9A%AE%2F</url>
    <content type="text"><![CDATA[准备工作 谷歌浏览器，火狐浏览器，360浏览器（其中之一），别的我不知道行不行 油猴插件 链接: https://pan.baidu.com/s/15OXBLU0jcRPfAe2f9ysgZQ 提取码: gsx2 vip脚本文件（搜索vip即可） https://greasyfork.org/zh-CN 开始 油猴插件下载后，解压出来 打开谷歌浏览器，点击右上角自定义控制按钮==》更多工具==》扩展程序 进入后打开开发者模式，然后加载扩展程序 加载油猴文件夹 进入脚本网站下载（搜索vip，点击下载就阔以） 打开网站会有对应角标,点击解析跳转,完成]]></content>
      <categories>
        <category>随笔</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[==和equals的区别]]></title>
    <url>%2F2019%2F07%2F18%2F%3D%3D%E5%92%8Cequals%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[Java中判断两个变量是否相等有两种方式，分别是 == 和 equals ==的使用基本数据类型基本数据类型指的是byte，short，int，long，float，double，char，boolean。对这些基本数据类型判断是：值是否相等 123int a = 10; Double b = 10.0D; System.out.println(a == b); // true 引用数据类型引用类型指的是继承自Object类的对象。对于引用数据类型判断是：内存地址是否相等，即是否同一个对象 123String s1 = new String(&quot;zyn&quot;);String s2 = new String(&quot;zyn&quot;);System.out.println(s1 == s2); // false equals()的使用equals()是基类Object的方法，所有继承自Object类的对象都可使用，一般会被继承类所重写，用来实现特定的比较。我们看一下Object类中equals的实现，可以看到如果未重写equals方法，判断两个对象的内存地址是否相等 1234// Object类中的equals实现public boolean equals(Object obj) &#123; return (this == obj);&#125; 再来看一下String类是否重写了equals()方法 123456789101112131415161718192021public boolean equals(Object anObject) &#123; if (this == anObject) &#123; return true; &#125; if (anObject instanceof String) &#123; String anotherString = (String)anObject; int n = value.length; if (n == anotherString.value.length) &#123; char v1[] = value; char v2[] = anotherString.value; int i = 0; while (n-- != 0) &#123; if (v1[i] != v2[i]) return false; i++; &#125; return true; &#125; &#125; return false; &#125; 我们可以看到，String类重写了equals()方法，判断的是传入对象的字符串是否相等。 123String s1 = new String(&quot;zyn&quot;);String s2 = new String(&quot;zyn&quot;);System.out.println(s1.equals(s2)); // true 关于String的equals方法这里应注意:str.equals(“zyn”)这种写法有可能会出现NullPointerException，应改为zyn.equals(str)这种写法来避免异常 总结判断两个对象是否为同一对象，两个基本数据类型是否相等使用==判断两个对象的内容是否相等，则需要重写equals实现相应逻辑]]></content>
      <tags>
        <tag>java基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ArrayList源码个人笔记]]></title>
    <url>%2F2019%2F07%2F14%2FArrayList%E6%BA%90%E7%A0%81%E4%B8%AA%E4%BA%BA%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[简介 ArrayList底层是数组实现的，所以特性也是查询快增删慢。但和数组不同的是它可以实现动态增长，在知晓数据的大概容量时可使用ensureCapacity方法进行手动扩容。 ArrayList继承自AbstractList，实现了List，RandomAccess，Cloneable，Serializable接口 ArrayList继承AbstractList，实现LIst，实现了增加，删除，修改，遍历等功能。 RandomAccess，Cloneable，Serializable都是标志接口，接口内没有任何内容。其中RandomAccess标志着ArrayList实现了随机访问，Cloneable标志着ArrayList重写了Object类的clone方法实现拷贝，而Serializable则标志ArrayList支持序列化。 核心源码基本参数1234567891011121314151617181920212223242526272829public class ArrayList&lt;E&gt; extends AbstractList&lt;E&gt; implements List&lt;E&gt;, RandomAccess, Cloneable, java.io.Serializable&#123; private static final long serialVersionUID = 8683452581122892189L; /** * 默认初始容量 */ private static final int DEFAULT_CAPACITY = 10; /** * 空数组. */ private static final Object[] EMPTY_ELEMENTDATA = &#123;&#125;; /** * */ private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = &#123;&#125;; /** * 真正用于保存数据的数组 */ transient Object[] elementData; /** * ArrayList包含的元素数量 */ private int size; 构造方法123456789101112131415161718192021222324252627282930313233// 无参构造public ArrayList() &#123; this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA; &#125;// 有参构造，指定初始容量public ArrayList(int initialCapacity) &#123; // 参数的合法性校验 if (initialCapacity &gt; 0) &#123; // 创建长度为initialCapacity的数组 this.elementData = new Object[initialCapacity]; &#125; else if (initialCapacity == 0) &#123; // 数组为EMPTY_ELEMENTDATA（空数组） this.elementData = EMPTY_ELEMENTDATA; &#125; else &#123; throw new IllegalArgumentException(&quot;Illegal Capacity: &quot;+ initialCapacity); &#125; &#125;// 传入参数（集合），构造为ArrayListpublic ArrayList(Collection&lt;? extends E&gt; c) &#123; elementData = c.toArray(); if ((size = elementData.length) != 0) &#123; // 数组的长度不为0 // c.toArray可能返回的不是object类型数组 if (elementData.getClass() != Object[].class) elementData = Arrays.copyOf(elementData, size, Object[].class); &#125; else &#123; // 如果传入的集合长度为0，替换为空数组. this.elementData = EMPTY_ELEMENTDATA; &#125; &#125; trimToSize修剪此ArrayList实例的容量为最合适值，节约空间 12345678910public void trimToSize() &#123; modCount++; if (size &lt; elementData.length) &#123; // 下边可能刚看有点迷，可以看我注掉的这个，会直观一些 // elementData = ((size == 0) ? EMPTY_ELEMENTDATA : Arrays.copyOf(elementData, size)); elementData = (size == 0) ? EMPTY_ELEMENTDATA : Arrays.copyOf(elementData, size); &#125; &#125; add方法和grow方法（重要）扩容方法是ArrayList中最核心方法，它最影响性能，所以在知晓数据存储量的情况下，应设置ArrayList的初始容量来避免扩容 12345678910111213141516171819202122232425262728293031323334353637383940414243public boolean add(E e) &#123; // 内部容量担保 ensureCapacityInternal(size + 1); // 将元素放入底层数组的size++位置，就是数组赋值 elementData[size++] = e; return true; &#125; // 内部容量担保private void ensureCapacityInternal(int minCapacity) &#123; if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) &#123; // 若底层数组和默认容量数组是一样的，则将最小容量指定为10 // 这个判断一般只在数组为指定容量第一次添加元素时进入 minCapacity = Math.max(DEFAULT_CAPACITY, minCapacity); &#125; ensureExplicitCapacity(minCapacity); &#125; // 判断是否需要扩容 private void ensureExplicitCapacity(int minCapacity) &#123; modCount++; // 判断最小容量是否大于底层数组长度 if (minCapacity - elementData.length &gt; 0) // 扩容方法 grow(minCapacity); &#125;// 扩容方法private void grow(int minCapacity) &#123; // 旧容量的赋值 int oldCapacity = elementData.length; // 新容量赋值为旧容量的1.5倍 int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); // 判断新容量是否大于最小容量 if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; // 判断新容量是否大于数组最大容量 if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); // 将旧数组的数据转移到新数组中 elementData = Arrays.copyOf(elementData, newCapacity); &#125; add的重载方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051// index：插入的位置，element：插入的元素// 慎用，每一次写入都会造成数组的复制和迁移，如果大数据量的情况下非常影响性能public void add(int index, E element) &#123; // 索引检查 rangeCheckForAdd(index); // 内部容量担保 ensureCapacityInternal(size + 1); // Increments modCount!! // 将elementData数组的index位置及其后的所有元素，插入到elementData数组的inde+1位置 // 其实就是把index位置空出来，把原来index及其后的元素集合向后错一位 System.arraycopy(elementData, index, elementData, index + 1, size - index); elementData[index] = element; size++; &#125;// 将集合填入到ArrayList中public boolean addAll(Collection&lt;? extends E&gt; c) &#123; Object[] a = c.toArray(); int numNew = a.length; // 内部容量担保 ensureCapacityInternal(size + numNew); // Increments modCount // 将集合数组插入到ArrayList的size开始的位置，插入数量为numNew // 从ArrayList的尾部插入 System.arraycopy(a, 0, elementData, size, numNew); // size的改变 size += numNew; return numNew != 0; &#125;// 将集合从指定位置填入ArrayList中// 慎用public boolean addAll(int index, Collection&lt;? extends E&gt; c) &#123; rangeCheckForAdd(index); Object[] a = c.toArray(); int numNew = a.length; // 内部容量担保 ensureCapacityInternal(size + numNew); // Increments modCount // 取出偏移量 int numMoved = size - index; if (numMoved &gt; 0) // 进行偏移 System.arraycopy(elementData, index, elementData, index + numNew, numMoved); // 将新传入的集合从指定位置开始插入 System.arraycopy(a, 0, elementData, index, numNew); size += numNew; return numNew != 0; &#125; 总结ArrayList查询快，增删慢（数组扩容、移位导致），线程不安全核心是扩容机制 tips：如果知晓需要存入的数据的长度，应在构造时设置好ArrayList的容量，减少扩容提高效率 记得看到过一个面试题，如何让一个数组快速实现元素去重？把元素数组转为List，然后把List放入Set中就可以快速实现啦 参考：https://snailclimb.gitee.io/javaguide/#/java/collection/ArrayList?id=arraylist%E7%AE%80%E4%BB%8B]]></content>
      <categories>
        <category>后台</category>
      </categories>
      <tags>
        <tag>java基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之策略模式]]></title>
    <url>%2F2019%2F07%2F12%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E7%AD%96%E7%95%A5%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[1. 什么是策略模式定义算法族，分别封装起来，使他们之间可以相互替换 2. 设计原则 封装变化 多用组合，少用继承 针对接口编程 3. 使用场景 针对同一类型问题的多种处理方式，仅仅是具体行为有差别时； 需要安全地封装多种同一类型的操作时； 出现同一抽象类有多个子类，而又需要使用 if-else 或者 switch-case 来选择具体子类时。 4. 代码实现（诸葛亮的锦囊妙计，每一个锦囊就是一个策略。）UML类图：算法（妙计）接口： 12345public interface IStrategy &#123; //每个锦囊妙计都是一个可执行的算法 public void operate();&#125; 算法（妙计）类 123456public class BackDoor implements IStrategy &#123; @Override public void operate() &#123; System.out.println(&quot;找乔国老帮忙，让吴国太给孙权施加压力&quot;); &#125;&#125; 123456public class GivenGreenLight implements IStrategy &#123; @Override public void operate() &#123; System.out.println(&quot;求吴国太开个绿灯,放行！&quot;); &#125;&#125; 123456public class BlockEnemy implements IStrategy &#123; @Override public void operate() &#123; System.out.println(&quot;孙夫人断后，挡住追兵&quot;); &#125;&#125; 锦囊类 123456789101112public class Context &#123; //构造函数，你要使用那个妙计 private IStrategy straegy; public Context(IStrategy strategy)&#123; this.straegy = strategy; &#125; //使用计谋了，看我出招了 public void operate()&#123; this.straegy.operate(); &#125;&#125; 具体的使用类（赵云） 1234567891011121314public class ZhaoYun &#123; public static void main(String[] args) &#123; Context context; context = new Context(new BackDoor()); // 第一个妙计 context.operate(); // 第二个妙计 context = new Context(new GivenGreenLight()); context.operate(); // 第三个妙计 context = new Context(new BlockEnemy()); context.operate(); &#125;&#125; 5. 优缺点及总结优点： 算法（锦囊）可自由切换 避免了多重条件判断（if else和switch） 扩展性良好 缺点： 可维护性差（随着策略类的增多变得难以维护） 使用者必须了解所有算法的区别及使用场景 总结： 2019.7.13与Collection的sort方法和Arrays的sort方法传入相应的comparator作为参数的道理十分相似，传入相应的排序策略达到排序目的，使用者了解自己传入的comparator参数的作用，很能体现策略模式的思想。 欢迎指正~ 引用：设计模式之禅引用：http://ifeve.com/strategy-design-pattern-in-java-example-tutorial/]]></content>
      <categories>
        <category>后台</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[为什么Java许多项目的工具类都是抽象的？]]></title>
    <url>%2F2019%2F07%2F12%2F%E4%B8%BA%E4%BB%80%E4%B9%88Java%E8%AE%B8%E5%A4%9A%E9%A1%B9%E7%9B%AE%E7%9A%84%E5%B7%A5%E5%85%B7%E7%B1%BB%E9%83%BD%E6%98%AF%E6%8A%BD%E8%B1%A1%E7%9A%84%EF%BC%9F%2F</url>
    <content type="text"><![CDATA[为什么项目里许多工具类都定义为抽象类防止创建实例因为他是工具类，提供的方法肯定都是static的，一般直接由class.method()调用，防止其直接创建实例。 为什么项目里会出现一些common包公共模块方便统一维护实习的时候学到了许多东西，感觉最深的就是编码的一些规范（这也是后台老大一直跟我们强调的）。在今天看项目的时候突然开窍（哈哈哈，隔了好几个月才开窍）。公司的项目后台老大把项目中的拦截器，自定义注解，自定义异常，登录校验，切面的一些东西都放到了一个叫common的包下，当时还很疑惑（因为自己写的时候都是直接放在项目目录下，不会去细分一些东西）也不明白当时大佬的意思（可能这就是菜鸡吧= =），今天突然想到，根本就是公共的东西，本就应该放在一起方便管理嘛。]]></content>
      <categories>
        <category>后台</category>
      </categories>
      <tags>
        <tag>java基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springboot拦截器的使用]]></title>
    <url>%2F2019%2F07%2F09%2Fspringboot%E6%8B%A6%E6%88%AA%E5%99%A8%E7%9A%84%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[使用场景处理所有请求的共性问题，例如： 解决乱码问题 解决权限验证问题 如何使用 编写拦截器类TestInterceptor 实现HandlerInterceptor 接口并实现相应方法 123456789101112131415161718192021222324// 实现HandlerInterceptor 接口并实现方法@Componentpublic class TestInterceptor implements HandlerInterceptor &#123; // 在请求执行前执行 @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; // 设置编码格式为utf-8 request.setCharacterEncoding(&quot;utf-8&quot;); System.out.println(&quot;preHandle执行&quot;); return true; &#125; // 在请求执行后执行（preHandle必须返回true才会执行到这里） @Override public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception &#123; System.out.println(&quot;postHandle执行&quot;); &#125; // 视图渲染完成后执行（preHandle必须返回true才会执行到这里），通常用来清理资源 @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception &#123; System.out.println(&quot;afterCompletion执行&quot;); &#125;&#125; 实现WebMvcConfigurer 接口，将拦截器注册进spring容器并定义拦截路径（当注册多个拦截器时，先注册的会先执行） 1234567891011121314@Componentpublic class WebMvcConfig implements WebMvcConfigurer &#123; @Autowired private TestInterceptor testInterceptor; // 关于拦截路径这里 例如路径：http://localhost:8080/request/test // 拦截路径为/** =》拦截所有的请求 // 拦截路径为/**/request =》拦截所有尾为request的请求 // 拦截路径为/request/** =》拦截request下的所有请求 @Override public void addInterceptors(InterceptorRegistry registry) &#123; registry.addInterceptor(testInterceptor).addPathPatterns(&quot;/**&quot;); &#125;&#125; 关于拦截路径问题可参考：https://blog.csdn.net/zhou920786312/article/details/81026381 总结拦截器主要用来处理web请求中的共性问题，共性问题在拦截器中解决，可以减少重复代码，便于维护]]></content>
      <categories>
        <category>后台</category>
      </categories>
      <tags>
        <tag>java基础</tag>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于Ajax跨域的解决方案]]></title>
    <url>%2F2019%2F07%2F04%2F%E5%85%B3%E4%BA%8EAjax%E8%B7%A8%E5%9F%9F%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%2F</url>
    <content type="text"><![CDATA[Ajax跨域的原因 浏览器限制 跨域（协议、主机名、端口有一个不同就会产生跨域） xhr请求（XMLHttpRequest）当以上三个条件同时满足时才会产生ajax跨域 Ajax跨域的解决方案只要破坏上述三个条件之一就可以解决跨域问题 浏览器的启动参数上来设置，使浏览器不做跨域校验（不常用）以谷歌浏览器为例，在chrome.exe所在的路径按下shift键，点击右键，点击“在此处打开命令行窗口”，然后输入chrome –disable-web-security就可以了，此方法不常用，因为需要在客户端操作，而大多数用户是不会操作的 xhr解决==》jsonp（不常用）以下是谷歌浏览器中如何查看是否xhr请求（按F12，然后在弹出框中点击NetWork的All）使用jsonp来传输，jsonp会把动态创建script标签来进行请求，而对于服务器后台返回的数据用scprit标签形式进行解析（此时后台必须进行改动返回jsonp数据，否则前台会解析异常） js代码： 12345678$.ajax(&#123; url: &quot;http://localhost:8080/ajaxTest&quot;, dataType: &quot;jsonp&quot;, jsonp: &quot;callback&quot;, // 此处的字段应和后台统一，否则不会返回jsonp格式 success: function (json) &#123; alert(json) &#125; &#125;) 后台接口： 12345@RequestMapping(value = &quot;/ajaxTest&quot;) public Result ajaxTest()&#123; System.out.println(&quot;ajaxtest方法被调用了&quot;); return ResultUtil.success(); &#125; 浏览器控制台： 1Uncaught SyntaxError: Unexpected token（这里是解析异常） 服务器给出的json数据依旧能拿到，但控制台会报出解析异常，因为Jsonp解析的是script字段，此时应对后台接口进行改动（此处改动是基于springboot的）： 1234567891011import org.springframework.web.bind.annotation.ControllerAdvice; import org.springframework.web.servlet.mvc.method.annotation.AbstractJsonpResponseBodyAdvice; @ControllerAdvice// AbstractJsonpResponseBodyAdvice在Springboot 2.x已废弃public class JsonpAdvice extends AbstractJsonpResponseBodyAdvice&#123; public JsonpAdvice() &#123; super(&quot;callback&quot;); // 此处字段和上边Ajax的jsonp应统一 &#125; &#125; jsonp的弊端： 服务器代码需要改动（自己的项目可以改，如果是别人的项目那就。。。） 只能支持get请求（请求和返回的都是script代码） 不是xhr请求 跨域方面解决（常用） 对于跨域的请求，浏览器会在请求头上加上Origin，而在服务器返回数据时判断响应头有无跨域信息，若没有则会报错 被调用方解决跨域： 服务器端实现使用Filter来进行处理 12345678910// 注册filter @Bean public FilterRegistrationBean registerFilter()&#123; FilterRegistrationBean bean = new FilterRegistrationBean(); // 设置所有请求都经过过滤器 bean.addUrlPatterns(&quot;/*&quot;); // 设置添加的过滤器 bean.setFilter(new CrosFilter()); return bean; &#125; 12345678910111213public class CrosFilter implements Filter &#123; @Override public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException &#123; HttpServletResponse response = (HttpServletResponse)servletResponse; // 设定允许请求的域 response.addHeader(&quot;Access-Control-Allow-Origin&quot;,&quot;*&quot;); // 设定允许请求的头(简单请求不需要加，非简单请求需要带上) response.addHeader(&quot;Access-Control-Allow-Headers&quot;,&quot;*&quot;); // 设定允许请求的方法 response.addHeader(&quot;Access-Control-Allow-Methods&quot;,&quot;*&quot;); &#125; &#125;&#125; 带cookie的跨域filter设置(对于带自定义请求头的跨域，只许要在过滤器返回中添加对应请求头) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class CorsFilter implements Filter &#123; @Override public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException &#123; HttpServletRequest request = (HttpServletRequest) servletRequest; HttpServletResponse response = (HttpServletResponse) servletResponse; /* 设定允许请求的域 * 但在带cookie的访问时，origin必须完全匹配，不能用*， * cookie是被调用方的cookie */ // response.addHeader(&quot;Access-Control-Allow-Origin&quot;,&quot;*&quot;); // 动态设置允许请求的域 String origin = request.getHeader(&quot;Origin&quot;); if (!StringUtils.isEmpty(origin)) &#123; response.addHeader(&quot;Access-Control-Allow-Origin&quot;, origin); &#125; /* 设定允许请求的头(简单请求不需要加，非简单请求需要带上) * 简单请求：get，post，head * 请求header中无自定义请求头Content-type为以下几种：text/plain，multipart/form-data，application/x-www-form-urlencoded * 常见非简单请求：put，delete，json格式的ajax请求，带自定义头的ajax请求 */ // response.addHeader(&quot;Access-Control-Allow-Headers&quot;,&quot;*&quot;); String headers = request.getHeader(&quot;Access-Control-Request-Headers&quot;); if (!StringUtils.isEmpty(headers)) &#123; response.addHeader(&quot;Access-Control-Allow-Headers&quot;, headers); &#125; // -------------------------------------我是华丽丽分割线---------------------------------------------- // ------------------------------------下方三个都是固定值--------------------------------------------- // 允许请求的方法 // 个人感觉允许所有请求方法不安全 response.addHeader(&quot;Access-Control-Allow-Methods&quot;, &quot;*&quot;); // response.addHeader(&quot;Access-Control-Allow-Methods&quot;, &quot;GET,POST&quot;); // 非简单请求预检命令缓存一小时，否则每次请求会调用两次 response.addHeader(&quot;Access-Control-Max-Age&quot;, &quot;3600&quot;); // 是否开启cookie response.addHeader(&quot;Access-Control-Allow-Credentials&quot;, &quot;true&quot;); filterChain.doFilter(servletRequest, servletResponse); &#125; @Override public void init(FilterConfig filterConfig) throws ServletException &#123;&#125; @Override public void destroy() &#123;&#125;&#125; Nginx配置 待添加— Apache配置 待添加—- spring框架的跨域注解@CrossOrgin可以加在类或方法上来解决跨域 调用方解决 Nginx反向代理 Apache方向代理 参考： https://www.imooc.com/learn/947]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>http</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis的持久化]]></title>
    <url>%2F2019%2F06%2F21%2FRedis%E7%9A%84%E6%8C%81%E4%B9%85%E5%8C%96%2F</url>
    <content type="text"><![CDATA[Redis的持久化Redis的持久化有两种方式：Rdb和Aof Rdb（Redis的默认持久化策略）主进程fork（复制）出一个子进程来进行持久化，子进程会把内存中的数据复制一份写进一个临时文件中，当持久化完成的时候，会用临时文件来替换掉原来的dump,rdb（rdb文件的文件名可以通过conf文件中的dbfilename指定，原来dump的存放位置可以通过Redis的conf文件中的dir去查看，或通过config get dir 命令来查看）文件，此时持久化完成。在fork过程中，主进程不进行任何I/O操作，这保证了极高的性能。 优缺点优点： 适合大规模数据的恢复。 对数据完整性和一致性要求不高。 缺点： 最后一次持久化的数据可能丢失（当你进行持久化时Redis挂了，就会丢失）。 fork子进程，会复制主进程中的所有数据，如果主进程中数据非常大时，会造成极大的压力。 持久化策略save 900 1 900秒内Key改变1次，就会自动触发BGSAVE命令创建快照save 300 100 300秒内Key改变100次，就会自动触发BGSAVE命令创建快照save 60 10000 60秒内Key改变10000次，就会自动触发BGSAVE命令创建快照 创建快照的办法 BGSAVE命令：客户端向Redis发送BGSAVE命令，主进程会fork出一个子进程进行持久化。 SAVE命令：客户端向Redis发送SAVE命令创建一个快照，接到SAVE命令后Redis服务器在快照创建完毕前不会响应其他指令，SAVE命令不常用，通常只在没有足够内存或等待持久化操作完毕也无所谓的情况下才会使用。 SHUTDOWN命令：当Redis服务器接收到SHUTDOWN命令关闭时，会进行SAVE，并在SAVE执行完毕后关闭服务器。 一个Redis服服务务器器连连接接到到另另一一个个Redis服务器：当一个Redis服务器连接到另一个Redis服务器，并向对方发送SYNC命令来开始一次复制操作的时候，如果主服务器目前没有执行BGSAVE操作，或者主服务器并非刚刚执行完BGSAVE操作，那么主服务器就会执行BGSAVE命令 Aof（Redis默认关闭）以日志的形式来记录每个写操作，将Redis执行过的写指令全都记录下来（读操作不记录），只许追加文件但不可以改写文件，Redis启动时会读取该文件重新构建数据，Redis重启的话就是根据日志文件的内容将写指令从前往后执行一次来完成数据的恢复工作。（Aof保存的appendonly.aof文件） 持久化策略Appendfsync： always：同步持久化，每次发生数据改变立即记录到磁盘，性能差完整性好。 everysec：出厂默认推荐，一步操作，每秒记录，如果宕机只会丢失疫苗数据 no：从不记录 Aof的文件修复命令redis-check-aof –fix rewite重写Aof采用文件追加方式，文件会越来越大为了避免这种情况，新增重写机制，当Aof文件的大小超过所设定的阈值，Redis会启动aof文件的内容压缩，只保留可以恢复数据的最小指令集，可使用命令bgwriteaof 原理aof文件过大时，会fork出一条新进程将文件重写（先写入临时文件），遍历新进程中的内存数据，每条记录有一条对应的set语句。并没有读取原来aof文件中的数据，而是将内存中的数据库内容用命令重写了一遍。 触发机制auto-aof-rewite-percentage 100auto-aof-rewite-min-size 64mb默认配置是当aof文件大小是上次rewite后大小的一倍且文件大于64Mb是触发。 优点 每秒同步：appendfsync always 同步持久，数据完整性高性能较差。 每修改同步：appendfsync everysec 异步操作，每秒记录，如果一秒内宕机，有数据丢失。 劣势 相同数据集数据而言aof文件要远大于rdb文件，恢复速度慢与rdb。 aof运行效率慢于rdb，每秒同步策略效率较高。 转载：Java 学习/面试指南]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java遍历过程中删除元素]]></title>
    <url>%2F2018%2F11%2F16%2FJava%E9%81%8D%E5%8E%86%E8%BF%87%E7%A8%8B%E4%B8%AD%E5%88%A0%E9%99%A4%E5%85%83%E7%B4%A0%2F</url>
    <content type="text"><![CDATA[Iterator遍历过程中删除元素123456789101112131415161718public static void main(String[] args) &#123; List&lt;String&gt; list = new ArrayList&lt;&gt;(); list.add(&quot;a&quot;); list.add(&quot;b&quot;); list.add(&quot;c&quot;); Iterator&lt;String&gt; iterator = list.iterator(); while(iterator.hasNext()) &#123; String s = iterator.next(); if(s.equals(&quot;a&quot;)) &#123; iterator.remove(); &#125; &#125; for (String str : list) &#123; System.out.println(str); &#125; &#125;]]></content>
      <categories>
        <category>后台</category>
      </categories>
      <tags>
        <tag>java基础</tag>
      </tags>
  </entry>
</search>
